# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Overview

This is an R data package (`ethord`) containing metadata and report data from 96 research projects funded by the ETH Board's Open Research Data (ORD) program. The package follows standard R package conventions and provides four main datasets documenting projects from ETH Zurich, EPFL, and the four research institutes of the ETH Domain.

## Package Structure

### Data Objects
The package exports four main datasets, each documented in `R/`:
- `portal`: Project metadata from the ORD portal (96 projects, 8 variables)
- `docs_detail`: Detailed project information (7 rows, 19 variables including applicant details, funding, duration)
- `docs_proposal`: Project proposal documents (352 bytes)
- `docs_report`: Project report data (10KB)

### Data Pipeline
Raw data is stored in `data-raw/` and processed using the `pipeline.qmd` workflow:
1. Raw CSV files in `data-raw/` contain source data
2. `data-raw/dictionary.csv` defines the data dictionary mapping variables to descriptions
3. `data-raw/ord_portal_fetch_code/` contains scraping scripts:
   - `fetch_urls.js`: JavaScript for extracting project URLs
   - `fetch_data_from_html.py`: Python script for parsing HTML and extracting data
4. Processed data is exported to both `data/*.rda` (R format) and `inst/extdata/*.csv` (portable format)

### Key Directories
- `R/`: Dataset documentation files (roxygen2 format)
- `data/`: Binary R data objects (.rda files)
- `data-raw/`: Raw source data and processing scripts
- `inst/extdata/`: CSV exports and metadata.json for external use
- `data/metadata/`: Structured metadata files (access.csv, attributes.csv, biblio.csv, creators.csv)
- `man/`: Generated documentation
- `vignettes/articles/`: Package articles and documentation

## Development Commands

### Building and Documentation
```r
# Install package from GitHub
devtools::install_github("Global-Health-Engineering/ethord", dependencies = TRUE)

# Build package documentation site (pkgdown)
pkgdown::build_site_github_pages(new_process = FALSE, install = FALSE)

# Generate documentation from roxygen2 comments
devtools::document()

# Build README.md from README.Rmd
rmarkdown::render("README.Rmd")
```

### Data Processing
The `pipeline.qmd` file contains the data processing workflow. The main function `process_csv()` handles:
- Reading raw CSV files
- Cleaning column names with `janitor::clean_names()`
- Converting "null"/"NA"/"" strings to actual NA values
- Converting numeric columns to integers
- Exporting to both .rda and .csv formats

To process a new dataset:
```r
process_csv("data-raw/your_file.csv",
            overwrite_rda = TRUE,
            overwrite_csv = TRUE)
```

## Package Metadata

- **License**: CC BY 4.0
- **Version**: 0.0.3
- **DOI**: 10.5281/zenodo.16563064
- **Organization**: Global-Health-Engineering
- **Website**: https://global-health-engineering.github.io/ethord/
- **Dependencies**: Requires R >= 3.5

## Project Categories
Projects are classified into three funding categories:
- **Contribute**: 30k CHF projects
- **Explore**: 150k CHF projects
- **Establish**: 1.5m CHF projects

## Documentation Standards

Dataset documentation in `R/` files follows this pattern:
- Title and description reference the package overview
- `@format` specifies tibble dimensions (rows Ã— variables)
- `\describe{}` block documents each variable with `\item{name}{description}`
- Documentation is generated from roxygen2 comments

## CI/CD

The `.github/workflows/pkgdown.yaml` workflow automatically builds and deploys the pkgdown website to GitHub Pages on pushes to main/master, pull requests, and releases.

## Important Notes

- This is a data-only package (no exported functions)
- NAMESPACE is generated by roxygen2 and contains no exports
- README.md is generated from README.Rmd - edit the .Rmd file, not .md
- The package uses the `washr` package for data processing workflows (from openwashdata)
- Data dictionary in `data-raw/dictionary.csv` maps all variables across datasets
