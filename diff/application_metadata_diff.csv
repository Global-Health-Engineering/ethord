change_type,column,row,row_number_main,row_number_current,old_value,new_value,data_type
value_changed,main_applicant_laboratory_name,CONTRIBUTE/BRAINSCOREHUMAN,6,6,EPFL SV INX-SV UPSCHRIMPF1,EPFL SV INX-SV UPSCHRIMPF1 (UPSCHRIMPF1 laboratory of the Interschool Neuro X Institute),text
value_changed,project_abstract,CONTRIBUTE/BRAINSCOREHUMAN,6,6,"Brain-Score is a fast-growing platform which curates a diverse set of neural and behavioral measurements from non-human primate neuroscience experiments and facilitates its use in evaluating computational models of the brain's visual system. By translating models from machine learning into neuroscientific hypotheses, and neuroscience data into quantitative benchmarks to evaluate such models, Brain-Score makes computational as well as experimental advances available to the broader community in a synergistic manner. In this proposal, we aim to broaden the scope of Brain-Score to data from human experiments which will open the platform to the cognitive neuroscience community and make computational models more broadly applicable.<br/><br/>Specifically, we will:- Contribute new software to the Brain-Score platform to enable it to work with human data. This involves defining new endpoints for computational models to align with human brain anatomy and a common experimental behavioral task.
- Curate the Natural Scenes Dataset (NSD, Allen et al. 2022) for Brain-Score such that it is accessible for reproducible model evaluations. NSD is a large-scale dataset of human whole-brain recordings in response to thousands of natural images.
- Curate the THINGS-similarity dataset (Hebart et al. 2020) for addition into Brain-Score to make it accessible and reproducible for model evaluations. THINGS-similarity is a human behavioral dataset of millions of similarity judgments for thousands of images.","Brain-Score is a fast-growing platform which curates a diverse set of neural and behavioral measurements from non-human primate neuroscience experiments and facilitates its use in evaluating computational models of the brain's visual system. By translating models from machine learning into neuroscientific hypotheses, and neuroscience data into quantitative benchmarks to evaluate such models, Brain-Score makes computational as well as experimental advances available to the broader community in a synergistic manner. In this proposal, we aim to broaden the scope of Brain-Score to data from human experiments which will open the platform to the cognitive neuroscience community and make computational models more broadly applicable.<br/><br/>Specifically, we will:<br/>
* Contribute new software to the Brain-Score platform to enable it to work with human data. This involves defining new endpoints for computational models to align with human brain anatomy and a common experimental behavioral task.<br/>
* Curate the Natural Scenes Dataset (NSD, Allen et al. 2022) for Brain-Score such that it is accessible for reproducible model evaluations. NSD is a large-scale dataset of human whole-brain recordings in response to thousands of natural images.<br/>
* Curate the THINGS-similarity dataset (Hebart et al. 2020) for addition into Brain-Score to make it accessible and reproducible for model evaluations. THINGS-similarity is a human behavioral dataset of millions of similarity judgments for thousands of images.",text
value_changed,project_abstract,CONTRIBUTE/OPENMIC&AI,26,26,"Imaging science and computational microscopy are rapidly advancing, driven by novel interdisciplinary approaches involving deep learning algorithms. However, the increasing complexity and cost of these cutting-edge imaging systems and algorithms often make them inaccessible for non-experts, low-resource settings, and teaching applications. To address this challenge, we would like to organize a one-day workshop on open-source microscopy and AI to bring together the smart-microscopy community.The workshop will showcase a full pipeline of open-source solutions for optical imaging, from hardware to computational reconstruction and deep learning-based analysis. It will provide hands-on experience for participants to assemble an open microscope (OpenSIM, OpenUC2), perform reconstructions (Pyxu), and analyze images (DeepImageJ). It aims to empower researchers and teachers to take full control of their imaging pipeline and iterate rapidly on new solutions. Beyond this event, the project seeks to drive a broader and lasting impact on the community. Educational resources such as Jupyter notebooks and hardware kits will be developed and made publicly available to support teaching at EPFL and beyond.By showcasing a comprehensive open-source ecosystem for microscopy, this initiative aims at making state-of-the-art imaging technologies more accessible and further catalyze the growth of an open, interdisciplinary microscopy community.","Imaging science and computational microscopy are rapidly advancing, driven by novel interdisciplinary approaches involving deep learning algorithms. However, the increasing complexity and cost of these cutting-edge imaging systems and algorithms often make them inaccessible for non-experts, low-resource settings, and teaching applications. To address this challenge, we would like to organize a one-day workshop on open-source microscopy and AI to bring together the smart-microscopy community. The workshop will showcase a full pipeline of open-source solutions for optical imaging, from hardware to computational reconstruction and deep learning-based analysis. It will provide hands-on experience for participants to assemble an open microscope (OpenSIM, OpenUC2), perform reconstructions (Pyxu), and analyze images (DeepImageJ). It aims to empower researchers and teachers to take full control of their imaging pipeline and iterate rapidly on new solutions. Beyond this event, the project seeks to drive a broader and lasting impact on the community. Educational resources such as Jupyter notebooks and hardware kits will be developed and made publicly available to support teaching at EPFL and beyond. By showcasing a comprehensive open-source ecosystem for microscopy, this initiative aims at making state-of-the-art imaging technologies more accessible and further catalyze the growth of an open, interdisciplinary microscopy community.",text
value_changed,start_date,EXPLORE/OPENWASHDATA,73,73,2022-10-01,2024-09-01,text
value_changed,main_applicant_function,EXPLORE/OPENWASHDATA,73,73,Prof. Dr.,Prof. Dr.; Associate professor or similar,text
value_changed,project_title,EXPLORE/OPENWASHDATA,73,73,Open WASH data by building Open Science Competencies and Community,Open WASH data by establishing Data Stewards and increasing FAIRness,text
value_changed,total_budget_requested,EXPLORE/OPENWASHDATA,73,73,149990.0,150000.0,numeric
value_changed,project_abstract,EXPLORE/OPENWASHDATA,73,73,"Poor data management practices hold back progress in the Water, Sanitation, and Hygiene (WASH) sector, as WASH professionals often lack the training in data management competencies necessary for organizing, storing, and sharing data aligned with FAIR principles. This project addresses this gap by building the openwashdata community, which will support members in using open-source computational tools and further developing competencies consistent with FAIR data standards. The community aims to facilitate the publication of over 50 previously unpublished datasets contributed by members, fostering open science. The project also seeks to develop a global community of students and practitioners, create an accessible open data platform for WASH-related data, and research the technical, pedagogical, and political factors necessary for expanding and replicating this initiative to become the most comprehensive host and training platform in the open science WASH sector. The ultimate goal is to build a lasting, passionate network of WASH professionals applying FAIR data principles to benefit the entire sector.","We established the openwashdata community for the Water, Sanitation, and Hygiene (WASH) sector. We built infrastructure and communication channels, taught 100 WASH professionals the basics of data science, developed a workflow to publish WASH data following FAIR data principles, and mobilized those in the sector who were interested in joining our vision and mission. Our next step is establishing a data stewardship network, actively working with strategic partners in Malawi and South Africa by placing a fully-funded data steward within a research institute and a non-governmental organization. A newly developed 12-module ""data stewardship for openwashdata"" training programme will develop data management strategies and help our partners to institutionalize ORD practices long-term within their organizations. We will also further invest in the openwashdata publishing arm of the community by increasing the FAIRness of our data, critically analyzing how to better address the details of all four components of FAIR: Findability, Accessibility, Interoperability, and Reusability. We will also set up a governance structure and sounding board to ensure the long-term sustainability of the community. Through our activities and active open communications channels, we expect to create a demand for data stewardship in the WASH sector, assess their role and define a profile for data stewards more generally.",text
value_changed,main_applicant_function,CONTRIBUTE/WASHCOLLAB,45,45,Prof. Dr.,Director,text
value_changed,main_applicant_function,CONTRIBUTE/THRACE,38,38,Dr.,Scientist with tenure track,text
value_changed,main_applicant_first_name,CONTRIBUTE/THRACE,38,38,George Dan,George-Dan,text
value_changed,project_title,EXPLORE/FAIRQUAL,56,56,FAIRqual - FAIR Data Practices for Qualitative Research in Transdisciplinarity,FAIR Data Practices for Qualitative Research in Transdisciplinarity,text
value_changed,main_applicant_laboratory_name,EXPLORE/FAIRQUAL,56,56,Transdisciplinarity Lab (TdLab),TdLab,text
value_changed,main_applicant_first_name,ESTABLISH/OPEM,48,48,Henning,Christophe,text
value_changed,main_applicant_surname,ESTABLISH/OPEM,48,48,Stahlberg,Stahlberg; Coperet,text
value_changed,project_title,CONTRIBUTE/OPAS,24,24,Open Processing of Airborne imaging Spectrometry,Open Processing of Airborne imaging Spectrometry (OPAS),text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/OPAS,24,24,EPFL ENAC IIE CRYOS,"EPFL ENAC IIE CRYOS (Laboratory of Cryospheric Sciences, CRYOS)",text
value_changed,project_abstract,CONTRIBUTE/OPAS,24,24,"Developed by NASA-JPL and operated by the consortium of Swiss universities - ARES, the AVIRIS-4 is the most advanced airborne imaging spectrometer (AIS) currently operational in Europe. In agreement with NASA-JPL, ARES will make all data produced by AVIRIS-4 publicly available and is building an environment of open tools to make the processing of this data accessible, interoperable and reproducible, in line with FAIR principles. During our previous ORD-Contribute project, OGAIS, we developed an open tool which can be used to label point correspondences in AIS images by hand. This tool enables the airborne remote sensing community to obtain ground truth “tie-points” for evaluating the quality of the scene reconstruction and/or improving the image geo-referencing accuracy. After the first flights of AVIRIS-4 during the spring-summer this year, a clear need emerged for the mission at high resolution (0.3 – 1 m/pixel) to obtain point correspondence labels without human intervention in order to i) improve the conventional (direct) georeferencing, ii) automate the quality assessment on all current and future missions featuring more than couple flight-lines (>0.5 TB / mission). This project therefore proposes to support ARES ORD practices by providing tools to automate the detection of tie-points as spatial constraints in overlapping AVIRIS-4 images, and integrate them in EPFL’s open, on-line georeferencing service ODYN to maximise findability.","Developed by NASA-JPL and operated by the consortium of Swiss universities - ARES, the AVIRIS-4 is the most advanced airborne imaging spectrometer (AIS) currently operational in Europe. In agreement with NASA-JPL, ARES will make all data produced by AVIRIS-4 publicly available and is building an environment of open tools to make the processing of this data accessible, interoperable and reproducible, in line with FAIR principles. During our previous ORD-Contribute project, OGAIS, we developed an open tool which can be used to label point correspondences in AIS images by hand. This tool enables the airborne remote sensing community to obtain ground truth “tie-points” for evaluating the quality of the scene reconstruction and/or improving the image geo-referencing accuracy. After the first flights of AVIRIS-4 during the spring-summer this year, a clear need emerged for the mission at high resolution (0.3 – 1 m/pixel) to obtain point correspondence labels without human intervention in order to ii) improve the conventional (direct) georeferencing, ii) automate the quality assessment on all current and future missions featuring more than couple flight-lines (>0.5 TB / mission). This project therefore proposes to support ARES ORD practices by providing tools to automate the detection of tie-points as spatial constraints in overlapping AVIRIS-4 images, and integrate them in EPFL’s open, on-line georeferencing service ODYN to maximise findability.",text
value_changed,project_abstract,CONTRIBUTE/OPENJMP,25,25,"Decades of manual data structuring have resulted in the most comprehensive and internationally-comparable information on Water, Sanitation, and Hygiene (WASH) coverage. The WHO/UNICEF Joint Monitoring Programme for Water Supply, Sanitation and Hygiene (JMP) maintains the database. The data are shared openly but in spreadsheet-based proprietary software, not following FAIR data principles. Data stored in spreadsheets underutilizes the potential those data could have for purposes other than the national, regional and global progress monitoring in WASH.

We will approach this unused potential by developing open-source data and software packages that follow FAIR data principles to share the data within the WASH community and beyond. In the process, we engage with the community by hosting free learning events using open-source computational tools, enabling community members to further competencies aligned with FAIR data principles.","Decades of manual data structuring have resulted in the most comprehensive and internationally-comparable information on Water, Sanitation, and Hygiene (WASH) coverage. The WHO/UNICEF Joint Monitoring Programme for Water Supply, Sanitation and Hygiene (JMP) maintains the database. The data are shared openly but in spreadsheet-based proprietary software, not following FAIR data principles. Data stored in spreadsheets underutilizes the potential those data could have for purposes other than the national, regional and global progress monitoring in WASH.
We will approach this unused potential by developing open-source data and software packages that follow FAIR data principles to share the data within the WASH community and beyond. In the process, we engage with the community by hosting free learning events using open-source computational tools, enabling community members to further competencies aligned with FAIR data principles.",text
value_changed,main_applicant_function,EXPLORE/NMRPRIME,66,66,Professor (Prof. Dr.); Senior Scientist,Professor (Prof. Dr.),text
value_changed,project_title,CONTRIBUTE/SOP,34,34,Speckle-OpenCascade Prototype for Enhanced AEC Interoperability through Geometry-Centered Approach.,Speckle-OpenCascade Prototype for Enhanced AEC Interoperability through Geometry-Centered Approach,text
value_changed,project_abstract,CONTRIBUTE/SOLARFUELSDB+,33,33,"In this proposal, we seek to significantly extend the recently created Solar Fuels Database (SolarFuelsDB) where we developed a systematic machine-readable framework for solar to fuel devices and developed an online interface for data entry and visualization, with the ultimate aim of accelerating the development of such technologies. The original project successfully created a systematic machine-readable framework in which to categorise photo-electrochemical (PEC) systems, populated the database (72 papers, 154 reported devices) and developed an online interface for data entry and visualisation, focusing intentionally on photo-electrochemical water splitting (hydrogen production) to define a manageable research task. The initial ambition at project conception was always to expand to other solar fuels (e.g. CO₂ reduction towards CO, ethylene, ethanol, etc.) and methodologies (e.g. thermochemical H₂ production), so the existing database schema has been designed to be versatile and extensible. Specifically, we plan to extend the solar fuels considered to include carbon monoxide, syngas, formic acid, methane, ethanol, etc., and extend the technological pathways to include thermochemical redox cycles. Notably, there has been a recent focus on moving from solar hydrogen to solar-driven reduction of CO₂ to valuable chemicals and fuels. Consequently, the extended SolarFuelsDB database (SolarFuelsDB+) has the potential to unify multiple different solar fuel pathways into a single repository where reports can be found and performances of various technologies can be systematically and equitably compared. We will engage with international research communities to ensure a judicious selection of metadata is captured by the database. These reporting guidelines will facilitate standardization in data reporting, and inclusion in the database will provide an incentive for authors as inclusion of research could lead to improved findability and greater dissemination of results. In line with the open-science goals of this project, it is envisaged the database will become continually maintained through community submission of new papers. This greatly improved and openly accessible resource will consolidate previous work and provide the overview required to gain novel insight in to the field and thereby identify promising future research trends required to move solar fuels towards wide-scale implementation.","In this proposal, we seek to significantly extend the recently created Solar Fuels Database where we developed a systematic machine-readable framework for solar to fuel devices and developed an online interface for data entry and visualization, with the ultimate aim of accelerating the development of such technologies. This project would extend the database to further chemistries and methodologies beyond currently captured in the database (photo-electrochemical water splitting). Specifically, we plan to extend the solar fuels considered to include carbon monoxide, syngas, formic acid, methane, ethanol etc. and extend the technological pathways to include thermochemical redox cycles. We will engage with international research communities to ensure a judicious selection of metadata is captured by the database. These reporting guidelines will facilitate standardization in data reporting, and inclusion in the database will provide an incentive for authors as inclusion of research could lead to improved findability and greater dissemination of results. In line with the open-science goals of this project, it is envisaged the database will become continually maintained through community submission of new papers. This greatly improved and openly accessible resource will consolidate previous work and provide the overview required to gain novel insight in to the field and thereby identify promising future research trends required to move solar fuels towards wide-scale implementation.",text
value_changed,project_title,CONTRIBUTE/WEAR-MED,46,46,Open Access and Interoperability in Medical Wearables: Community-driven standardization of low-level communication protocols for raw wearable sensor data,Open Access and Interoperability in Medical Wearables,text
value_changed,project_duration_months,CONTRIBUTE/WEAR-MED,46,46,6.0,5.0,numeric
value_changed,project_abstract,CONTRIBUTE/BOOST4EPILEPSY,4,4,"In the last decade several initiatives have made annotated scalp EEG datasets of people with epilepsy available to researchers around the world. However, the format of the data varies between datasets. This heterogeneity of data along with a heterogeneity of methods used by researchers to validate algorithms makes comparison of algorithms difficult, ranking the best algorithms impossible and ultimately significantly hinders the research progress.This proposal builds on ORD datasets and community guidelines and standards to propose a unified framework for the validation of seizure detection algorithms. The main objective is the development of tools and standards that will unify the workflow for the validation of seizure detection algorithms in order to make data for seizure detection adhere to the principles of Findable, Accessible, Interpretable and Reusable data.To build this framework we will be contributing to Open Research Data by curating existing public annotated datasets, by standardising the data format of these different datasets. For these standards we will develop software tools that convert the original datasets to this standardised format. We will standardise the methodology to evaluate algorithms in order to build a benchmark state of the art algorithms.We will centralise all this knowledge, datasets, standards tools and benchmark on a website that will help to speed the development of seizure detection algorithms.","In the last decade several initiatives have made annotated scalp EEG datasets of people with epilepsy available to researchers around the world. However, the format of the data varies between datasets. This heterogeneity of data along with a heterogeneity of methods used by researchers to validate algorithms makes comparison of algorithms difficult, ranking the best algorithms impossible and ultimately significantly hinders the research progress.

This proposal builds on ORD datasets and community guidelines and standards to propose a unified framework for the validation of seizure detection algorithms. The main objective is the development of tools and standards that will unify the workflow for the validation of seizure detection algorithms in order to make data for seizure detection adhere to the principles of Findable, Accessible, Interpretable and Reusable data.

To build this framework we will be contributing to Open Research Data by curating existing public annotated datasets, by standardising the data format of these different datasets. For these standards we will develop software tools that convert the original datasets to this standardised format. We will standardise the methodology to evaluate algorithms in order to build a benchmark state of the art algorithms.

We will centralise all this knowledge, datasets, standards tools and benchmark on a website that will help to speed the development of seizure detection algorithms.",text
value_changed,project_abstract,EXPLORE/ILOG,61,61,"Our aim is to develop practices and tools to trace and share the state of shared inventory items in a multi-user laboratory, linking this information to the personal Electronic Lab Notebook (ELN) of each user. With this practice, we seek to fill a big blank spot in the tracking of mutable laboratory information management system (LIMS) objects. A tool akin to a digital inventory logbook will be developed as an openBIS extension to support a wide range of experimental laboratories with variable types of measurement equipment and inventory items. This inventory logbook will complement the native openBIS ELN-LIMS, with focus on measurement equipment and inventory management. The implementation will prioritize generality and user-friendliness to minimize adaptation barriers and promote the dissemination of this ORD practice.","Our aim is to develop practices and tools to trace and share the state of shared inventory items in a multi-user laboratory, linking this information to the personal Electronic Lab Notebook (ELN) of each user. With this practice, we seek to fill a big blank spot in the tracking of mutable laboratory information management system (LIMS) objects.
A tool akin to a digital inventory logbook will be developed as an openBIS extension to support a wide range of experimental laboratories with variable types of measurement equipment and inventory items. This inventory logbook will complement the native openBIS ELN-LIMS, with focus on measurement equipment and inventory management. The implementation will prioritize generality and user-friendliness to minimize adaptation barriers and promote the dissemination of this ORD practice.",text
value_changed,start_date,EXPLORE/NHCDATAVISION,65,65,2024-09-01,NA,text
value_changed,main_applicant_function,EXPLORE/NHCDATAVISION,65,65,Professor,NA,text
value_changed,project_title,EXPLORE/NHCDATAVISION,65,65,Enhancing 3D data visualization standards and practices for natural history collections,NA,text
value_changed,main_applicant_city,EXPLORE/NHCDATAVISION,65,65,Zürich,NA,text
value_changed,main_applicant_laboratory_name,EXPLORE/NHCDATAVISION,65,65,Biocommunication/ ETH Entomological Collection,NA,text
value_changed,main_applicant_first_name,EXPLORE/NHCDATAVISION,65,65,Consuelo,NA,text
value_changed,main_applicant_surname,EXPLORE/NHCDATAVISION,65,65,De Moraes,NA,text
value_changed,project_duration_months,EXPLORE/NHCDATAVISION,65,65,12.0,NA,numeric
value_changed,project_acronym,EXPLORE/NHCDATAVISION,65,65,NHCDataVision,NA,text
value_changed,total_budget_requested,EXPLORE/NHCDATAVISION,65,65,150000.0,NA,numeric
value_changed,main_applicant_institution,EXPLORE/NHCDATAVISION,65,65,ETH Zürich,NA,text
value_changed,project_abstract,EXPLORE/NHCDATAVISION,65,65,"3D imaging is a cutting-edge method for digitizing natural history collections, offering immense potential for taxonomy, general biology, and education. By analyzing 3D models, specialists worldwide can instantly access rare reference objects from collections, aiding in field interpretation and various scientific and educational applications. As 3D scanning becomes more efficient and digitization initiatives invest heavily in generating 3D data, 3D models are anticipated to become widespread. Surprisingly, there is limited research on how these 3D data are being used for research and education in natural history collections. Initial comparisons suggest that current 3D models are complex sets of data, lack suitable tools for analysis and modification, and require linking to additional metadata for utility in taxonomic research and education. This proposal aims to establish additional standards for 3D data preparation and develop best practice guidelines to ensure the usability of natural history collections data. Rather than focusing on developing ready-to-use solutions, the emphasis will be on identifying needs, documenting recommendations, and testing them with expert user groups. The outcomes will directly impact data infrastructures in the U.S., Europe, and Switzerland, serving over 500 institutions. They will also enable expert groups worldwide, particularly in the Global South, to virtually access natural history collection specimens for various scientific purposes.",NA,text
value_changed,main_applicant_postcode,EXPLORE/NHCDATAVISION,65,65,8092.0,NA,numeric
value_changed,project_title,CONTRIBUTE/FIRE,13,13,Open Mechanized Foundations for JavaScript Regular Expressions (FiRE),Open Mechanized Foundations for JavaScript Regular Expressions,text
value_changed,project_title,EXPLORE/EXAIRIM,54,54,Explore AiiDA for Regional Inverse Modelling of Greenhouse Gases (ExAiRIM),Explore AiiDA for Regional Inverse Modelling of Greenhouse Gases,text
value_changed,project_title,EXPLORE/HT-CHEMBORD,60,60,High-Throughput Chemistry Based Open Research Database,High-Throughput Chemistry Based Open Research Database HT-CHEMBORD,text
value_changed,main_applicant_laboratory_name,EXPLORE/HT-CHEMBORD,60,60,EPFL SB ISIC SWISSCAT,EPFL SB ISIC SWISSCAT (Swiss Cat+ West Hub),text
value_changed,main_applicant_function,EXPLORE/XCELL,77,77,Senior Scientist (PhD),Senior Scientist (PhD); Principal Investigator,text
value_changed,project_title,EXPLORE/XCELL,77,77,Towards an Open and Fair International Tree-Ring database for intra-annual tree-ring data and images (Xcell),Towards an Open and Fair International Tree-Ring database for intra-annual tree-ring data and Images (Xcell),text
value_changed,project_abstract,EXPLORE/XCELL,77,77,"Tree-ring research has played a pivotal role in unraveling past environmental conditions, understanding climate variability, and providing valuable insights into ecological changes over time. In the current era of digitalization, driven by technological advancements, the field is undergoing a profound transformation, delivering unprecedented details crucial for enhanced comprehension and exploration across various research domains. However, the absence of a suitable repository and the emerging imbalance between resource-intensive data producers and users pose significant challenges to data-sharing practices. This project aims to address these challenges by showcasing an operational solution, exemplified through intra-annually resolved wood cell anatomical data and images, involving the establishment of a modern, robust, and flexible repository and simultaneous redefinition of incentives for data producers. The Xcell Hub, through the creation of a community-specific, interactive, visualizable, and user-friendly online data repository, aims to foster Open Research Data (ORD) practices. Specifically, the project will develop an ORD-oriented operational web-based prototype designed for handling and hosting intra-annual resolved tree-ring data, focusing initially on Quantitative Wood Anatomy (QWA) data produced with the ROXAS software. The hub will collect, harmonize, centralize, preserve, and archive QWA data, metadata, and images, promoting openness, reproducibility, and collaboration between data producers and users. Features include a user-friendly Shiny web interface linked to a PostgreSQL database, comprehensive documentation, interactive data visualization, and a data policy that encourages sharing while recognizing contributors. This platform addresses current inequalities in data publication and access within the QWA and dendrochronology communities, providing a scalable example of good ORD practices through decentralized interactivity, rewarding mechanisms, transparent data assessment, and enhanced data quality.","Tree-ring research has played a pivotal role in unraveling past environmental conditions, understanding climate variability, and providing valuable insights into ecological changes over time. In the current era of digitalization, driven by technological advancements, the field is undergoing a profound transformation, delivering unprecedented details crucial for enhanced comprehension and exploration across various research domains. However, the absence of a suitable repository and the emerging imbalance between resource-intensive data producers and users pose significant challenges to data-sharing practices. This project aims to address these challenges by showcasing an operational solution, exemplified through intra-annually resolved wood cell anatomical data and images, involving the establishment of a modern, robust, and flexible repository and simultaneous redefinition of incentives for data producers. The Xcell Hub, through the creation of a community-specific, interactive, visualizable, and user-friendly online data repository, aims to foster Open Research Data (ORD) practices. This solution integrates modern open-source technologies, emphasizing decentralized interactivity, rewarding mechanisms, and transparent data assessment to secure data archiving, engage data producers, stimulate contributions, and enhance data quality.",text
value_changed,start_date,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,2024-10-01,text
value_changed,main_applicant_function,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,Group Leader Genome Informatics,text
value_changed,main_applicant_city,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,Zurich,text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,Functional Genomics Center Zurich,text
value_changed,project_duration_months,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,12.0,numeric
value_changed,total_budget_requested,CONTRIBUTE/NGSDATABOOSTER,22,22,15000.0,30000.0,numeric
value_changed,project_abstract,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,"Life science generates vast amounts of next generation sequencing (NGS) data, and there are well-established, FAIR repositories for open access of this data. Still, depositing NGS data in these repositories bears some challenges for life science researchers, leading to data not being deposited and shared. We propose to implement a web service that simplifies data deposition for life science. Our service, will start from data and meta-information available in omics-data management systems like B-Fabric. It will let the user review and curate the information to be uploaded and will then perform the upload. Our web service will directly help research groups to make their data swiftly accessible in a well-defined and well-documented format in the recognized repositories with world-wide visibility and accessibility. The service will significantly reduce the efforts of making NGS data openly accessible, it will increase the quality of the openly accessible data, and it will make the originators of NGS data, the various research institutes in Switzerland, more visible.",text
value_changed,main_applicant_postcode,CONTRIBUTE/NGSDATABOOSTER,22,22,NA,8057.0,numeric
value_changed,start_date,CONTRIBUTE/GRAND TOUR,17,17,2024-03-01,NA,text
value_changed,main_applicant_function,CONTRIBUTE/GRAND TOUR,17,17,Prof,NA,text
value_changed,project_title,CONTRIBUTE/GRAND TOUR,17,17,Fostering Research on Mobile Robotics with High-Quality Data and Open Tooling (GrandTour),Fostering Research on Mobile Robotics with High-Quality Data and Open Tooling,text
value_changed,main_applicant_city,CONTRIBUTE/GRAND TOUR,17,17,Zurich,NA,text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/GRAND TOUR,17,17,Robotic Systems Lab,NA,text
value_changed,project_duration_months,CONTRIBUTE/GRAND TOUR,17,17,12.0,NA,numeric
value_changed,project_acronym,CONTRIBUTE/GRAND TOUR,17,17,Grand Tour,NA,text
value_changed,project_abstract,CONTRIBUTE/GRAND TOUR,17,17,"Mobile ground robots have become increasingly popular in academia and various industrial applications. However, unlike other domains like aerial robotics, autonomous driving, and construction, there is currently no high-quality, large-scale dataset or reliable benchmark established in this field, nor the tooling available to do so. Creating such a dataset would be immensely valuable for researchers and developers in fostering research on robust and practical algorithms across diverse environments. Moreover, the development of a standardized benchmarking platform would promote fair comparisons between different approaches, fostering innovation and facilitating the rapid progress of mobile ground robot research. Motivated by this, we propose to collect and share a high-quality, versatile, large-scale robotic dataset, “GrandTour”, with scalable and automated tooling– focusing on legged robots in addition to a set of benchmarks and the necessary tooling.",NA,text
value_changed,main_applicant_postcode,CONTRIBUTE/GRAND TOUR,17,17,8092.0,NA,numeric
value_changed,project_abstract,CONTRIBUTE/MISHMASH,19,19,"The emerging field of microbiome research is driven by large-scale, high-dimensional datasets. Unrestricted access to sequence data and metadata is necessary for scientific innovation and re-use, and is consequently required by the scientific community, certain journals, and funding agencies.<br/><br/>Unfortunately, many microbiome studies suffer from poor data accessibility and metadata interoperability, hampering scientific advancement.<br/><br/>The project aims to close open research data (ORD) gaps in the microbiome field by addressing (1) the ineffectiveness of sequence data availability statements, which leads to poor reporting, reproducibility, and re-use; and (2) lack of consistent metadata standards for annotating microbial ORD.<br/>We propose a two-pronged solution in (1) developing a tier-based FAIR ORD standard for the field, and (2) building software to assess adherence to FAIR ORD standards. This project would contribute open resources intended for use by a diverse range of users, including researchers, journals, and funding agencies.<br/><br/>Combined with the tier-based system, validation software will enable users to assess how well microbiome studies meet data availability and metadata standards. The tools and guidelines developed here will improve sequence data and metadata reporting practices for greater accessibility, interoperability, and future re-use.","The emerging field of microbiome research is driven by large-scale, high-dimensional datasets. Unrestricted access to sequence data and metadata is necessary for scientific innovation and re-use, and is consequently required by the scientific community, certain journals, and funding agencies.

Unfortunately, many microbiome studies suffer from poor data accessibility and metadata interoperability, hampering scientific advancement.

The project aims to close open research data (ORD) gaps in the microbiome field by addressing (1) the ineffectiveness of sequence data availability statements, which leads to poor reporting, reproducibility, and re-use; and (2) lack of consistent metadata standards for annotating microbial ORD.

We propose a two-pronged solution in (1) developing a tier-based FAIR ORD standard for the field, and (2) building software to assess adherence to FAIR ORD standards. This project would contribute open resources intended for use by a diverse range of users, including researchers, journals, and funding agencies.

Combined with the tier-based system, validation software will enable users to assess how well microbiome studies meet data availability and metadata standards. The tools and guidelines developed here will improve sequence data and metadata reporting practices for greater accessibility, interoperability, and future re-use.",text
value_changed,start_date,EXPLORE/MED-WEAR,64,64,2024-12-01,NA,text
value_changed,main_applicant_function,EXPLORE/MED-WEAR,64,64,Senior Scientist (Head SCAI Lab),NA,text
value_changed,project_title,EXPLORE/MED-WEAR,64,64,Open API and Interoperability in Medical Wearable Data for Healthcare Research,NA,text
value_changed,main_applicant_city,EXPLORE/MED-WEAR,64,64,Nottwil,NA,text
value_changed,main_applicant_laboratory_name,EXPLORE/MED-WEAR,64,64,SCAI Lab,NA,text
value_changed,main_applicant_first_name,EXPLORE/MED-WEAR,64,64,Diego,NA,text
value_changed,main_applicant_surname,EXPLORE/MED-WEAR,64,64,Paez-Granados,NA,text
value_changed,project_duration_months,EXPLORE/MED-WEAR,64,64,18.0,NA,numeric
value_changed,project_acronym,EXPLORE/MED-WEAR,64,64,MED-WEAR,NA,text
value_changed,total_budget_requested,EXPLORE/MED-WEAR,64,64,150000.0,NA,numeric
value_changed,main_applicant_institution,EXPLORE/MED-WEAR,64,64,ETH Zürich,NA,text
value_changed,project_abstract,EXPLORE/MED-WEAR,64,64,"The MED-WEAR project addresses the absence of data interoperability in wearable devices in clinical practice and research, i.e., each manufacturer, service provider and researcher, executes unique solutions for data capturing, storing, and formatting in each study. In response to this challenge, we propose the development of a Wearable API (MED-WEAR), which provides a standardised framework between medical wearables and robotic devices to collect data in multiple research and clinical facilities, whilst reducing the workload and costs by applying FAIR principles in clinical research with this devices. We aim to establish standardised data collection in the ETH domain and beyond, herewith, empowering the research in healthcare community for streamlined data collection with wearables to foster innovation with wearables and define open standards. MED-WEAR impacts clinical and data science research by enabling lifelogging for individuals, promoting transparency in patient monitoring across rehabilitation laboratories. Engaging with the Swiss Neuro Rehab Initiative and collaboration across ETH RESC, RELAB, SMS lab, SCAI lab and DART lab at LLUI, the project establishes an interoperable platform, with the potential to provide a new ORD service within the ETH domain.",NA,text
value_changed,main_applicant_postcode,EXPLORE/MED-WEAR,64,64,6007.0,NA,numeric
value_changed,main_applicant_laboratory_name,EXPLORE/OPENPULSE,70,70,Swiss Data Science Center (EPFL VPA VPA-AVP-CP SDSC),EPFL VPA VPA-AVP-CP SDSC,text
value_changed,project_abstract,EXPLORE/OPENPULSE,70,70,"OpenPulse: Assessing Open Science community metrics for Open Source Software aims to redefine the measurement of Open Science by focusing on Open Source Software (OSS) from EPFL. It addresses the limitations of current Open Science metrics, which primarily track Open Access publications, by proposing a new framework to evaluate the development of OSS and its community impact. This involves developing a tool, OpenPulse, to monitor OSS activities, establish reliable OSS datasets, and create visualizations for real-time impact assessment. The project emphasizes collaboration, community engagement, and the development of discipline-specific dashboards, aiming to foster a more inclusive and comprehensive understanding of Open Science's impact beyond traditional publications. Our project aims to solve that issue, by investigating ways to identify Open Source Software coming out of EPFL, defining measures of their FAIRness and investigating community metrics that will provide us with an understanding of the impact and health of a project. This therefore falls within the objective of both specifying ORD standards and prototyping a new ORD tool for monitoring Open Science outputs and their impact. Through providing visibility to these outputs, our intention is also to help researchers build and find their communities to engage in collaboration around shared resources. Crucially, we hold the view that Open Science extends beyond institutional boundaries and is instead rooted in discipline-specific communities and their individual definitions of the concept. The project will therefore involve workshops to consult researchers about the needs of their specific communities, and build individual dashboards that are catered to these needs. Once the project is robust and deployed, expansion to inter institutional collaborations will be developed.","OpenPulse: Assessing Open Science community metrics for Open Source Software"" aims to redefine the measurement of Open Science by focusing on Open Source Software (OSS) from EPFL. It addresses the limitations of current Open Science metrics, which primarily track Open Access publications, by proposing a new framework to evaluate the development of OSS and its community impact. This involves developing a tool, OpenPulse, to monitor OSS activities, establish reliable OSS datasets, and create visualizations for real-time impact assessment. The project emphasizes collaboration, community engagement, and the development of discipline-specific dashboards, aiming to foster a more inclusive and comprehensive understanding of Open Science's impact beyond traditional publications.",text
value_changed,main_applicant_surname,EXPLORE/ASTROORDAS,51,51,Kneib,"Kneib, Tolley, Neronov, Savchenko",text
value_changed,project_abstract,CONTRIBUTE/CA ORD,8,8,"The Groupe ACM (Gr-ACM) is a research group responsible for the collection of architecture heritage archives known as the Archives de la construction moderne (ACM). Digital contents in architecture heritage archives is increasing and will increase in the future both through donations of new born-digital archives and digitization campaigns of paper archives. Through the CA ORD Project, the Gr-ACM aims to improve its capacity to preserve and make FAIRly available data and metadata from digital architecture archives (both born-digital and digitized from paper). To date, the Gr-ACM has collected 4 Tb of digital data made of files in different formats (.dwg, .dxf, .pln, .jpg, .pdf, etc.) stored on external hard drives and CD-Rs, which are therefore unavailable for research. The CA ORD Project aims to fill this gap. It is about installing, configuring, and running the open-source software Archivematica, which is an archiving system based on a multi-services architecture, that allows for automation, extraction, and normalization of data and metadata. These (METS files) will be made available on the already existing ACM’s ORD AtoM-based portal Morphé, since Archivematica and Atom are interoperable. Thanks to readily exploitable data, the CA ORD Project will enlarge the ACM users community (currently limited to historians) including new researchers from the fields of architecture, engineering and land management.","The Groupe ACM (Gr-ACM) is a research group responsible for the collection of architecture heritage archives known as the Archives de la construction moderne (ACM). Digital contents in architecture heritage archives is increasing and will increase in the future both through donations of new born-digital archives and digitization campaigns of paper archives. Through the CA ORD Project, the Gr-ACM aims to improve its capacity to preserve and make FAIRly available data and metadata from digital architecture archives (both born-digital and digitized from paper). To date, the Gr-ACM has collected 4 Tb of digital data made of files in different formats (.dwg, .dxf, .pln, .jpg, .pdf, etc.) stored on external hard drives and CD-Rs, which are therefore unavailable for research.<br/>The CA ORD Project aims to fill this gap. It is about installing, configuring, and running the open-source software Archivematica, which is an archiving system based on a multi-services architecture, that allows for automation, extraction, and normalization of data and metadata. These (METS files) will be made available on the already existing ACM’s ORD AtoM-based portal Morphé, since Archivematica and Atom are interoperable.<br/>Thanks to readily exploitable data, the CA ORD Project will enlarge the ACM users community (currently limited to historians) including new researchers from the fields of architecture, engineering and land management.",text
value_changed,start_date,CONTRIBUTE/TIMERESHDRMX,39,39,NA,2023-01-01,text
value_changed,main_applicant_function,CONTRIBUTE/TIMERESHDRMX,39,39,NA,Beamline Data Scientist,text
value_changed,main_applicant_city,CONTRIBUTE/TIMERESHDRMX,39,39,NA,"Villigen, PSI",text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/TIMERESHDRMX,39,39,NA,Swiss Light Source,text
value_changed,project_duration_months,CONTRIBUTE/TIMERESHDRMX,39,39,NA,12.0,numeric
value_changed,project_abstract,CONTRIBUTE/TIMERESHDRMX,39,39,NA,"The upcoming Swiss Light Source 2.0 machine upgrade and the advent of free electron lasers (SwissFEL) enable novel and exciting advancements in X-ray science. One of the emerging techniques is time-resolved serial crystallography. The technique can provide good insight into biomolecular processes at micro- and millisecond timescales but is extremely data intensive. A single experiment can, already at this moment, produce a continuous stream of X-ray images at a rate of 2’000 images per second (17 GB/s), running for hours. Dataset size for the technique is many terabytes. The dataset size makes complete raw data deposited in the public repository difficult to access.Within this project, I will create reduced datasets with improved accessibility by applying existing protein diffraction labeling algorithms to filter images. The resulting dataset will only contain images with high-quality diffraction (usually 0.1-10% of all images) and will be available in the PSI public data repository alongside the complete dataset. I will also improve metadata content by including labeling results to help the datasets' interoperability and findability.",text
value_changed,main_applicant_postcode,CONTRIBUTE/TIMERESHDRMX,39,39,NA,5323.0,numeric
value_changed,project_title,EXPLORE/COORDINEO,52,52,COmmunity Needs of Open Research Data Practices iN FibEr-Optic Sensing - Leading by Example. [COORDINEO],COmmunity Needs of Open Research Data PractIces iN FibEr-Optic Sensing - Leading by Example. [COORDINEO],text
value_changed,start_date,CONTRIBUTE/XYT,47,47,NA,2023-04-01,text
value_changed,main_applicant_function,CONTRIBUTE/XYT,47,47,NA,PhD Student,text
value_changed,main_applicant_city,CONTRIBUTE/XYT,47,47,NA,Lausanne,text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/XYT,47,47,NA,EPFL ENAC IA LASUR,text
value_changed,project_duration_months,CONTRIBUTE/XYT,47,47,NA,5.0,numeric
value_changed,project_abstract,CONTRIBUTE/XYT,47,47,NA,"Today, more and more digital data are generated by urban dynamics. Yet, the generated data is extensive and heterogenous. Datasets are large, multi-sourced, often noisy, and come in various formats and standards. In addition, a particularity of urban data is its mix in terms of level of restriction. While geolocation data is private and sensitive, public transit schedules are open data. In this context, there is a need (i) to provide a framework to re-unify the multiformity of urban dynamics data, (ii) to articulate open and restricted data, (iii) to cohere offer and demand data, and (iv) to keep track of a privacy metric. This project proposes to develop and release an open Python package to address these four needs and therefore contribute to Urban Mobility Open Research Data practices.",text
value_changed,main_applicant_postcode,CONTRIBUTE/XYT,47,47,NA,1015.0,numeric
value_changed,main_applicant_function,ESTABLISH/PREMISE,49,49,Group leader (Senior Scientist),"Group leader (Senior Scientist); Lecturer / Reader, Senior researcher",text
value_changed,project_title,ESTABLISH/PREMISE,49,49,PREMISE: Open and Reproducible Materials Science Research,PREMISE (Open and Reproducible Materials Science Research),text
value_changed,project_abstract,EXPLORE/FAIRGEO,55,55,"The project aims to improve openness and interaction between research communities working with geospatial data. There is currently a significant gap in the absence of an application that enables research communities and Open Science stakeholders to publish, visualise, combine and extract research geospatial data in the formats desired by users, and to use them directly and openly in teaching and research. The project will focus on addressing key questions and working with research communities to better understand the needs and requirements of researchers for working with geospatial data in an open research data context. Key questions include the desired practices, data formats and standards for searching, combining, sharing and publishing open research geodata, and assessing the capabilities of existing geoportals such as GeoVITe to implement the developed ORD practices.
Collaboration with the community, in particular with representatives of the geosciences, is essential to discuss and develop user-centred ORD practices. Participatory approaches aim to focus on user needs to make research geodata findable, accessible, interoperable and reusable in line with the FAIR principles. Based on the identified needs and processes, initial testing and technical implementation will be carried out on the portal. The long-term goal is to establish sustainable tools for the open research geodata community, based on existing open standards and an improved web-based geoportal.","The project aims to improve openness and interaction between research communities working with geospatial data. There is currently a significant gap in the absence of an application that enables research communities and Open Science stakeholders to publish, visualise, combine and extract research geospatial data in the formats desired by users, and to use them directly and openly in teaching and research. The project will focus on addressing key questions and working with research communities to better understand the needs and requirements of researchers for working with geospatial data in an open research data context. Key questions include the desired practices, data formats and standards for searching, combining, sharing and publishing open research geodata, and assessing the capabilities of existing geoportals such as GeoVITe to implement the developed ORD practices. Collaboration with the community, in particular with representatives of the geosciences, is essential to discuss and develop user-centred ORD practices. Participatory approaches aim to focus on user needs to make research geodata findable, accessible, interoperable and reusable in line with the FAIR principles. Based on the identified needs and processes, initial testing and technical implementation will be carried out on the portal. The long-term goal is to establish sustainable tools for the open research geodata community, based on existing open standards and an improved web-based geoportal.",text
value_changed,project_title,EXPLORE/OPENSPM,71,71,An ecosystem for community driven scanning probe microscopy research and development - OpenSPM,An ecosystem for community driven scanning probe microscopy research and development,text
value_changed,total_budget_requested,CONTRIBUTE/GLOVDH,15,15,29991.2,29992.0,numeric
value_changed,project_abstract,CONTRIBUTE/GLOVDH,15,15,"Geodetic Very Long Baseline Interferometry (VLBI) stands at the forefront of precise measurement of Earth's rotation and orientation.<br/><br/>At the core of geodetic VLBI operations lies the International VLBI Service for Geodesy and Astrometry (IVS), a collaborative platform that unites institutions, observatories, and research agencies worldwide.<br/><br/>Members of the IVS can submit VLBI-related files to the IVS, such as reports and logs that include a variety of performance metrics.<br/><br/>This project aims to enhance geodetic VLBI research by curating these existing performance metrics submitted to the IVS into a common database. The database will consist of three tables, monitoring performance on a session-, station-, and source basis. It will be openly available via a common web interface and an Application Programming Interface (API). The session-based database will serve as a monitoring tool for enabling swift adjustments to observing programs. For this purpose, comprehensive online plotting tools will be developed as part of the web interface. The station and source-based databases can be used to optimize observing plans by excluding poorly performing elements and prioritizing high-performing ones.<br/><br/>Thus, this project will enhance data accuracy and foster collaboration within the VLBI community. The project's technological advancements will contribute to open research data initiatives and promote scientific excellence in Earth sciences and geodesy, especially for the IVS community.","Geodetic Very Long Baseline Interferometry (VLBI) stands at the forefront of precise measurement of Earth's rotation and orientation. At the core of geodetic VLBI operations lies the International VLBI Service for Geodesy and Astrometry (IVS), a collaborative platform that unites institutions, observatories, and research agencies worldwide. Members of the IVS can submit VLBI-related files to the IVS, such as reports and logs that include a variety of performance metrics. This project aims to enhance geodetic VLBI research by curating these existing performance metrics submitted to the IVS into a common database. The database will consist of three tables, monitoring performance on a session-, station-, and source basis. It will be openly available via a common web interface and an Application Programming Interface (API). The session-based database will serve as a monitoring tool for enabling swift adjustments to observing programs. For this purpose, comprehensive online plotting tools will be developed as part of the web interface. The station and source-based databases can be used to optimize observing plans by excluding poorly performing elements and prioritizing high-performing ones. Thus, this project will enhance data accuracy and foster collaboration within the VLBI community. The project's technological advancements will contribute to open research data initiatives and promote scientific excellence in Earth sciences and geodesy, especially for the IVS community.",text
value_changed,start_date,EXPLORE/OPENWASHDATA,74,74,NA,2022-10-01,text
value_changed,main_applicant_function,EXPLORE/OPENWASHDATA,74,74,NA,Prof. Dr.; Open Science Specialist,text
value_changed,project_title,EXPLORE/OPENWASHDATA,74,74,Open WASH data by establishing Data Stewards and increasing FAIRness,Open WASH data by building Open Science Competencies and Community,text
value_changed,main_applicant_city,EXPLORE/OPENWASHDATA,74,74,NA,Zürich,text
value_changed,main_applicant_laboratory_name,EXPLORE/OPENWASHDATA,74,74,NA,Global Health Engineering,text
value_changed,main_applicant_first_name,EXPLORE/OPENWASHDATA,74,74,Elizabeth,Lars,text
value_changed,main_applicant_surname,EXPLORE/OPENWASHDATA,74,74,Tilley,Tilley; Schöbitz,text
value_changed,project_duration_months,EXPLORE/OPENWASHDATA,74,74,NA,18.0,numeric
value_changed,total_budget_requested,EXPLORE/OPENWASHDATA,74,74,15000.0,149990.0,numeric
value_changed,project_abstract,EXPLORE/OPENWASHDATA,74,74,NA,"Poor data management practices hold back progress in the Water, Sanitation, and Hygiene (WASH) sector. WASH professionals are not taught the competencies needed to manage the vast quantities of data they collect. Specifically, the activities and strategies related to the storage, organization, description, and sharing of data and other materials (i.e. data analysis code) following FAIR data principles are underused. We will approach this gap by building the openwashdata community to support members in this process. We use and teach open-source computational tools, enabling community members to further competencies aligned with FAIR data principles. We expect to publish a large number (> 50) of previously unpublished data sets shared by community members who will contribute to the process throughout the program. The result will be a growing network of WASH professionals passionate about applying FAIR data principles to their work, which will benefit everyone in the entire sector.",text
value_changed,main_applicant_postcode,EXPLORE/OPENWASHDATA,74,74,NA,8092.0,numeric
value_changed,project_abstract,CONTRIBUTE/NEST-BOT,21,21,"The built environment generates complex and heterogeneous data, categorized into 3 main types: structural and architectural information, performance data (time series of energy consumption, temperatures, or occupancy), and administrative records (contracts, costs). Despite the critical value of ORD in fostering scalable applications, significant challenges persist, including fragmented data storage, heterogeneity in standards, and inadequate metadata documentation, which complicates data contextualization and accessibility. This project, NEST-Bot, aims to address these challenges by enhancing data discoverability through an automated integration layer that populates a knowledge graph.
NEST-Bot will train a LLM to serve as an intuitive interface for stakeholders-ranging from academic researchers and data scientists to HVAC engineers, architects, and automation experts-to access NEST-related data. A key aspect of the project involves the automatic generation of the integration layer from existing repositories, allowing the LLM to retrieve complex, heterogeneous datasets via natural language queries.
This innovative approach aims to streamline data retrieval, enhance data quality, reduce redundancies, and make ORD practices more scalable and beneficial to the building sector. By linking and organizing diverse repositories, NEST-Bot will enable seamless interaction with complex datasets, establishing new standards for data integration and ORD in building automation and research.
We aim to simplify data access through a user-friendly interface, enabling stakeholders to query relevant NEST measurements via natural language. This MVP will focus on core features such as retrieving specific sensor data and providing contextual information for easier interpretation. Our goal is to enhance data contextualization, improve data discovery, and support research in building and energy management. Furthermore, we intend to lay the foundation for incorporating additional data silos into the NEST-Bot ecosystem.","The built environment generates complex and heterogeneous data, categorized into 3 main types: structural and architectural information, performance data (time series of energy consumption, temperatures, or occupancy), and administrative records (contracts, costs). Despite the critical value of ORD in fostering scalable applications, significant challenges persist, including fragmented data storage, heterogeneity in standards, and inadequate metadata documentation, which complicates data contextualization and accessibility. This project, NEST-Bot, aims to address these challenges by enhancing data discoverability through an automated integration layer that populates a knowledge graph.

NEST-Bot will train a LLM to serve as an intuitive interface for stakeholders-ranging from academic researchers and data scientists to HVAC engineers, architects, and automation experts-to access NEST-related data. A key aspect of the project involves the automatic generation of the integration layer from existing repositories, allowing the LLM to retrieve complex, heterogeneous datasets via natural language queries.

This innovative approach aims to streamline data retrieval, enhance data quality, reduce redundancies, and make ORD practices more scalable and beneficial to the building sector. By linking and organizing diverse repositories, NEST-Bot will enable seamless interaction with complex datasets, establishing new standards for data integration and ORD in building automation and research.",text
value_changed,start_date,EXPLORE/SUCCESS,76,76,NA,2024-10-01,text
value_changed,main_applicant_function,EXPLORE/SUCCESS,76,76,NA,Senior Scientist,text
value_changed,main_applicant_city,EXPLORE/SUCCESS,76,76,NA,Zürich,text
value_changed,main_applicant_laboratory_name,EXPLORE/SUCCESS,76,76,NA,Biomedical Informatics Lab,text
value_changed,project_duration_months,EXPLORE/SUCCESS,76,76,NA,18.0,numeric
value_changed,project_abstract,EXPLORE/SUCCESS,76,76,NA,"The exponential growth of biomedical sequencing data has led to considerable challenges and open problems for genomic data management, leading to limitations in accessing and utilising this vast resource efficiently. The Sequence Read Archive (SRA) exemplifies the scale of available data, housing over 40 Petabases. However, the current indexing methods, which rely on metadata rather than full-text searches, significantly limit the potential for research and discovery. The Biomedical Informatics lab at ETH Zürich has developed a computational framework capable of indexing whole sequence repositories on a petabyte scale, compressing data significantly while maintaining search efficiency. This framework, embodied in the MetaGraph software platform, represents a major technological advancement, enabling precise, large-scale genomic data analysis. The lab has applied this framework to over 4 PB of raw sequencing data, freely sharing the generated indexes to promote open research. The proposal aims to establish MetaGraph as a leading open research data tool and to build a vibrant user community around it, enhancing accessibility and utility of genomic data. This initiative seeks to break down barriers to data access, fostering a more open, collaborative research environment, and expanding the scope of MetaGraph beyond DNA to include non-DNA repositories, addressing privacy and ethical considerations in data accessibility, and contributing to the democratisation of genomic data.",text
value_changed,main_applicant_postcode,EXPLORE/SUCCESS,76,76,NA,8092.0,numeric
value_changed,project_abstract,CONTRIBUTE/FACILITATE,11,11,"In recent years, a “reproducibility crisis” has been identified in different scientific domains, including biomedical sciences . Open science practices address some aspects of this crisis and are increasingly required by funders, journals, and institutions. Consequently, data should be findable, accessible, interoperable, and reusable (FAIR). However, reproducibility is not guaranteed by FAIR data sharing alone, but also requires a fully defined computational environment including all dependencies for the interpretation of data and generation of publishable results.<br/>To enable full reproducibility, we developed a Reproducible Research Platform (RRP), which encapsulates FAIR research data, code, and the computational environment. Our RRP is based on established open-source tools to manage FAIR data (openBIS ELN-LIMS), code (git), and computational environment (repo2docker), and interacts through JupyterLab. Here, we propose to contribute an extension to easily share projects with all required data and computational components from our RRP with third parties (other research groups, public). We anticipate that sharing RRP projects will finally enable full reusability by allowing others to reproduce, but also modify and extend previous work. Anticipated users include collaborators within and between institutions, authors and reviewers, students and supervisors, and the general public","In recent years, a “reproducibility crisis” has been identified in different scientific domains, including biomedical sciences . Open science practices address some aspects of this crisis and are increasingly required by funders, journals, and institutions. Consequently, data should be findable, accessible, interoperable, and reusable (FAIR). However, reproducibility is not guaranteed by FAIR data sharing alone, but also requires a fully defined computational environment including all dependencies for the interpretation of data and generation of publishable results.
To enable full reproducibility, we developed a Reproducible Research Platform (RRP), which encapsulates FAIR research data, code, and the computational environment. Our RRP is based on established open-source tools to manage FAIR data (openBIS ELN-LIMS), code (git), and computational environment (repo2docker), and interacts through JupyterLab. Here, we propose to contribute an extension to easily share projects with all required data and computational components from our RRP with third parties (other research groups, public). We anticipate that sharing RRP projects will finally enable full reusability by allowing others to reproduce, but also modify and extend previous work. Anticipated users include collaborators within and between institutions, authors and reviewers, students and supervisors, and the general public",text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/PYSPM,31,31,EPFL STI IBI-STI LBNI,EPFL STI IBI-STI LBNI (Laboratory for Bio- and Nano-Instrumentation),text
value_changed,project_abstract,CONTRIBUTE/PYSPM,31,31,"Storing acquired data is a crucial step in every research cycle. Nowadays, instruments tend to discard most of the acquired data by down-sampling or discarding most of the signal via averaging or decimation. Saved data is normally stored into proprietary file formats, which limits the data exchange among the scientific community. It also impedes adding or modifying necessary metadata to keep important information about experiment parameters or instrument status, and hinders the use of existing post processing routines written for different file formats, leading to duplicated codes and preventing the exchange of routines among researchers.

Open-source data schemes are becoming increasingly important for scientific data storage. They enable sharing of software, data, and knowledge at early phases in the scientific process, maintain the digital integrity of the data at lower cost, and facilitate long-term preservation and future data mining through metadata. Developing software as open source allows modules to be readily shared, reused and extended by others. By choosing appropriate storage file open standards, it is possible to maximize available analysis tools and resources, reduce the cost of data manipulation and maintenance, and achieve ideal long-term preservation of large amounts of files.

In this project, we aim to implement the HDF5 and USID open standards on an already well-established ORD worldwide project at EPFL: the Open-Source SPM controller. Its current file scheme presents several weaknesses that we intend to overcome with these modern standards. Furthermore, the implementation of this scheme will enable access to a lively open software ecosystem called Pycroscopy, allowing the Open-Source SPM project to take advantage of all the functionalities and tools already existing in that ecosystem based on the HDF5 and USID open standards.","Open-source data schemes are becoming increasingly important for scientific data storage. They enable sharing of software, data, and knowledge at early phases in the scientific process, as well as proper long-term preservation storage. In this project, we aim to implement the HDF5 and USID open standards on an already well-established ORD worldwide project at EPFL: the Open-Source SPM controller. Its current file scheme presents several weaknesses that we intend to overcome with those modern standards. Furthermore, the implementation of this scheme will enable the access to a lively open software ecosystem called Pycroscopy, where the Open-Source SPM project will take advantage of all the functionalities and tools already existing on that ecosystem based on the HDF5 and USID open standards.",text
value_changed,total_budget_requested,CONTRIBUTE/STILLBERGDAT,37,37,29953.0,29853.0,numeric
value_changed,main_applicant_laboratory_name,CONTRIBUTE/MAST,18,18,EPFL ENAC IIC EESD,"Earthquake Engineering and Structural Dynamics Laboratory (EESD), EPFL ENAC IIC",text
value_changed,start_date,CONTRIBUTE/FAIR-CITIES,12,12,2025-01-01,NA,text
value_changed,main_applicant_function,CONTRIBUTE/FAIR-CITIES,12,12,Assistant Professor (tenure-track),NA,text
value_changed,project_title,CONTRIBUTE/FAIR-CITIES,12,12,FAIRifying Urban Climate Modeling for Greening Cities (FAIR-CITIES),NA,text
value_changed,main_applicant_city,CONTRIBUTE/FAIR-CITIES,12,12,Lausanne,NA,text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/FAIR-CITIES,12,12,EPFL ENAC IA URBES,NA,text
value_changed,main_applicant_first_name,CONTRIBUTE/FAIR-CITIES,12,12,Gabriele,NA,text
value_changed,main_applicant_surname,CONTRIBUTE/FAIR-CITIES,12,12,Manoli,NA,text
value_changed,project_duration_months,CONTRIBUTE/FAIR-CITIES,12,12,12.0,NA,numeric
value_changed,project_acronym,CONTRIBUTE/FAIR-CITIES,12,12,FAIR-CITIES,NA,text
value_changed,total_budget_requested,CONTRIBUTE/FAIR-CITIES,12,12,30000.0,NA,numeric
value_changed,main_applicant_institution,CONTRIBUTE/FAIR-CITIES,12,12,EPFL,NA,text
value_changed,project_abstract,CONTRIBUTE/FAIR-CITIES,12,12,"This project aims to translate the UT&C model to an open-source programming language which concurrently enables high computational efficiency and modularity. UT&C is a widely used urban climate model with a detailed vegetation scheme, thus being the perfect tool to inform urban greening strategies in cities around the world. However, the current code is written in a proprietary language and it is computationally heavy. By translating the UT&C code into Python and making it more open, FAIR, and user-friendly, this project will open up to new scientific opportunities (e.g., city-scale simulations, model coupling), facilitate a community-based development, and increase its accessibility to the broader urban climate and urban planning communities.",NA,text
value_changed,main_applicant_postcode,CONTRIBUTE/FAIR-CITIES,12,12,1015.0,NA,numeric
value_changed,main_applicant_laboratory_name,EXPLORE/DCSM,53,53,EPFL ENAC IIC LSMS,Computational Solid Mechanics Laboratory (EPFL ENAC IIC LSMS),text
value_changed,main_applicant_surname,EXPLORE/DCSM,53,53,Anciaux,Molinari,text
value_changed,start_date,EXPLORE/OPEN-ACTRIS,67,67,2024-09-01,NA,text
value_changed,main_applicant_function,EXPLORE/OPEN-ACTRIS,67,67,Senior scientist,NA,text
value_changed,project_title,EXPLORE/OPEN-ACTRIS,67,67,OPEN-ACTRIS: Building FAIR data chains for atmospheric observations in the ACTRIS-Switzerland network.,NA,text
value_changed,main_applicant_city,EXPLORE/OPEN-ACTRIS,67,67,Villigen,NA,text
value_changed,main_applicant_laboratory_name,EXPLORE/OPEN-ACTRIS,67,67,Laboratory of Atmospheric Chemistry,NA,text
value_changed,main_applicant_first_name,EXPLORE/OPEN-ACTRIS,67,67,Robin,NA,text
value_changed,main_applicant_surname,EXPLORE/OPEN-ACTRIS,67,67,Modini,NA,text
value_changed,project_duration_months,EXPLORE/OPEN-ACTRIS,67,67,12.0,NA,numeric
value_changed,project_acronym,EXPLORE/OPEN-ACTRIS,67,67,OPEN-ACTRIS,NA,text
value_changed,total_budget_requested,EXPLORE/OPEN-ACTRIS,67,67,150000.0,NA,numeric
value_changed,main_applicant_institution,EXPLORE/OPEN-ACTRIS,67,67,PSI,NA,text
value_changed,project_abstract,EXPLORE/OPEN-ACTRIS,67,67,"The OPEN-ACTRIS project aims to explore and build up FAIR data chain standards and strategies for atmospheric observations collected in Switzerland as part of the Aerosol, Clouds and Trace Gases Research Infrastructure (ACTRIS). ACTRIS is a pan-European network that aims to deepen our understanding of climate change and air pollution by producing high-quality data on short-lived atmospheric constituents. ACTRIS-Switzerland is the multi-institutional Swiss node of the network. ACTRIS has a comprehensive vision for FAIR data that covers all stages of the research data life cycle through the definition of data levels covering raw measurements, processed data, and elaborated data products. The OPEN-ACTRIS project aims to implement these ORD concepts in the ETH domain and to explore best ORD practice within ACTRIS-Switzerland by combining existing tools and infrastructure from the ETH domain and the ACTRIS community. We will achieve this by building FAIR data chains for the aerosol observations continuously recorded at field measurement stations on the Jungfraujoch and in Payerne, and for the aerosol and gas measurements performed on a campaign-basis in the PSI Atmospheric Chemistry Simulation Chambers.",NA,text
value_changed,main_applicant_postcode,EXPLORE/OPEN-ACTRIS,67,67,5232.0,NA,numeric
value_changed,main_applicant_function,EXPLORE/GENDIB-ORD,59,59,Dr.,Project leader DNL,text
value_changed,total_budget_requested,EXPLORE/GENDIB-ORD,59,59,150000.0,75000.0,numeric
value_changed,start_date,CONTRIBUTE/PHENOMAST,29,29,NA,2022-10-01,text
value_changed,main_applicant_function,CONTRIBUTE/PHENOMAST,29,29,NA,Scientific staff member,text
value_changed,main_applicant_city,CONTRIBUTE/PHENOMAST,29,29,NA,Birmensdorf,text
value_changed,main_applicant_laboratory_name,CONTRIBUTE/PHENOMAST,29,29,NA,Disturbance Ecology,text
value_changed,project_duration_months,CONTRIBUTE/PHENOMAST,29,29,NA,12.0,numeric
value_changed,project_abstract,CONTRIBUTE/PHENOMAST,29,29,NA,"Most of the dominant tree species in Switzerland do not produce a constant amount of seeds from year to year but rather show a regular pattern of massive seed production every few years followed by years with no seed production, i.e. they exhibit a masting behaviour. Seed mast dynamics have a strong influence not only on tree regeneration but also on population dynamics across the food web. The timing and interval of seed masts are controlled by diverse environmental triggers and are changing in the recent warming decades. Given the ecosystem-wide impacts of seed mast it is not surprising that in recent years, the processes underlying forest regeneration have gained considerable attention in the scientific literature. Nevertheless, many networks and field surveys focusing on phenology often ignore seed mast. We plan to organize a workshop bringing together managers from different existing phenological networks in order to contribute and integrate an ORD protocol for collecting seed mast data obeying elaborated standards within these observation networks (programs). Based on this standardized and simple method, seed mast data can be collected within existing phenology networks to benefit researchers from different fields, including modellers, physiologists and ecologists. The collected data will be curated and made publicly available on the ORD platform of MastWeb facilitating collaborations with other European- or worldwide phenology networks.",text
value_changed,main_applicant_postcode,CONTRIBUTE/PHENOMAST,29,29,NA,8903.0,numeric
