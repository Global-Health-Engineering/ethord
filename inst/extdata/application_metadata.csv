project_id,project_category,main_applicant_institution,main_applicant_function,main_applicant_first_name,main_applicant_surname,main_applicant_laboratory_name,main_applicant_postcode,main_applicant_city,project_title,project_acronym,project_abstract,start_date,project_duration_months,total_budget_requested
CONTRIBUTE/API-MOSAIC,Contribute,ETH Zürich,Post-doctoral researcher,Sarah,Paradis,Biogeoscience,8092,Zürich,Application Programming Interface for the Modern Ocean Sedimentary Inventory and Archive of Carbon database. (API-MOSAIC),API-MOSAIC,"The increasing use of data repositories in marine geosciences has led to large, albeit dispersed and unstandardized datasets that require large amounts of time and effort to compile and harmonize. To overcome this, the Modern Ocean Sediment Archive and Inventory of Carbon (MOSAIC) database was devised to understand the factors that affect the distribution of the quantity, origin and reactivity of organic carbon in marine sediments, a key component of the global carbon cycle of growing interest with respect to carbon stocktaking and ecosystem services. Over the last year, MOSAIC has quadrupled its spatiotemporal coverage, increased by ten-fold the number of variables it contains, and it is currently stored as a PostgreSQL spatial relational database. The complexity of this expanding database requires it to be dynamically queried through a user-friendly interface. Hence, this project aims to improve the accessibility to the database by creating an Application Programming Interface (API). This will be achieved by building an interactive and user-friendly web-interface that allows users to query MOSAIC. Finally, Python and R packages will also be built that allow researchers to incorporate MOSAIC in their data analysis and processing workflows, ensuring reproducibility of their findings. This project will provide accessibility of the database to users with different backgrounds and interests, building on Open Research Data practices in marine geosciences.",2023-03-01,12,30000
CONTRIBUTE/API-ROGER,Contribute,ETH Zürich,Dr.,Sarah,Paradis,Environmental Physics Group,8092,Zürich,Application Programming Interface for the River to Ocean Geodatabase for Education and Research,API-ROGER,"In order to advance our understanding of the carbon cycle, it is essential to evaluate the spatiotemporal variations of carbon between river and marine environments and gain insights into the pathways of carbon transfer from land to ocean. To do this, we need to work jointly with riverine and marine data, accounting for their temporal and spatial distribution. However, each of these systems have different data and metadata reporting strategies that need to be accounted for, which complicates their joint application. Efforts have been made to compile data from each of these systems into independent databases, but no attempt has yet been done to create a joint database of data of both of these systems while accounting for their different metadata. Hence, this project aims to bring together riverine and marine data into one database to easily query the data between both systems through the River to Ocean Geodatabase for Education and Research (ROGER). This database will be displayed in an interactive web-interface that queries riverine and/or marine data depending on the user’s requirements through a REST API. Harnessing the advanced geographical functions of PostgreSQL, the REST API will include functions that allow users to geospatially integrate riverine and marine data. This new database will provide a crucial step forward in the understanding of the carbon cycle along the land-ocean continuum, while ensuring that the data complies with best Open Research Data practices.",2025-01-01,12,30000
CONTRIBUTE/BOOST4EPILEPSY,Contribute,EPFL,Full Professor,David,Atienza,EPFL STI IEM ESL,1015,Lausanne,Boost for the validation of seizure detection algorithms with ORD (Boost4Epilepsy),Boost4Epilepsy,"In the last decade several initiatives have made annotated scalp EEG datasets of people with epilepsy available to researchers around the world. However, the format of the data varies between datasets. This heterogeneity of data along with a heterogeneity of methods used by researchers to validate algorithms makes comparison of algorithms difficult, ranking the best algorithms impossible and ultimately significantly hinders the research progress.This proposal builds on ORD datasets and community guidelines and standards to propose a unified framework for the validation of seizure detection algorithms. The main objective is the development of tools and standards that will unify the workflow for the validation of seizure detection algorithms in order to make data for seizure detection adhere to the principles of Findable, Accessible, Interpretable and Reusable data.To build this framework we will be contributing to Open Research Data by curating existing public annotated datasets, by standardising the data format of these different datasets. For these standards we will develop software tools that convert the original datasets to this standardised format. We will standardise the methodology to evaluate algorithms in order to build a benchmark state of the art algorithms.We will centralise all this knowledge, datasets, standards tools and benchmark on a website that will help to speed the development of seizure detection algorithms.",2023-10-01,12,30000
CONTRIBUTE/BOSTORD,Contribute,ETH Zürich,Assistant Professor,Nicholas,Bokulich,Food Systems Biotechnology,8092,Zurich,BOSTORD: Building Open-Source Tools for reproducible interaction with biological ORD databases,BOSTORD,"The life sciences are increasingly reliant on access to and use of centralized online databases for exchanging biological information (e.g., NCBI, EBI, MGnify) (EBI, 2022; NCBI, 2022c; Mitchell et al., 2020). These databases allow researchers to share diverse primary (raw) and secondary (processed) biological datasets, allowing downstream re-use. However, significant rate-limiting steps to scientific discovery are (a) technical challenges for users depositing or withdrawing open research data (ORD) from these datasets, and (b) the poor control, traceability, and reproducibility of some steps involved in interacting with and downstream use of these ORD resources. We propose developing ORD tools (software) to facilitate remote, programmatic, and fully FAIR/reproducible interaction with several leading ORD resources that are commonly used in the biological sciences. These will eliminate current barriers to ORD sharing, (re-)use, and practices, and encourage community engagement in ORD practices. In this “contribute” project we will specifically contribute ORD tools for the microbiome research domain, but the mutli-disciplinarity of this field will position our project outcomes to translate to other research domains. This fits the criteria for the Contribute program, as we contribute software tools to facilitate interaction with and re-use of ORD from established ORD databases.",2023-04-01,12,30000
CONTRIBUTE/BRAINSCOREHUMAN,Contribute,EPFL,Tenure-Track Assistant Professor,Martin,Schrimpf,EPFL SV INX-SV UPSCHRIMPF1,1015,Lausanne,BRAINSCOREHUMAN – Making Brain and Behavior Data Accessible for Modelling via Brain-Score,BRAINSCOREHUMAN,"Brain-Score is a fast-growing platform which curates a diverse set of neural and behavioral measurements from non-human primate neuroscience experiments and facilitates its use in evaluating computational models of the brain's visual system. By translating models from machine learning into neuroscientific hypotheses, and neuroscience data into quantitative benchmarks to evaluate such models, Brain-Score makes computational as well as experimental advances available to the broader community in a synergistic manner. In this proposal, we aim to broaden the scope of Brain-Score to data from human experiments which will open the platform to the cognitive neuroscience community and make computational models more broadly applicable.<br/><br/>Specifically, we will:- Contribute new software to the Brain-Score platform to enable it to work with human data. This involves defining new endpoints for computational models to align with human brain anatomy and a common experimental behavioral task.
- Curate the Natural Scenes Dataset (NSD, Allen et al. 2022) for Brain-Score such that it is accessible for reproducible model evaluations. NSD is a large-scale dataset of human whole-brain recordings in response to thousands of natural images.
- Curate the THINGS-similarity dataset (Hebart et al. 2020) for addition into Brain-Score to make it accessible and reproducible for model evaluations. THINGS-similarity is a human behavioral dataset of millions of similarity judgments for thousands of images.",2023-08-01,12,30000
CONTRIBUTE/BRAINSCORETMPRL,Contribute,EPFL,Tenure-Track Assistant Professor,Martin,Schrimpf,EPFL SV INX-SV UPSCHRIMPF1,1015,Lausanne,BRAINSCORETEMPORAL – Making Temporal Brain Recording Accessible For Modeling via Brain-Score,BRAINSCORETMPRL,"Brain-Score is an established platform which curates a diverse set of neural and behavioral measurements from neuroscience experiments and facilitates its use in modeling the brain's visual system. By making experimental data accessible to the modeling community in the form of quantitative benchmarks, Brain-Score allows modelers to evaluate computational hypotheses on a broad range of biological data without having to know the details of each experiment. In this proposal, we aim to broaden the scope of Brain-Score model comparisons from the presentation of static images to video inputs. This will enable the modeling of a critical axis of brain processing in visual cortex that has not yet been explored.

Specifically, we will:

* Contribute new software to Brain-Score to enable the platform to work with temporal data. This involves defining a unified interface for how to provide models with video input, and adding candidate video models from the machine learning community.

* Curate published temporal datasets for Brain-Score. Without Brain-Score, even these public data are often difficult to use for model testing.

* Curate new primate recordings from experimental collaborators (MIT DiCarlo lab) for Brain-Score such that they are accessible for model evaluations. These are among the first electrode recordings in the visual ventral stream where the stimuli are short ecological video clips.",2024-03-01,12,30000
CONTRIBUTE/CA ORD,Contribute,EPFL,"Collaborateur scientifique-fct. dirigeant, Director Gr-ACM",Salvatore,Aprea,EPFL ENAC IA GR-ACM,1015,Lausanne,Contemporary Architecture Open Research Data (CA ORD),CA ORD,"The Groupe ACM (Gr-ACM) is a research group responsible for the collection of architecture heritage archives known as the Archives de la construction moderne (ACM). Digital contents in architecture heritage archives is increasing and will increase in the future both through donations of new born-digital archives and digitization campaigns of paper archives. Through the CA ORD Project, the Gr-ACM aims to improve its capacity to preserve and make FAIRly available data and metadata from digital architecture archives (both born-digital and digitized from paper). To date, the Gr-ACM has collected 4 Tb of digital data made of files in different formats (.dwg, .dxf, .pln, .jpg, .pdf, etc.) stored on external hard drives and CD-Rs, which are therefore unavailable for research. The CA ORD Project aims to fill this gap. It is about installing, configuring, and running the open-source software Archivematica, which is an archiving system based on a multi-services architecture, that allows for automation, extraction, and normalization of data and metadata. These (METS files) will be made available on the already existing ACM’s ORD AtoM-based portal Morphé, since Archivematica and Atom are interoperable. Thanks to readily exploitable data, the CA ORD Project will enlarge the ACM users community (currently limited to historians) including new researchers from the fields of architecture, engineering and land management.",2024-09-01,12,30000
CONTRIBUTE/CATCHARACTPROVI,Contribute,ETH Zürich,Scientist,Erwin,Lam,Swiss Cat+ East,8093,Zürich,Catalysis Characterization Processing and Visualization Tools for Large Open Research Data,CatCharactProVi,"Catalysts play a major role in the production of many chemicals that are used everyday. Their proper characterization allows to understand their properties and therefore enables a rational design of better performing catalysts. Therefore, having large amounts of open access characterization data of catalysts will enable more efficient data/machine learning driven approaches to understand catalysts at a higher level and further speed up the design of better performing catalysts. However, although a wide variety of catalyst characterization data and open access repositories are available, one missing link is the proper and standardized data processing step complying to the FAIR principles prior to the upload to open access repositories.At Swiss Cat+, an ETH domain technology platform, large amounts of data related to catalyst characterization are generated with the help of automated high-throughput technologies. Therefore the aim of the proposal is to implement additional components within the ETHZ Swiss Cat+ ORD Roadmap to have streamlined and standardized catalysis characterization data processing, and visualization tools within and beyond Swiss Cat+. This implementation will fully unlock the potential of using catalysis characterization data that are generated globally.",2024-08-01,12,30000
CONTRIBUTE/ENVIPATH+EDGEBP,Contribute,Eawag,Group leader,Serina,Robinson,Microbial Specialized Metabolism,8600,Duebendorf,Prediction of biodegradation potential from (meta)genomes: advancing the enviPathPlus ORD platform,enviPath+EDGEbp,"Chemical pollution has exceeded planetary boundaries, requiring urgent solutions for chemical waste removal. Microbial biodegradation processes are crucial for breaking down chemical contaminants, yet the functions of microbial communities are often challenging to predict. To address this challenge, we aim to contribute a new pipeline, EDGEbp (Enabling Detection of metaGEnomic biodegradation potential), to advance the research capabilities of the ORD biodegradation prediction software, enviPathPlus. Specifically, in EDGEbp, we will build a Hidden Markov Model-based pipeline to identify biodegradation genes and pathways from total microbial community DNA (metagenomic) sequencing data. EDGEbp will output confidence scores to infer the ‘contaminant biodegradation potential’ of a given microbial community based on sequencing information. In other words, our aim is to build a tool to convert unintelligible DNA sequences into easily-understood biodegradation confidence scores. This will help us infer the capabilities of a specific microbiome to transform chemical contaminants. This project will therefore advance the sustainable development goals of improving water quality by reducing chemical pollution through microbial biodegradation. Overall, we anticipate that EDGEbp will expand the cutting-edge functionalities of the ORD tool enviPathPlus to support its long-term preservation and promote community engagement in line with ORD principles.",2024-03-01,12,15000
CONTRIBUTE/FACILITATE,Contribute,ETH Zürich,Senior Scientist,Hans-Michael,Kaltenbach,Computational Systems Biology,4058,Basel,"FACILITATE - FAIR and reproducible sharing of data, code and computational environment",FACILITATE,"In recent years, a “reproducibility crisis” has been identified in different scientific domains, including biomedical sciences . Open science practices address some aspects of this crisis and are increasingly required by funders, journals, and institutions. Consequently, data should be findable, accessible, interoperable, and reusable (FAIR). However, reproducibility is not guaranteed by FAIR data sharing alone, but also requires a fully defined computational environment including all dependencies for the interpretation of data and generation of publishable results.<br/>To enable full reproducibility, we developed a Reproducible Research Platform (RRP), which encapsulates FAIR research data, code, and the computational environment. Our RRP is based on established open-source tools to manage FAIR data (openBIS ELN-LIMS), code (git), and computational environment (repo2docker), and interacts through JupyterLab. Here, we propose to contribute an extension to easily share projects with all required data and computational components from our RRP with third parties (other research groups, public). We anticipate that sharing RRP projects will finally enable full reusability by allowing others to reproduce, but also modify and extend previous work. Anticipated users include collaborators within and between institutions, authors and reviewers, students and supervisors, and the general public",2023-06-01,12,30000
CONTRIBUTE/FAIR-CITIES,Contribute,EPFL,Assistant Professor (tenure-track),Gabriele,Manoli,EPFL ENAC IA URBES,1015,Lausanne,FAIRifying Urban Climate Modeling for Greening Cities (FAIR-CITIES),FAIR-CITIES,"This project aims to translate the UT&C model to an open-source programming language which concurrently enables high computational efficiency and modularity. UT&C is a widely used urban climate model with a detailed vegetation scheme, thus being the perfect tool to inform urban greening strategies in cities around the world. However, the current code is written in a proprietary language and it is computationally heavy. By translating the UT&C code into Python and making it more open, FAIR, and user-friendly, this project will open up to new scientific opportunities (e.g., city-scale simulations, model coupling), facilitate a community-based development, and increase its accessibility to the broader urban climate and urban planning communities.",2025-01-01,12,30000
CONTRIBUTE/FIRE,Contribute,EPFL,PostDoc,Aurèle,Barrière,EPFL IC IINFCOM SYSTEMF,1015,Lausanne,Open Mechanized Foundations for JavaScript Regular Expressions (FiRE),FiRE,"One of the main forms of ORD in the programming languages research community is two-sided mechanized language specifications (the definition in a proof assistant of the semantics of a language). These mechanized specifications have many benefits: they can be extracted to an executable reference implementation, and used by both implementers (to verify compilers, interpreters and optimizations) and by users (to guarantee the correctness of programs in that programming language).We propose to contribute the first open, two-sided, mechanized specification of JavaScript regular expressions (regexes). The lack of such mechanization is harming the research community: previous work has mechanized other parts of the JavaScript language but not regexes, and as a consequence researchers use paper-only semantics for JavaScript regexes. These paper semantics are neither executable nor reusable and often incorrect. We will translate to Coq the part of the open ECMAScript standard that describes JavaScript regexes; extract this mechanization to a reference implementation in OCaml; and validate our mechanization with Coq proofs.Our project will provide a solid foundation for JavaScript regex research to build upon our Coq mechanization, including proving the correctness of regex optimizations, detecting regexes with security issues (ReDOS), or proving the correctness of entire regex engines. Our project will allow the open JavaScript community to test their regex engines.",2024-02-13,12,30000
CONTRIBUTE/FLAKE,Contribute,EPFL,Operational Director,Natacha,Tofield-Pasche,EPFL ENAC LIMNC,1015,Lausanne,FAIRifying LéXPLORE: enhancing open research data pipelines for Advanced LaKe SciencE,FLAKE,"LéXPLORE platform (LP) is as an innovative, open-water infrastructure on Lake Geneva, where multidisciplinary data are acquired at high frequency. Datalakes (DL) is a web-based open access data platform that provides, for LP, seven datasets in real-time. We have identified two challenges that could limit the FAIR approach to the data. This project aims at addressing them by: a) enhancing the robustness of the LP data transfer pipelines and b) enhancing DL data quality by prototyping a collaborative QA/QC Solution. The first objective is to strengthen the LP data pipeline by decoupling the data gathering from the data processing functions. The resulting simplified distribution of responsibilities will facilitate long-term maintenance and secure the system's long-term reliability. The second objective aims at designing a prototype of a collaborative QA/QC tool. For this, we will collaborate closely with the LP community, by organising two workshops and a QA/QC hackathon. The developed prototype will allow domain experts to efficiently assess and flag data quality issues, in order to improve accuracy and reliability of sensor data. This project will involve the operational LP team, the DL core developers, and research software engineers from ENAC-IT4R. The proposed improvements will help to strategically maintain and elevate LP's high scientific impacts in the long-term. DL will continue to guide the lake research community towards embracing Open Research Data practices.",2025-01-01,6,30000
CONTRIBUTE/GLOVDH,Contribute,ETH Zürich,Postdoktorand,Matthias,Schartner,Chair of Space Geodesy,8093,Zürich,Global Geodetic VLBI Data Hub (GloVDH),GloVDH,"Geodetic Very Long Baseline Interferometry (VLBI) stands at the forefront of precise measurement of Earth's rotation and orientation.<br/><br/>At the core of geodetic VLBI operations lies the International VLBI Service for Geodesy and Astrometry (IVS), a collaborative platform that unites institutions, observatories, and research agencies worldwide.<br/><br/>Members of the IVS can submit VLBI-related files to the IVS, such as reports and logs that include a variety of performance metrics.<br/><br/>This project aims to enhance geodetic VLBI research by curating these existing performance metrics submitted to the IVS into a common database. The database will consist of three tables, monitoring performance on a session-, station-, and source basis. It will be openly available via a common web interface and an Application Programming Interface (API). The session-based database will serve as a monitoring tool for enabling swift adjustments to observing programs. For this purpose, comprehensive online plotting tools will be developed as part of the web interface. The station and source-based databases can be used to optimize observing plans by excluding poorly performing elements and prioritizing high-performing ones.<br/><br/>Thus, this project will enhance data accuracy and foster collaboration within the VLBI community. The project's technological advancements will contribute to open research data initiatives and promote scientific excellence in Earth sciences and geodesy, especially for the IVS community.",2024-02-01,9,29991.2
CONTRIBUTE/GPM-API,Contribute,EPFL,PhD Student,Gionata,Ghiggi,EPFL ENAC IIE LTE,1020,Renens,GPM-API: A Python Interface to Access the Global Precipitation Measurement Mission Satellites Open Data Archive,GPM-API,"This proposal aims to finalize a software (GPM-API) to increase the findability and accessibility of the satellites’ measurements from the Global Precipitation Measurement Mission (GPM).<br/><br/>To this end, an Application Programming Interface (API) has been developed to facilitate the download, processing, manipulation, and visualization of such heterogenous data archive which sizes several petabytes.<br/><br/>The GPM archive is composed of various product Levels, ranging from raw measurements collected by a constellation of 34 passive microwave sensors and 2 weather radars (L1), intermediate geophysical retrieval products (L2), to multi-satellites merged datasets (L3) which provides a global 25-year legacy data records of precipitation.<br/><br/>The GPM-API provides a simple-to-use interface to search and download the GPM files of interest, to open the satellite products with a single line of code in an analysis-ready-data format following the Climate and Forecast (CF) conventions, as well as to facilitate the distributed processing of the data archive to gain in computational efficiency.<br/><br/>In conclusion, this project will enable to openly share the GPM-API, so that it will (1) considerably increase scientist productivity by eliminating the weeks/months currently required for satellite data wrangling, (2) widen the GPM users’ community, and (3) make the GPM archive easily exploitable also for educational purposes.",2023-07-03,6,30000
CONTRIBUTE/GRAND TOUR,Contribute,ETH Zürich,Prof,Marco,Hutter,Robotic Systems Lab,8092,Zurich,Fostering Research on Mobile Robotics with High-Quality Data and Open Tooling (GrandTour),Grand Tour,"Mobile ground robots have become increasingly popular in academia and various industrial applications. However, unlike other domains like aerial robotics, autonomous driving, and construction, there is currently no high-quality, large-scale dataset or reliable benchmark established in this field, nor the tooling available to do so. Creating such a dataset would be immensely valuable for researchers and developers in fostering research on robust and practical algorithms across diverse environments. Moreover, the development of a standardized benchmarking platform would promote fair comparisons between different approaches, fostering innovation and facilitating the rapid progress of mobile ground robot research. Motivated by this, we propose to collect and share a high-quality, versatile, large-scale robotic dataset, “GrandTour”, with scalable and automated tooling– focusing on legged robots in addition to a set of benchmarks and the necessary tooling.",2024-03-01,12,30000
CONTRIBUTE/MAST,Contribute,EPFL,PhD Student,Mathias,Haindl Carvallo,EPFL ENAC IIC EESD,1015,Lausanne,MAST (MAsonry Shake-Table database) - A comprehensive database and collaborative resource for advancing seismic assessment of unreinforced masonry buildings,MAST,"Every year, building collapses due to earthquakes cause thousands of deaths. Due to the lack of design to resist seismic forces, unreinforced masonry buildings are very prone to collapse. By developing an open-access web-based platform that will contain the first-ever consolidated database for shake-table tests on complete unreinforced masonry buildings, this project aims to contribute to addressing this critical issue. The platform will make comprehensive data from over seventy experimental campaigns conducted over the last 30 years easily accessible to the earthquake engineering community, including researchers and practitioners. As a result, by facilitating data exchange and collaboration, this platform will play a key role in advancing our understanding of the seismic behavior of unreinforced masonry structures. The platform may be used by researchers and practitioners as a valuable reference to benchmark their models, enhance predictive capabilities, and encourage improved design and retrofitting practices. Overall, the development of this platform has enormous potential to reduce seismic risk and increase the resilience of unreinforced masonry buildings, hence increasing public safety in earthquake-prone areas.",2023-10-01,7,30000
CONTRIBUTE/MISHMASH,Contribute,ETH Zürich,Doctoral Student,Lina,Kim,Food Systems Biotechnology,8006,Zürich,MiShMASh: Microbiome sequence and metadata availability standards,MISHMASH,"The emerging field of microbiome research is driven by large-scale, high-dimensional datasets. Unrestricted access to sequence data and metadata is necessary for scientific innovation and re-use, and is consequently required by the scientific community, certain journals, and funding agencies.<br/><br/>Unfortunately, many microbiome studies suffer from poor data accessibility and metadata interoperability, hampering scientific advancement.<br/><br/>The project aims to close open research data (ORD) gaps in the microbiome field by addressing (1) the ineffectiveness of sequence data availability statements, which leads to poor reporting, reproducibility, and re-use; and (2) lack of consistent metadata standards for annotating microbial ORD.<br/>We propose a two-pronged solution in (1) developing a tier-based FAIR ORD standard for the field, and (2) building software to assess adherence to FAIR ORD standards. This project would contribute open resources intended for use by a diverse range of users, including researchers, journals, and funding agencies.<br/><br/>Combined with the tier-based system, validation software will enable users to assess how well microbiome studies meet data availability and metadata standards. The tools and guidelines developed here will improve sequence data and metadata reporting practices for greater accessibility, interoperability, and future re-use.",2022-10-01,12,30095
CONTRIBUTE/MMS,Contribute,EPFL,Mr.,Mati Ullah,Shah,EPFL ENAC IIC EESD,1015,Lausanne,MMS (Masonry MicroStructures database) - A 3D masonry microstructures database for advancing numerical research on irregular stone masonry structures,MMS,"Stone masonry is an eco-friendly construction material, but its use has declined due to its vulnerability to earthquakes, mainly because of the poor arrangement of its microstructure. The microstructure includes the shape, size, and arrangement of stone units, which vary based on geographic, temporal, and material factors. Current building codes cannot fully account for this variability, and experimental studies are costly and impractical due to the diversity of masonry typologies. Numerical studies offer a solution, but creating realistic microstructures for modeling irregular stone masonry is complex and time-consuming. As a result, simplified microstructures are often used in simulations, which fail to capture the complexities of irregular masonry walls. To address this challenge, we have developed a 3D masonry microstructures database ready to use in numerical simulations. To enhance accessibility and usability, this project aims to create a web-based platform hosting this curated database of 3D microstructures and their geometric indices. The proposed web-based platform will also feature a tool for evaluating masonry quality using the Masonry Quality Index (MQI) from 2D images, promoting the preservation of historic structures and sustainable construction practices. Additionally, the platform will enable researchers to contribute and document new 3D microstructures, fostering collaboration and advancing numerical research on stone masonry.",2024-12-01,6,30000
CONTRIBUTE/NEST-BOT,Contribute,Empa,Deputy Lab Head,Philipp,Heer,Urban Energy Systems Lab,8600,Dübendorf,Integrating and Enhancing Building Data for Advanced Research: NEST-Bot,NEST-Bot,"The built environment generates complex and heterogeneous data, categorized into 3 main types: structural and architectural information, performance data (time series of energy consumption, temperatures, or occupancy), and administrative records (contracts, costs). Despite the critical value of ORD in fostering scalable applications, significant challenges persist, including fragmented data storage, heterogeneity in standards, and inadequate metadata documentation, which complicates data contextualization and accessibility. This project, NEST-Bot, aims to address these challenges by enhancing data discoverability through an automated integration layer that populates a knowledge graph.
NEST-Bot will train a LLM to serve as an intuitive interface for stakeholders-ranging from academic researchers and data scientists to HVAC engineers, architects, and automation experts-to access NEST-related data. A key aspect of the project involves the automatic generation of the integration layer from existing repositories, allowing the LLM to retrieve complex, heterogeneous datasets via natural language queries.
This innovative approach aims to streamline data retrieval, enhance data quality, reduce redundancies, and make ORD practices more scalable and beneficial to the building sector. By linking and organizing diverse repositories, NEST-Bot will enable seamless interaction with complex datasets, establishing new standards for data integration and ORD in building automation and research.
We aim to simplify data access through a user-friendly interface, enabling stakeholders to query relevant NEST measurements via natural language. This MVP will focus on core features such as retrieving specific sensor data and providing contextual information for easier interpretation. Our goal is to enhance data contextualization, improve data discovery, and support research in building and energy management. Furthermore, we intend to lay the foundation for incorporating additional data silos into the NEST-Bot ecosystem.",2025-01-01,12,30000
CONTRIBUTE/NGSDATABOOSTER,Contribute,ETH Zürich,NA,Hubert,Rehrauer,NA,NA,NA,NGSDataBooster: Simplifying and democratizing the open deposition of Next Generation Sequencing Data,NGSDataBooster,NA,NA,NA,15000
CONTRIBUTE/OGAIS,Contribute,EPFL,MER,Jan,Skaloud,EPFL ENAC IIE CRYOS,1015,Lausanne,OGAIS – An Open Georeferencing of Airborne Image Spectrometry,OGAIS,"This project aims to synergize with the development of a new high resolution airborne image spectrometer (AIS), made by NASA-JPL for a consortium of Swiss research institutions, to propose new tools for open and precise georeferencing of hyperspectral data, used to measure terrestrial processes of the Earth system at regional scale. The concrete outcomes are the following: a) a definition of new open format for sensor stabilization that is used together with raw navigation data in the process of georeferencing for this instrument while involving collaboration with the International Society of Remote Sensing (ISPRS), b) the development of a new tool to annotate known point position in the data for testing and calibration, c) the extension of EPFL public service of sensor-motion estimation and geometrical calibration by including new modalities and software components specific to line-scanners of this type, d) the release of first data sets with reference processing and a dissemination through a peer-review publication and a webinar.",2023-11-01,12,30000
CONTRIBUTE/OPAS,Contribute,EPFL,MER,Jan,Skaloud,EPFL ENAC IIE CRYOS,1015,Lausanne,Open Processing of Airborne imaging Spectrometry,OPAS,"Developed by NASA-JPL and operated by the consortium of Swiss universities - ARES, the AVIRIS-4 is the most advanced airborne imaging spectrometer (AIS) currently operational in Europe. In agreement with NASA-JPL, ARES will make all data produced by AVIRIS-4 publicly available and is building an environment of open tools to make the processing of this data accessible, interoperable and reproducible, in line with FAIR principles. During our previous ORD-Contribute project, OGAIS, we developed an open tool which can be used to label point correspondences in AIS images by hand. This tool enables the airborne remote sensing community to obtain ground truth “tie-points” for evaluating the quality of the scene reconstruction and/or improving the image geo-referencing accuracy. After the first flights of AVIRIS-4 during the spring-summer this year, a clear need emerged for the mission at high resolution (0.3 – 1 m/pixel) to obtain point correspondence labels without human intervention in order to i) improve the conventional (direct) georeferencing, ii) automate the quality assessment on all current and future missions featuring more than couple flight-lines (>0.5 TB / mission). This project therefore proposes to support ARES ORD practices by providing tools to automate the detection of tie-points as spatial constraints in overlapping AVIRIS-4 images, and integrate them in EPFL’s open, on-line georeferencing service ODYN to maximise findability.",2025-01-06,12,30000
CONTRIBUTE/OPENJMP,Contribute,ETH Zürich,Associate Professor,Elizabeth,Tilley,Global Health Engineering,8092,Zurich,Open JMP - unlocking the potential of global indicator data,openjmp,"Decades of manual data structuring have resulted in the most comprehensive and internationally-comparable information on Water, Sanitation, and Hygiene (WASH) coverage. The WHO/UNICEF Joint Monitoring Programme for Water Supply, Sanitation and Hygiene (JMP) maintains the database. The data are shared openly but in spreadsheet-based proprietary software, not following FAIR data principles. Data stored in spreadsheets underutilizes the potential those data could have for purposes other than the national, regional and global progress monitoring in WASH.

We will approach this unused potential by developing open-source data and software packages that follow FAIR data principles to share the data within the WASH community and beyond. In the process, we engage with the community by hosting free learning events using open-source computational tools, enabling community members to further competencies aligned with FAIR data principles.",2023-07-01,12,29905
CONTRIBUTE/OPENMIC&AI,Contribute,EPFL,Scientific collaborator,Jonathan,Dong,EPFL STI IEM LIB,1015,Lausanne,EPFL Workshop on Open Microscopy and AI: First Edition,OpenMic&AI,"Imaging science and computational microscopy are rapidly advancing, driven by novel interdisciplinary approaches involving deep learning algorithms. However, the increasing complexity and cost of these cutting-edge imaging systems and algorithms often make them inaccessible for non-experts, low-resource settings, and teaching applications. To address this challenge, we would like to organize a one-day workshop on open-source microscopy and AI to bring together the smart-microscopy community.The workshop will showcase a full pipeline of open-source solutions for optical imaging, from hardware to computational reconstruction and deep learning-based analysis. It will provide hands-on experience for participants to assemble an open microscope (OpenSIM, OpenUC2), perform reconstructions (Pyxu), and analyze images (DeepImageJ). It aims to empower researchers and teachers to take full control of their imaging pipeline and iterate rapidly on new solutions. Beyond this event, the project seeks to drive a broader and lasting impact on the community. Educational resources such as Jupyter notebooks and hardware kits will be developed and made publicly available to support teaching at EPFL and beyond.By showcasing a comprehensive open-source ecosystem for microscopy, this initiative aims at making state-of-the-art imaging technologies more accessible and further catalyze the growth of an open, interdisciplinary microscopy community.",2024-09-01,6,30000
CONTRIBUTE/OPENSENSE,Contribute,EPFL,Prof.,Josie,Hughes,EPFL STI IGM CREATE-LAB,1015,Lausanne,Enabling Open Datasets of Soft Tactile Sensor Characterization through Openly Available Hardware and Software (OpenSense),OpenSense,"The rapid development of soft materials with incorporated sensing properties has diverse applications in wearable devices, healthcare, and soft robotics. Soft sensors can detect strain, force, temperature, humidity, and more, emulating human skin's sensing abilities. This interdisciplinary field combines robotics, materials science, and data science. However, developing soft sensors is challenging due to the linked mechanical and sensing properties, requiring simultaneous data reporting for optimization. To address this, we require open access data-sets that enable comparison and analysis of different sensors. Current data collection methods using expensive equipment and post-processing hinder progress. We propose a novel hardware solution based upon low-cost 3D printer platforms which could offer promising solutions to foster and enable this ORD practice. In this project we seek to formally contribute the openly available hardware design and software to enable curation of data is a data format that is aligned with ORD best practises. This will involve making the designs and software openly available and findable under FAIR principles and providing the necessary documentation in a manner that is easy to update. The software scripts must be developed to generate output data that is FAIR compliant and best supports ORD practices. A second aspect of this project is to disseminate the enabling technologies by participating in key workshops on the topic of ‘open hardware’.",2024-01-01,12,30000
CONTRIBUTE/ORSMD,Contribute,ETH Zürich,Senior Researcher / Lecturer,Milos,Balac,CSFM,8092,Zürich,An ORD framework for synthetic mobility data,ORSMD,"The eqasim pipeline, developed at ETH, is an ORD tool for generating synthetic travel demand datasets. However, its current implementation in Switzerland has several limitations. The Swiss implementation relies on non-open data from the Swiss Federal Office of Statistics, which complicates data sharing and slows research due to the need for lengthy data privacy agreements. This limits the speed of innovation and collaboration among researchers. Additionally, each new application of eqasim requires duplicating and modifying the codebase to incorporate new datasets, resulting in fragmented approaches. This project aims to overcome these limitations by enhancing the standardization of the eqasim framework, improving the ease of data exchange, and enabling better control over algorithms and data extraction. By addressing these issues, the project will streamline data sharing and accelerate research, ultimately increasing the impact of eqasim in Switzerland and beyond.",2024-12-01,9,30000
CONTRIBUTE/PHENOMAST,Contribute,WSL,NA,Daniel,Scherrer,NA,NA,NA,PhenoMast - Integration of standardized tree seed mast observations into existing phenology monitoring networks,PhenoMast,NA,NA,NA,30000
CONTRIBUTE/PYCSOU-FAIR,Contribute,EPFL,"Principal Scientist and Lecturer, Head of the EPFL Hub for Advanced Image Reconstruction",Matthieu,Simeoni,EPFL VPA VPA-AVP-CP IMAGING,1015,Lausanne,Pycsou FAIR: A Community Marketplace for Discovering and Sharing Image Reconstruction Plugins,Pycsou-FAIR,"Pycsou is an open-source computational imaging software framework for Python with native support for hardware acceleration and distributed computing. The latter adopts a modular and interoperable microservice architecture providing highly optimised and scalable general-purpose computational imaging functionalities and tools, easy to reuse and share across imaging modalities. One key specificity of the framework is its domain-agnosticity, which helps it remain lightweight (with only a few core dependencies), accessible to most imaging scientists, and portable/scalable across computing platforms and imaging modalities. However, this domain-agnosticity also limits the adoption of the framework by certain imaging communities with very specific computational imaging needs. This project adresses this issue by introducing Pycsou FAIR, a web platform, meta-programming framework and interoperability protocol for Pycsou aiming at facilitating the discovery, installation, development and sharing of FAIR-compliant community-based image reconstruction plugins at scale. This platform will allow imaging scientists to develop, share and take full advantage of modern computational imaging methods in their routine processing pipelines.",2022-11-01,12,30000
CONTRIBUTE/PYSPM,Contribute,EPFL,Scientist,Marcos,Penedo Garcia,EPFL STI IBI-STI LBNI,1015,Lausanne,HDF5-USID scheme implementation in the Open-Source SPM project for Pycroscopy ecosystems,PySPM,"Storing acquired data is a crucial step in every research cycle. Nowadays, instruments tend to discard most of the acquired data by down-sampling or discarding most of the signal via averaging or decimation. Saved data is normally stored into proprietary file formats, which limits the data exchange among the scientific community. It also impedes adding or modifying necessary metadata to keep important information about experiment parameters or instrument status, and hinders the use of existing post processing routines written for different file formats, leading to duplicated codes and preventing the exchange of routines among researchers.

Open-source data schemes are becoming increasingly important for scientific data storage. They enable sharing of software, data, and knowledge at early phases in the scientific process, maintain the digital integrity of the data at lower cost, and facilitate long-term preservation and future data mining through metadata. Developing software as open source allows modules to be readily shared, reused and extended by others. By choosing appropriate storage file open standards, it is possible to maximize available analysis tools and resources, reduce the cost of data manipulation and maintenance, and achieve ideal long-term preservation of large amounts of files.

In this project, we aim to implement the HDF5 and USID open standards on an already well-established ORD worldwide project at EPFL: the Open-Source SPM controller. Its current file scheme presents several weaknesses that we intend to overcome with these modern standards. Furthermore, the implementation of this scheme will enable access to a lively open software ecosystem called Pycroscopy, allowing the Open-Source SPM project to take advantage of all the functionalities and tools already existing in that ecosystem based on the HDF5 and USID open standards.",2024-02-01,6,30000
CONTRIBUTE/SCPAW,Contribute,PSI,Tenure-Track Scientist,Clemens,Lange,Laboratory for Particle Physics,5232,Villigen PSI,Seamlessly containerised physics analysis workloads (SCPAW),SCPAW,"The reusability of particle physics analyses is severely affected by undocumented and manual steps taken by the analysis teams. Starting from typically centrally produced reusable data sets, such high-level physics analyses are largely performed using individually developed analysis scripts and frameworks. While the analysis code is commonly under version control in a git repository, this does not guarantee that it works nor that it yields the results obtained from manual execution. This project aims to provide a prototype solution to these issues for experiments performed at the PSI Laboratory for Particle Physics (CMS, Mu3e, n2EDM) by encoding the missing information directly in the code repository and integrating it with the execution environment to ensure the code’s functionality. This will be achieved by providing templates to automatically test the code and package it in self-contained and portable software container images on the code repository server. These container images will then be distributed on the compute clusters using technology that allows for massively parallel batch processing. Aiming for an excellent user experience to increase adoption, this setup that builds upon the existing infrastructure at PSI will be benchmarked and optimized for a potential future large-scale deployment. Dedicated documentation will be developed, a training course be held at PSI, and the results as well as lessons learned will be presented at an international computing workshop.",2024-01-01,12,30000
CONTRIBUTE/SOLARFUELSDB+,Contribute,EPFL,Postdoctoral researcher,Isaac,Holmes-Gentle,EPFL STI IGM LRESE,1015,Lausanne,A standardized database framework for synthetic carbon-based solar fuels,SolarFuelsDB+,"In this proposal, we seek to significantly extend the recently created Solar Fuels Database (SolarFuelsDB) where we developed a systematic machine-readable framework for solar to fuel devices and developed an online interface for data entry and visualization, with the ultimate aim of accelerating the development of such technologies. The original project successfully created a systematic machine-readable framework in which to categorise photo-electrochemical (PEC) systems, populated the database (72 papers, 154 reported devices) and developed an online interface for data entry and visualisation, focusing intentionally on photo-electrochemical water splitting (hydrogen production) to define a manageable research task. The initial ambition at project conception was always to expand to other solar fuels (e.g. CO₂ reduction towards CO, ethylene, ethanol, etc.) and methodologies (e.g. thermochemical H₂ production), so the existing database schema has been designed to be versatile and extensible. Specifically, we plan to extend the solar fuels considered to include carbon monoxide, syngas, formic acid, methane, ethanol, etc., and extend the technological pathways to include thermochemical redox cycles. Notably, there has been a recent focus on moving from solar hydrogen to solar-driven reduction of CO₂ to valuable chemicals and fuels. Consequently, the extended SolarFuelsDB database (SolarFuelsDB+) has the potential to unify multiple different solar fuel pathways into a single repository where reports can be found and performances of various technologies can be systematically and equitably compared. We will engage with international research communities to ensure a judicious selection of metadata is captured by the database. These reporting guidelines will facilitate standardization in data reporting, and inclusion in the database will provide an incentive for authors as inclusion of research could lead to improved findability and greater dissemination of results. In line with the open-science goals of this project, it is envisaged the database will become continually maintained through community submission of new papers. This greatly improved and openly accessible resource will consolidate previous work and provide the overview required to gain novel insight in to the field and thereby identify promising future research trends required to move solar fuels towards wide-scale implementation.",2022-07-01,6,30000
CONTRIBUTE/SOP,Contribute,EPFL,Scientific Assistant,Raphaël,Vouilloz,EPFL ENAC IA LAPIS,1015,Lausanne,Speckle-OpenCascade Prototype for Enhanced AEC Interoperability through Geometry-Centered Approach.,SOP,"A Speckle connector for Open Cascade Technology will enhance software and data interoperability within the architecture, engineering, and construction industry. The project aims to bolster the use of free software in the sector, by uniting the capabilities of two open-source ecosystems in a sector where proprietary tools are currently very dominant. On the one hand, Speckle open-source connectors enable seamless collaboration across diverse AEC software; it ensures accurate and efficient collaborative workflows between various actors and disciplines, thus contributing to the freedom of choice of digital tools, avoiding a captive market. The connector's open-source design encourages community contributions, fostering continual improvement. On the other hand, Open Cascade Technology is an open-source geometric kernel. It is used in free software alternatives such as Freecad or Salome, and in open-source libraries such as IfcOpenShell, which allows the development of applications based on IFC, the open standard for Building Information Modeling. Also, the open-source nature of Open Cascade Technology enables many researchers and professionals to develop their own highly specialized digital tools. Our prototype would connect this ecosystem to all AEC industry software, via Speckle.",2024-03-01,6,30000
CONTRIBUTE/SPAM-ORD,Contribute,EPFL,Principal Scientist,Edward,Andò,EPFL VPA VPA-AVP-CP IMAGING,1015,Lausanne,Reinforcing open data analysis with spam: FAIR packaging and workshop organisation,spam-ORD,"We aim to make our popular open-source software 'spam' more accessible to the experimental mechanics community to exemplify and encourage good ORD practise in the community and avoid vendor lock-in with closed formats.

We also hope to make a community of users with good practice for future joint developments within the ETH domain.

We will do this by outsourcing some of the more complex software engineering to a service in EPFL, and also by organising a three-day workshop to promote, explain and illustrate ORD practise with 'spam'",2023-02-01,8,30000
CONTRIBUTE/SRFI-DB,Contribute,ETH Zürich,Postdoctoral researcher,Matthias,Schartner,Chair of Space Geodesy,8093,Zürich,Mitigating spaceborne radio frequency interference through satellite database (SRFI-DB),SRFI-DB,"The tremendous growth of satellite mega-constellations such as Starlink and OneWeb, emitting signals at radio frequencies, threatens radio astronomy. The emitted satellite signal can cause radio frequency interference (RFI) or saturate the wideband receivers of the highly sensitive radio telescopes leading to an information loss or even failed observations. As a countermeasure, the International Very Long Baseline Interferometry Service for Geodesy and Astronomy (IVS) community, and the International Astronomical Union (IAU) have launched working groups on the measurement and mitigation of satellite RFI. One promising approach is to avoid observations close to potentially harmful satellites. Within this work, we plan to support this attempt by establishing an open database of satellite orbits and emitted satellite frequency spectra. We will curate existing orbit information and connect them with existing frequency information and measurements taken at the observatories. The database will be openly available and provides access via a web interface and an application programming interface (API). This ensures seamless integration into existing state-of-the-art software pipelines.",2023-01-01,6,29799
CONTRIBUTE/STILLBERGDAT,Contribute,WSL,PhD,Esther,Frei,"Mountain Ecosystems Research Group, WSL Institute for Snow and Avalanche Research SLF",7260,Davos Dorf,Seizing the treasure: making long-term environmental data available for eLTER and beyond,StillbergDAT,"The European Long-term Ecosystem Research (eLTER) facility Stillberg was established in 1975 in a treeline ecosystem near Davos, Switzerland. In almost 50 years of research, we have collected a wealth of environmental and ecological data at this unique alpine site. These include monitoring data of a large-scale treeline afforestation experiment, meteorological data, time series of plant responses to free-air carbon dioxide enrichment, soil warming and nutrient addition, as well as plant-snow, plant-soil interactions, and drivers of tree seedling recruitment. In this project we aim at contributing these important ecological datasets from Stillberg as open research data (ORD). By curating the existing datasets before the upload to national and international ORD platforms (EnviDat and DEIMS-SDR) we will improve their visibility, quality, and availability. The provisioning of this long-term environmental data will foster transdisciplinary and global research syntheses and meta-analyses, improving our understanding of long-term ecosystem processes in mountain regions and supporting the development of adequate adaptation strategies.",2022-06-01,6,29953
CONTRIBUTE/THRACE,Contribute,PSI,Dr.,George Dan,Miron,Laboratory for Waste Management (LES),5232,Villigen PSI,Traceable thermodynamic datasets for chemical modelling,THRACE,"At present, thermodynamic datasets do not follow ORD FAIR principles. ThermoHub database provides access to a collection of traceable thermodynamic datasets for various fields of application. These datasets are curated and documented by experts using an open standard JSON format. The aim of the project is to bring ThermoHub to its full potential and demonstrate its ORD capabilities by producing a unified database of several mainstream thermodynamic datasets that are ready to use for chemical modeling. The project also aims to develop and provide a documented semi-automatic workflow for future maintenance and extension with new data. This work can greatly standardize and unify the workflow of chemical thermodynamic modeling, and support iterative improvement of the quality, reliability, and traceability of databases and modeling results. Providing datasets following FAIR principles will be advantageous when used in modeling, as it will remove the burden from modelers of collecting all necessary standard thermodynamic values from vast literature or writing complex scripts for importing these from different formats. ThermoHub can greatly streamline collaboration within Swiss, European, and other international projects by providing traceable thermodynamic data for various modeling applications. It will also be advantageous for the recognized work at PSI/LES (as well as EPMA and ETHZ) on thermodynamic database and modeling code development.",2023-09-01,4,30000
CONTRIBUTE/TIMERESHDRMX,Contribute,PSI,NA,Filip,Leonarski,NA,NA,NA,Enabling compliance with ORD standards for cutting-edge time-resolved experiments at high data-rates,TimeResHDRMX,NA,NA,NA,22000
CONTRIBUTE/TRANSCODE,Contribute,EPFL,Assistant Professor,Sara,Bonetti,EPFL ENAC IIE CHANGE,1951,Sion,"Towards community-driven, open and FAIR ecohydrological modeling",TRANSCODE,"Mechanistic ecohydrological models are essential tools to accurately simulate the impacts of climate change on the water, carbon, and nutrient cycles. However, there are very few models available to the community which can holistically simulate such a wide range of processes and most of them are written in low-level programming languages (e.g., C++ or FORTRAN), hindering model accessibility to new users. In this regard, Tethys and Chloris (T&C), a state-of-the-art ecohydrological model written in MATLAB, offers a strong foundation for creating an accessible community-driven model. TRANSCODE aims to transform T&C into a FAIR (Findable, Accessible, Interoperable, Reusable) model by redesigning its architecture for modularity and re-implementing it in Julia, an open-source language which marries the computational efficiency of low-level programming languages such as FORTRAN and the accessibility of high-level languages such as MATLAB. This translation will improve computational efficiency, foster open code contributions from the community, and facilitate interoperability with other models. Specifically, the project will create a modular, comprehensively tested, highly efficient, and easily accessible version of T&C, termed T&C-Julia. TRANSCODE has the potential to significantly benefit the Earth science community and advance the field of ecohydrological modelling by providing a versatile, state-of-the-art, and open-source modelling platform.",2024-10-01,12,30000
CONTRIBUTE/TREASURE,Contribute,EPFL,Professor,Dimitrios,Lignos,EPFL ENAC IIC RESSLAB,1015,Lausanne,DaTabases and fRont-end wEb-bAsed Software for performance-based natUral hazaRds Engineering,TREASURE,"The growing realisation that data are valuable to extract information for both research and design purposes in natural hazards infrastructure engineering is timely. This project aims first to signify the further development and curation of open access databases in a consistent format. Predictive models and probabilistic distribution functions that express damage of structural metallic materials and members will be formulated in an interactive web-based software that will also provide enhanced data visualization features. The data curation process, which will be in line with the FAIR principles, will strive to harmonize data formats in a way to maximize data re-use within the research and engineering communities. Planned dissemination and maintenance strategies along with the development of comprehensive guidelines on how to standardize data storage and visualization will embrace the project’s sustainability in the long term.",2023-06-01,12,30000
CONTRIBUTE/TREENETGAPS,Contribute,WSL,Dr.,Mirko,Lukovic,Ecosystem Ecology - Forest Dynamics,8903,Birmensdorf,AI module for gap-filling TreeNet time series,TreeNetGaps,"In a recent WSL research project (deepT - internal grant no. 202011N2099) we developed a machine learning model for gap-filling multi-channel time series data. We would now like to add a module or toolbox that is based on this model to the existing automated near real-time TreeNet data acquisition infrastructure. The new tool would provide an additional option to the users of TreeNet dendrometer data to automatically fill the gaps in the time series using artificial intelligence. The existing model first must be improved using newly available data. It then has to be programmed in R, the native language used in the TreeNet software. Thereafter, the code must be inserted into the existing pipeline and offered as an option to the end-users of the data. This will also involve adapting the data to the input and output requirements of the model.",2024-01-01,12,30000
CONTRIBUTE/TSDF,Contribute,EPFL,Computer Scientist,Martí,Bosch,EPFL ENAC IIE CEAT,1015,Lausanne,TSDF (Time Series DataFrame) - A data storage architecture for scalable processing of heterogeneous and geospatial time series,TSDF,"Geospatial time series data play a central role in environmental sciences, with example applications ranging from fixed sensors such as meteorological stations to mobile sensors. However, despite their ubiquity, methods to process and store geospatial time series datasets are often disperse and lack standard practices. A key reason for such a shortcoming is the inherent heterogeneity and irregularity of time series data.In this proposal, we aim to address these challenges by developing TSDF, a new data specification that provides a flexible framework to access, process, store and share geospatial time series datasets. A binary format based on Apache Parquet will be designed to provide flexible and effective hierarchical structuring of time series measurements, enabling scalable and distributed processing of irregular and heterogeneous datasets. Additionally, a Python package will be developed to provide an easy interface to load the datasets into pandas data frames, with methods to facilitate operations such as filtering, reducing and combining the data. The proposed work can greatly facilitate the processing of geospatial time series data in a vast body of applications, reducing data wrangling time for researchers while enhancing interoperability, reusability and collaboration.",2023-06-01,7,30000
CONTRIBUTE/UQBENCH,Contribute,ETH Zürich,Professor,Bruno,Sudret,"Chair of Risk, Safety and Uncertainty Quantification",8093,Zurich,Open Platform for Benchmarking Uncertainty Quantification Algorithms,UQBench,"Uncertainty quantification (UQ) allows practitioners to assess the impact of uncertainties in natural and engineering systems for robust and well-informed decision making. It covers a wide range of scientific disciplines such as geophysics, civil and mechanical engineering or finance. As such, the efficiency of UQ methodologies is crucial. While many new methods are continuously developed, assessing their actual efficiency is not straightforward because of the lack of thorough benchmarking within the community. Besides the technical aspects of implementation, carrying out a benchmark properly requires defining meaningful performance measures and using consistent test data. The goal of this project is to build a benchmark module in UQLab, a reference software for uncertainty quantification developed in our Chair. This module will allow researchers to seamlessly perform benchmarks in an automated way, i.e., without the burden of actually gathering data, repeatedly running a code and post-processing the results. Both the benchmark data and results will be made available on UQWorld, a web-forum gathering thousands of UQ practitioners. This will ultimately result in a growing database that will serve as reference for future publications. In fine, we believe that making such a platform available will help further engaging with the UQ community and encourage ORD practices.",2023-09-01,4,30000
CONTRIBUTE/WASHCOLLAB,Contribute,ETH Zürich,Prof. Dr.,Elizabeth,Tilley,Global Health Engineering,8092,Zurich,Enhancing Global WASH Data Accessibility through Collaborative Initiatives,washcollab,"The ""Enhancing Global WASH Data Accessibility through Collaborative Initiatives"" proposal, a joint effort by WASHWeb and openwashdata, aims to improve the global Water, Sanitation, and Hygiene (WASH) data ecosystem. The partnership, formed under shared goals for better data accessibility, usability, and representation, proposes a project divided into three work packages: Maintain, Extend, and Disseminate. The first package updates the Joint Monitoring Programme (JMP) dataset for broader use. The second aims to collaborate with data providers to create a new R dataset package, enhancing analyses of WASH investments and outcomes. The final package seeks to promote these open data packages through webinars, conference sessions, and online discussion groups, fostering a community around open WASH data.",2024-08-01,12,30000
CONTRIBUTE/WEAR-MED,Contribute,ETH Zürich,Head of SCAI Lab (Senior Scientist),Diego,Paez-Granados,SCAI Lab,8092,Zurich,Open Access and Interoperability in Medical Wearables: Community-driven standardization of low-level communication protocols for raw wearable sensor data,WEAR-MED,"Wearable sensors offer vast potential for advancing healthcare through data-driven insights, but their integration into clinical trials and practice is hindered by a lack of interoperability. This project proposes the development of a standardized low-level communication protocol for wearable sensors to facilitate harmonized data collection across different platforms. By establishing a common standard for raw data transmission, the project aims to enable seamless aggregation of sensor data and foster collaboration among healthcare, research, and industry stakeholders. Through community-driven requirements gathering and standards development, the project seeks to address the current challenges in integrating wearable sensor data into healthcare practices. Inspired by successful standards in other domains, this initiative aims to catalyze a more interconnected digital health ecosystem where wearables play a pivotal role in personalized healthcare practices.",2024-09-01,6,32000
CONTRIBUTE/XYT,Contribute,EPFL,NA,Marc-Edouard,Schultheiss,NA,NA,NA,"‘XYT’, a python package to analyze activity-travel behaviors, organization and scheduling",XYT,NA,NA,NA,30000
ESTABLISH/OPEM,Establish,EPFL,Professor,Henning,Stahlberg,EPFL VPA VPA-AVP-CP DCI,1015,Lausanne,Open EM Data Network,OPEM,"This Open EM Data Network will establish ORD practice for Electron Microscopy (EM) in Switzerland. In the life sciences, cryo-EM experienced a resolution revolution enabling to the atomic-resolution determination of protein structures. In materials sciences, EM equally experienced a dramatic expansion of possibilities and multidisciplinary approaches, e.g., 4D STEM data collection. This led to unparalleled increase in data volumes and need for computational resources.

This Open EM Data Network (OPEM) will build on the PSI’s existing data annotation (SciCat) and data handling and storage technology (Data Catalog), which will be expanded to cover EM data and to establish Swiss-wide access. It will standardize the collection of data and metadata, streamline data and metadata handling, assist in data transfer and sharing, and automate and support deposition into existing international ORD repositories. It will provide user training in ORD practices and establish a sustainable structure to be maintained after closure of this project.

The Open EM Data Network is complementing a Swiss-wide effort to push the boundaries in EM technology with the “EM frontiers” initiative. It will establish ORD practice throughout the ETH-Domain EM sites and will be expanded to all Swiss University EM sites through a parallel application to SwissUniversities.",2023-01-01,30,1500000
ESTABLISH/PREMISE,Establish,Empa,Group leader (Senior Scientist),Carlo Antonio,Pignedoli,Laboratory for Materials Simulations,5232,Villigen PSI,PREMISE: Open and Reproducible Materials Science Research,PREMISE,"PREMISE aims to establish, promote and facilitate the adoption of FAIR ORD practices in Materials Science, focusing on enabling the treatment, at the same level, of experimental and simulation data. We will first develop metadata standards for machine-actionable interoperability between electronic lab notebooks (ELNs)/lab information management systems (LIMSs) and workflow management systems (WFMSs), and apply these standards to Materials Science ontologies. We will then collect, design and disseminate best practices for generating ORD as a natural part of the research process, rather than as an additional duty for researchers. Our deliverables will be demonstrated with concrete pilot use cases, chosen to be applicable to the broad field of Materials Science, and generalisable to other disciplines. We will leverage two robust open platforms, developed and maintained within the ETH domain, compliant by design with FAIR requirements for experiments (openBIS) and simulations (AiiDA+AiiDAlab). We will bring them ""to the next level"" by implementing our novel set of ORD practices and demonstrating how an ELN/LIMS and a WFMS can be made seamlessly interoperable. We expect our deliverables to be essential components of the emerging field of autonomous laboratories, where automated simulations and robotic experiments are combined via artificial intelligence in closed feedback loops, ultimately accelerating materials discovery and characterisation.",2023-01-01,36,1292100
EXPLORE/ADDLIDAR,Explore,EPFL,Senior Scientist,Jan,Skaloud,EPFL ENAC IIE CRYOS,1015,Lausanne,AddLidar – Airborne Laser Scanner Data Repository and Processing Portal for the ARES Observatory,AddLidar,"This project aims to establish an open database and processing pipeline for ALS (Airborne Laser Scanner) data, complementing the imaging spectrometry platform, to promote transparency, accessibility, reproducibility and innovation in sensor co-registration and data analysis, ultimately benefiting scientific communities worldwide.",2024-09-01,18,150000
EXPLORE/ASTROORDAS,Explore,EPFL,Professor,Jean-Paul,Kneib,EPFL SB IPHYS LASTRO,1290,Versoix,Development of Open Research Data Analysis Services supplementing astronomical Open Research Data (AstroORDAS),AstroORDAS,"Over the last decade, astronomers have been developing a new field of Multi-messenger astronomy that combines radio-to-gamma-ray electromagnetic signals with neutrino and gravitational wave signals to get new insights into physics of astronomical sources. Diversity of data sets (mostly available as ORD) involved in multi-messenger data analysis poses a challenge of reproducibility of multi-messenger analysis results and their traceability to raw observational data. Without thoughtful stewardship of the data reduction and elaboration methods, the key principle behind the ORD concept, the “Findable-Accessible-Interoperable-Reusable” (FAIR) principle, is not fully implemented: the results derived from ORD are not reproducible, the raw observational data are not reusable. The project proposes a solution to this problem through a setup of cloud-based ORD data analysis services (ORDAS) that supplement the ORD and explicitly assure reproducibility of results and reusability of the ORD. We propose to develop such services for two major next-generation facilities, gamma-ray observatory Cherenkov Telescope Array (CTA) and radio observatory Square Kilometre Array (SKA). We will demonstrate the power of ORDAS for CTA and SKA by engaging the community of multi-messenger astronomers in ORD practices through a Multi-Messenger Online Data Analysis (MMODA) platform for the study of transient multi-messenger astronomical sources for which on-the-fly analysis of multi-messenger ORD is vital.",2022-10-01,12,149277
EXPLORE/COORDINEO,Explore,ETH Zürich,Senior Scientist (Oberassistent),Daniel,Bowden,Seismology and Wave Physics,8092,Zürich,COmmunity Needs of Open Research Data Practices iN FibEr-Optic Sensing - Leading by Example. [COORDINEO],COORDINEO,"In recent years, seismological monitoring and observation has been revolutionized by the use of fiber optic sensing technologies. Distributed Acoustic Sensing (DAS) uses pulses of light and backscattered signatures to measure strains along fiber optic cables at an unprecedented spatial resolution. Within the Seismology and Wave Physics group at ETH, we have been pioneering DAS experiments around the world, including records of urban seismic activity, on glaciers, monitoring of avalanches, volcanic activity, and more. Given that DAS systems can produce hundreds of GBs of information in a single day, these projects have resulted in a correspondingly unprecedented increase in the amount of data that needs to be stored, processed, and shared. As more and more research institutions around the world explore this new technology, clear standards need to be established to further encourage interdisciplinary collaboration. Such standards include data and meta-data information according to FAIR Open Research Data (ORD) and Open Science (OS) principles. Whereas the scientific community around DAS is starting to tackle parts of the entire ORD and OS lifespan of geophysical experiments and data, examples and references of full solutions are not yet available. With our proposed ETH ORD project, we plan to establish ORD and OS practices throughout the full scientific lifespan of (geo-)physical projects - in close collaboration with the community, and leading by example.",2022-09-01,12,150000
EXPLORE/DCSM,Explore,EPFL,Senior scientific collaborator,Guillaume,Anciaux,EPFL ENAC IIC LSMS,1015,Lausanne,Cloud and web based platform for dissemination of computational solid mechanics,DCSM,"Academic knowledge is traditionally disseminated by academic journals. However, nowadays the production of scientific data in any given project exceeds by a vast amount what can be contained in a few journal pages. Reproducible scientific data and publications must be associated to boost scientific collaborations and discoveries. Open-science aims at publicly distributing the production of scientists. To be successful platforms simplifying workflows are required. Our project shall provide such a platform for the vast computational solid mechanics (CSM) community. It will allow to describe input, code and output of a simulation, therefore enabling storage on a repository. Facilities will be included for mainstream software and high-performance computing calculations. Results access and analysis will be web-based. When ready to be published, simply clicking a submission button to an open-access repository will be the only requirement. There are already existing open-source software for some of the bricks composing our proposal, but not for CSM needs. We propose to implement a distributed platform, based on well-established initiatives such as Meshio and Renku projects, yet focusing on such needs.",2022-10-01,18,131777
EXPLORE/EXAIRIM,Explore,Empa,Senior Scientist,Stephan,Henne,Air Pollution / Environmental Technology,8600,Dübendorf,Explore AiiDA for Regional Inverse Modelling of Greenhouse Gases (ExAiRIM),ExAiRIM,"Inverse modelling of greenhouse gas emissions is a powerful tool combining atmospheric observations and transport simulations to provide policy-relevant, real-world emission estimates. Inverse modelling requires computational workflows that deal with multiple atmospheric model simulations, pre- and post-processing steps, inversion codes and collection/aggregation of results across an ensemble of individual realisations. These steps are not handled in a traceable, repeatable and user-friendly way. Here, we propose to use the 'Automated Interactive Infrastructure and Database for Computational Science' AiiDA system to develop prototype workflows and implement plugins for automation of the above steps. AiiDA is a well-established tool in the field of computational material science within the ETH-domain. We will build on its flexible structure to transfer its powers to the atmospheric modelling community, specifically that of inverse modelling. We will interact with our Swiss and European partners to design generic workflows that can be easily adopted by other researchers working on inverse modelling. Our implementation will improve the traceability, repeatability, findability, and sharing of emission estimates that are crucial in the assessment of climate change policy and legislation. We expect to carry the achievements beyond the use in our own group to other researchers with whom we cooperate closely in the context of international and European programmes and projects.",2022-12-01,12,147000
EXPLORE/FAIRGEO,Explore,ETH Zürich,Prof. Dr.,Lorenz,Hurni,Institute of Cartography and Geoinformation,8093,Zürich,Advancing open geodata practices in research communities,FAIRGeo,"The project aims to improve openness and interaction between research communities working with geospatial data. There is currently a significant gap in the absence of an application that enables research communities and Open Science stakeholders to publish, visualise, combine and extract research geospatial data in the formats desired by users, and to use them directly and openly in teaching and research. The project will focus on addressing key questions and working with research communities to better understand the needs and requirements of researchers for working with geospatial data in an open research data context. Key questions include the desired practices, data formats and standards for searching, combining, sharing and publishing open research geodata, and assessing the capabilities of existing geoportals such as GeoVITe to implement the developed ORD practices.
Collaboration with the community, in particular with representatives of the geosciences, is essential to discuss and develop user-centred ORD practices. Participatory approaches aim to focus on user needs to make research geodata findable, accessible, interoperable and reusable in line with the FAIR principles. Based on the identified needs and processes, initial testing and technical implementation will be carried out on the portal. The long-term goal is to establish sustainable tools for the open research geodata community, based on existing open standards and an improved web-based geoportal.",2024-07-01,18,150000
EXPLORE/FAIRQUAL,Explore,ETH Zürich,Group Leader,Mollie,Chapman,Transdisciplinarity Lab (TdLab),8092,Zurich,FAIRqual - FAIR Data Practices for Qualitative Research in Transdisciplinarity,FAIRQual,"While ORD practices become increasingly widespread, one area that remains a challenge is qualitative data. On the one hand, qualitative data is more difficult to process and make available in open practices. On the other, ethical norms in research practice require confidentiality of research subjects. Yet interview transcripts, workshops or other kinds of qualitative data are difficult or sometimes impossible to anonymize. This challenge comes to the fore when conducting transdisciplinary (Td) research, where new forms of engagement between science and society co-produce problem framings and project outputs. In this context, questions of who processes and stores data are increasingly important. Td research makes frequent use of qualitative methods, especially interviews and workshops. Sharing of this data could allow for improved learning between Td processes and increase engagement between science and society. How might this data be shared according to FAIR principles? What are appropriate protocols for determining what data to share and how to navigate the ethical issues of research participant protection and the benefits of sharing qualitative data? In this project we will prototype tools for FAIR qualitative data within Td research projects, develop standards and guidelines for other Td researchers and build a dialogue and community of practice within the Td research community around FAIR practices for qualitative data.",2024-09-01,18,150000
EXPLORE/FOREST3DTWIN,Explore,WSL,Senior Scientist / Teamleader,Christian,Ginzler,Remote Sensing,8903,Birmensdorf,Open Laser Scanning Database for characterization of Forest Biophysical properties and beyond (Forest3DTwin),Forest3DTwin,"Highly detailed 3D characterization of trees and forests with close-range technologies offers great potential for modeling carbon, energy fluxes, habitat diversity and much more. Numerous research groups are collecting complex 3D data in forests, and some are making it available as open data to the community. However, there are currently very few open data repositories or even metadata for 3D forest data from laser scans that can be used by different groups on a European or global scale. In the Forest3DTwin project, we want to build a prototype for open storage of measured 3D data with reference data according to the FAIR principles (findability, accessibility, interoperability and reusability) and are convinced that this can be established at the Swiss Federal Institute for Forest Research WSL in the long term and lead to a engagement and commitment of the European and global community to open 3D forest data.",2024-09-01,18,150000
EXPLORE/FRAME,Explore,EPFL,Assistant Professor,Sara,Bonetti,EPFL ENAC IIE CHANGE,1951,Sion,A FAIR Protocol for Hybrid Models and Data in Hydrology (FRAME),FRAME,"Hybrid models, which combine physics and machine learning (ML) based models, are becoming increasingly popular in hydrology and the broader Earth Science community due to their potential for improved prediction and process representation. However, hybrid models pose unique challenges to open research practices, including the widely accepted FAIR principles. Unlike physics-based models, the reusability of hybrid models is hindered by the integration of ML models which dynamically change with training data. Furthermore, existing model and data repositories are not designed to host hybrid models which contain code, ML models, and associated training data. To address these challenges, FRAME will collaboratively design, implement, and test a standardised FAIR protocol tailored for hydrological hybrid models. The protocol will consist of coding standards for interoperability between different model components, a unified metadata specification accounting for different types of physics and ML-based models, and a python package leveraging existing model and data repositories widely used in the hydrology (HydroShare) and ML (DLHub) communities to share and retrieve hybrid models. To ensure wider and long-term impact of the project beyond its lifetime, the developed protocol will be actively used and improved by participating groups in the ETH Domain and Europe and will ultimately be transitioned to a community-driven protocol, inviting participation from the wider scientific community.",2024-11-01,18,146705
EXPLORE/GENDIB-ORD,Explore,WSL,Dr.,Felix,Gugerli,Biodiversity and Conservation Biology,8903,Birmensdorf,Promoting Open Research Data practice for genetic diversity (meta)datasets (GenDiB-ORD),GenDiB-ORD,"The prototype of a new national database on intra-specific genetic diversity in populations of wild species in Switzerland, GenDiB, is currently being developed as part of a project co-financed by the Federal Office for the Environment (FOEN). With this ORD initiative proposal, we aim at (i) development of new tools to support simple procedures for dataset up-/download and to implement attractive visualization features and (ii) community building among researchers and stakeholders through various interactive communication means. Our dedicated activities, in parallel to further developing GenDiB as a beta version for subsequent permanent operation and maintenance, should promote the standardized use of GenDiB as the core repository for respective datasets within the community of researchers and stakeholders in conservation management in Switzerland, and possibly beyond. Integrating GenDiB into the national network of database holding species-level occurrence data (InfoSpecies) will complement these databases to cover the genetic level of biodiversity, which is fundamental for population and species persistence in the context of environmental change.",2024-10-01,9,150000
EXPLORE/HT-CHEMBORD,Explore,EPFL,Executive director (Dr),Pascal,Miéville,EPFL SB ISIC SWISSCAT,1015,Lausanne,High-Throughput Chemistry Based Open Research Database,HT-CHEMBORD,"Experimental data from chemical synthesis are complex, rarely openly available in a computational format, and mostly biased toward positive results, which represent a minority of cases. This situation strongly impacts the development of efficient predictive models in chemistry, drug discovery, energy storage or generation, and new materials development. To improve data quality and availability for the chemist community, the Swiss Cat+ West Hub and SDSC, with support from the SWITCH Foundation, propose to jointly develop HT-CHEMBORD. This project combines a global chemical synthesis robust and open ontology based on high quality FAIR compliant experimental data generated initially in the Swiss Cat+ hubs and then thanks to future collaborations by other high-throughput validated laboratories, an open access database with complete data integrity management and a set of query tools allowing the community of chemists and data scientists to explore the unique dataset offered. Exploratory work on the data validation strategy, with a view to extending it to external data providers, is already planned in the current project.",2024-07-01,12,146000
EXPLORE/ILOG,Explore,Empa,Group Leader,Bruno,Schuler,nanotech@surfaces,8600,Duebendorf,Integrated Instrument and Inventory Logbook for Experimental Science Labs (iLog),iLog,"Our aim is to develop practices and tools to trace and share the state of shared inventory items in a multi-user laboratory, linking this information to the personal Electronic Lab Notebook (ELN) of each user. With this practice, we seek to fill a big blank spot in the tracking of mutable laboratory information management system (LIMS) objects. A tool akin to a digital inventory logbook will be developed as an openBIS extension to support a wide range of experimental laboratories with variable types of measurement equipment and inventory items. This inventory logbook will complement the native openBIS ELN-LIMS, with focus on measurement equipment and inventory management. The implementation will prioritize generality and user-friendliness to minimize adaptation barriers and promote the dissemination of this ORD practice.",2024-09-01,18,149260
EXPLORE/INOAP,Explore,ETH Zürich,Professor,Richard,Hahnloser,Birdsong and Natural Language Group,8057,Zürich,Interfacing Natural Language Processing (NLP) Tools with Open Access Publications,INOAP,"Scientific publications are among the most valuable achievements of mankind. Thanks to open research data (ORD) such as open access publications, the world’s scientific output is increasingly accessible. But access to this massive trove of data is not enough—we must be able to assimilate the knowledge it contains and put it to good use. We need accessory technologies to harness knowledge for the world’s benefit. Search engines and their keyword-driven interfaces are very limited in their ability to bring scientific knowledge to end users, i.e. researchers with specific questions and authors of scientific manuscripts. Tasks such as discovering, reviewing, summarizing, and generating discussions from the scientific literature are easier to accomplish as our Natural Language Processing (NLP) techniques advance. We propose to radically increase the value of the vast trove of open access scientific content by aggregating an OR database of more than 140 Million papers and by providing interfaces to state-of-the-art NLP tools. We intend to publish the code and content of this database, to provide access via an application programming interface (API), and to operate a web-based application that uses NLP algorithms to help authors of scientific manuscripts to assimilate the scientific literature. Our efforts will help scientists discover, characterize, and harness the store of knowledge in open access publications and streamline the scientific discovery and writing processes.",2022-09-01,18,150000
EXPLORE/INSCRIBE,Explore,Eawag,Group Leader (Dr.),Jörg,Rieckermann,Intelligent Network Operations,8600,Dübendorf,Exploring and strengthening reproducible research practices in urban drainage (INSCRIBE),INSCRIBE,"To enhance the reproducibility of research practices within the urban drainage community, particularly focusing on improving the interpretability and reusability of both data and code, it is imperative to enhance the documentation of the origins of open datasets and the outcomes of workflows and models utilizing these datasets. Our goal is twofold: develop prototype Open Research Data (ORD) tools with the Swiss Data Science Center and assess their effectiveness with the international urban drainage community. We will explore if RENKU can serve as a comprehensive platform for this, given its features like collaborative workflow management, version control, and integration with data science tools, promoting reproducibility, and efficient collaboration among researchers. Planned use cases include i) individual researchers sharing results, ii) benchmarking rainfall-runoff models in our department, iii) and distributed groups providing pre-processed datasets with full provenance information. We will start by enhancing the FAIRness of a 20-year-old dataset on sewer mixing. Additionally, we will evaluate different EPA-SWMM model implementations and engage the international urban drainage community in ORD practices. This initiative could establish a cornerstone for data sharing in urban drainage, extending beyond Eawag's research.",2025-01-01,18,150000
EXPLORE/MED-WEAR,Explore,ETH Zürich,Senior Scientist (Head SCAI Lab),Diego,Paez-Granados,SCAI Lab,6007,Nottwil,Open API and Interoperability in Medical Wearable Data for Healthcare Research,MED-WEAR,"The MED-WEAR project addresses the absence of data interoperability in wearable devices in clinical practice and research, i.e., each manufacturer, service provider and researcher, executes unique solutions for data capturing, storing, and formatting in each study. In response to this challenge, we propose the development of a Wearable API (MED-WEAR), which provides a standardised framework between medical wearables and robotic devices to collect data in multiple research and clinical facilities, whilst reducing the workload and costs by applying FAIR principles in clinical research with this devices. We aim to establish standardised data collection in the ETH domain and beyond, herewith, empowering the research in healthcare community for streamlined data collection with wearables to foster innovation with wearables and define open standards. MED-WEAR impacts clinical and data science research by enabling lifelogging for individuals, promoting transparency in patient monitoring across rehabilitation laboratories. Engaging with the Swiss Neuro Rehab Initiative and collaboration across ETH RESC, RELAB, SMS lab, SCAI lab and DART lab at LLUI, the project establishes an interoperable platform, with the potential to provide a new ORD service within the ETH domain.",2024-12-01,18,150000
EXPLORE/NHCDATAVISION,Explore,ETH Zürich,Professor,Consuelo,De Moraes,Biocommunication/ ETH Entomological Collection,8092,Zürich,Enhancing 3D data visualization standards and practices for natural history collections,NHCDataVision,"3D imaging is a cutting-edge method for digitizing natural history collections, offering immense potential for taxonomy, general biology, and education. By analyzing 3D models, specialists worldwide can instantly access rare reference objects from collections, aiding in field interpretation and various scientific and educational applications. As 3D scanning becomes more efficient and digitization initiatives invest heavily in generating 3D data, 3D models are anticipated to become widespread. Surprisingly, there is limited research on how these 3D data are being used for research and education in natural history collections. Initial comparisons suggest that current 3D models are complex sets of data, lack suitable tools for analysis and modification, and require linking to additional metadata for utility in taxonomic research and education. This proposal aims to establish additional standards for 3D data preparation and develop best practice guidelines to ensure the usability of natural history collections data. Rather than focusing on developing ready-to-use solutions, the emphasis will be on identifying needs, documenting recommendations, and testing them with expert user groups. The outcomes will directly impact data infrastructures in the U.S., Europe, and Switzerland, serving over 500 institutions. They will also enable expert groups worldwide, particularly in the Global South, to virtually access natural history collection specimens for various scientific purposes.",2024-09-01,12,150000
EXPLORE/NMRPRIME,Explore,ETH Zürich,Professor (Prof. Dr.); Senior Scientist,Roland,Riek,Laboratory of Physical Chemistry,8093,Zürich,Initiative for primary bio-NMR open research data,NMRprime,"Nuclear Magnetic Resonance (NMR) spectroscopy, one of the major techniques in structural biology, suffers from the lack of an open database for its primary data, the multidimensional NMR spectra. These spectra are the basis for studies in atomic detail of the structure, dynamics, interactions, and functions of proteins, but are so far generally not made available to other researchers. Our NMRprime initiative for primary bio-NMR open research data will establish a database following the FAIR principles for biomolecular NMR spectra and explore its coordination with existing open databases for related, derived data, such as the Protein Data Bank (PDB) for protein structures and the Biological Magnetic Resonance Bank (BMRB) for chemical shift assignments. NMRprime will provide the framework for upload of NMR spectra in all commonly used formats, automatic annotation using machine learning techniques, search facilities, and open access to the archived spectral data. The long-term goal, to be achieved together with PDB, BMRB, and journal representatives, is to make the deposition of the underlying NMR spectra an integral part of bio-NMR projects published in peer-reviewed journals in the same way as the requirement to deposit protein structures in the PDB. We are singularly suited for the NMRprime initiative because of decades of experience in bio-NMR and the possibility to build NMRprime on the re-use of central components of our recent fully automated NMR spectra analysis system.",2022-08-01,18,150000
EXPLORE/OPEN-ACTRIS,Explore,PSI,Senior scientist,Robin,Modini,Laboratory of Atmospheric Chemistry,5232,Villigen,OPEN-ACTRIS: Building FAIR data chains for atmospheric observations in the ACTRIS-Switzerland network.,OPEN-ACTRIS,"The OPEN-ACTRIS project aims to explore and build up FAIR data chain standards and strategies for atmospheric observations collected in Switzerland as part of the Aerosol, Clouds and Trace Gases Research Infrastructure (ACTRIS). ACTRIS is a pan-European network that aims to deepen our understanding of climate change and air pollution by producing high-quality data on short-lived atmospheric constituents. ACTRIS-Switzerland is the multi-institutional Swiss node of the network. ACTRIS has a comprehensive vision for FAIR data that covers all stages of the research data life cycle through the definition of data levels covering raw measurements, processed data, and elaborated data products. The OPEN-ACTRIS project aims to implement these ORD concepts in the ETH domain and to explore best ORD practice within ACTRIS-Switzerland by combining existing tools and infrastructure from the ETH domain and the ACTRIS community. We will achieve this by building FAIR data chains for the aerosol observations continuously recorded at field measurement stations on the Jungfraujoch and in Payerne, and for the aerosol and gas measurements performed on a campaign-basis in the PSI Atmospheric Chemistry Simulation Chambers.",2024-09-01,12,150000
EXPLORE/OPENCHEMUSES,Explore,Empa,Scientist,Zhanyun,Wang,Technology & Society Laboratory,9014,St. Gallen,A Toolbox for Providing Open Data on Chemical and Material Uses (OpenChemUses),OpenChemUses,"Open data on the uses are key for the safety assessment of existing chemicals and materials, and for the design of novel safer ones. However, the availability and accessibility of use data in the public domain is limited. For many chemicals and materials, use data have been reported, but they cannot be readily extracted and used by scientists, regulators and the industry on a large scale. This is because they are scattered over the public domain, and are often reported using different terminologies and in a non-machine-readable/processable format. Against this background, this project aims to enable and engage the scientific and regulatory communities to build up open FAIR data on the uses of chemicals and materials by developing and disseminating a toolbox of the missing tools. In particular, the toolbox will include a standard and templates for future reporting, as well as a set of novel cheminformatics and natural language processing-based workflows and tools for automated extraction and harmonization of existing reporting from different types of sources, to be used by researchers within the ETH-Domain, as well as external researchers including industrial scientists, regulators, and civil society organisations. The project will take a participatory approach, with stakeholders within and outside the ETH-Domain to be engaged in the testing, finalization and dissemination of the toolbox.",2022-09-01,17,150000
EXPLORE/OPENNEXUS-E,Explore,ETH Zürich,Executive Director,Christian,Schaffner,Energy Science Center (ESC),8006,Zürich,Supporting open science with a plugin-based research platform for energy models,OpenNexus-e,"The Nexus-e platform is a powerful tool for assessing the impacts of potential pathways for the Swiss energy system. This project aims to open-source both the model input data and code, adhering to FAIR Open Research Data and Open Science principles. The objective is to develop a modular framework allowing quick integration of new models and enabling easy execution of existing ones. Currently featuring five models, Nexus-e facilitates interdisciplinary research and policy analysis in energy systems. The project seeks to streamline the process of adding new models through a plugin architecture and implementing an API for standardized interaction with scenarios. By fostering collaboration and providing access to diverse input data, the project aims to enhance the usability and impact of Nexus-e within and beyond the ETH community, thereby advancing energy system research and supporting policy development.",2024-10-01,18,111675
EXPLORE/OPENPULSE,Explore,EPFL,Head of ORD Engagement & Services,Oksana,Riba Grognuz,Swiss Data Science Center (EPFL VPA VPA-AVP-CP SDSC),1015,Lausanne,OpenPulse: Assessing Open Science community metrics for Open Source Software,OpenPulse,"OpenPulse: Assessing Open Science community metrics for Open Source Software aims to redefine the measurement of Open Science by focusing on Open Source Software (OSS) from EPFL. It addresses the limitations of current Open Science metrics, which primarily track Open Access publications, by proposing a new framework to evaluate the development of OSS and its community impact. This involves developing a tool, OpenPulse, to monitor OSS activities, establish reliable OSS datasets, and create visualizations for real-time impact assessment. The project emphasizes collaboration, community engagement, and the development of discipline-specific dashboards, aiming to foster a more inclusive and comprehensive understanding of Open Science's impact beyond traditional publications. Our project aims to solve that issue, by investigating ways to identify Open Source Software coming out of EPFL, defining measures of their FAIRness and investigating community metrics that will provide us with an understanding of the impact and health of a project. This therefore falls within the objective of both specifying ORD standards and prototyping a new ORD tool for monitoring Open Science outputs and their impact. Through providing visibility to these outputs, our intention is also to help researchers build and find their communities to engage in collaboration around shared resources. Crucially, we hold the view that Open Science extends beyond institutional boundaries and is instead rooted in discipline-specific communities and their individual definitions of the concept. The project will therefore involve workshops to consult researchers about the needs of their specific communities, and build individual dashboards that are catered to these needs. Once the project is robust and deployed, expansion to inter institutional collaborations will be developed.",2024-07-01,18,150000
EXPLORE/OPENSPM,Explore,EPFL,Associate Professor,Georg,Fantner,EPFL STI IBI-STI LBNI,1015,Lausanne,An ecosystem for community driven scanning probe microscopy research and development - OpenSPM,OpenSPM,"Scientific instruments these days are often sophisticated, intelligent systems consisting of complex hardware, electronics, and software components. To innovate in the technique, one must get access to all levels; instrument, hardware, software. Unfortunately, most commercial instrument manufacturers keep their technology proprietary, and provide very little access to the hardware and software. Before one can improve things, one has to either hack into the commercial system, or completely re-engineer the instrument. In our research field (scanning probe microscopy) this has become painfully noticeable as a marked decrease in innovation. In this project we propose to bring together the community to share and standardise their hardware and software developments in the field of SPM. The goal is to reach an open development ecosystem in which new and existing research projects can be embedded without having to first reinvent the wheel. We plan to leverage our existing open hardware AFM projects and their early adopters to generate an OpenSPM ecosystem consisting of the Open Hardware tools (hardware and software), an extensive knowledge base and development resources, a world-wide user community, and a sourcing platform that helps people adopt the open hardware.",2022-09-01,18,150030
EXPLORE/OPENSPM+,Explore,EPFL,Associate professor,Georg,Fantner,EPFL STI IBI-STI LBNI,1015,Lausanne,Establishing the ecosystem for community driven scanning probe microscopy research and development,OpenSPM+,"Custom instruments designed by researchers in academia are a key resource for advancing discovery and technology. However, they are very difficult and thus rarely shared openly with the scientific community. In the previous Explore project we have built an OpenSPM ecosystem around our custom OpenSPM prototypes. Through the rapid growth and success of this project, we have identified what will be required to sustain the growth of the OpenSPM ecosystem to become a global platform for future SPM research and development. In this second Explore grant call, we will continue to increase the available open technology, focus on maintenance and long-term viability by developing a professional development framework, and expand the community through international outreach and expansion beyond the field of SPM. The result will be a long-term sustainable, globally distributed network of users and developers from academia and industry.",2024-08-01,18,150000
EXPLORE/OPENWASHDATA,Explore,ETH Zürich,Prof. Dr.,Elizabeth,Tilley,Global Health Engineering,8092,Zurich,Open WASH data by building Open Science Competencies and Community,openwashdata,"Poor data management practices hold back progress in the Water, Sanitation, and Hygiene (WASH) sector, as WASH professionals often lack the training in data management competencies necessary for organizing, storing, and sharing data aligned with FAIR principles. This project addresses this gap by building the openwashdata community, which will support members in using open-source computational tools and further developing competencies consistent with FAIR data standards. The community aims to facilitate the publication of over 50 previously unpublished datasets contributed by members, fostering open science. The project also seeks to develop a global community of students and practitioners, create an accessible open data platform for WASH-related data, and research the technical, pedagogical, and political factors necessary for expanding and replicating this initiative to become the most comprehensive host and training platform in the open science WASH sector. The ultimate goal is to build a lasting, passionate network of WASH professionals applying FAIR data principles to benefit the entire sector.",2022-10-01,18,149990
EXPLORE/OPENWASHDATA,Explore,ETH Zürich,NA,Elizabeth,Tilley,NA,NA,NA,Open WASH data by establishing Data Stewards and increasing FAIRness,openwashdata,NA,NA,NA,15000
EXPLORE/SOLIDIPES,Explore,EPFL,Dr,Guillaume,Anciaux,EPFL ENAC IIC LSMS,1015,Lausanne,Solidipes: an interoperable tool for curation of research data,Solidipes,"Achieving FAIR open-science needs reproducible scientific data and publications to be associated. While choosing the appropriate tools and storage facilities is already difficult, ensuring the quality of an open publication of datasets relies heavily on data curation procedures. Curation calls for proper data validations and annotations, which are clearly discipline dependent. This proposal aims at exploring the extension of Solidipes, a dataset curation software, to make it suitable to each scientific discipline's needs, but also to broaden the platforms (repositories) Solidipes can interact with. For this project, researchers from computational mechanics and astrophysics associate with a member of the EPFL library in order to gather the experience necessary to cover this ambitious explore project. If funded, the project's team will collaborate with the teams of Episciences (French diamond open access platform) and with Renku (Swiss platform deploying tools for reproducible and collaborative data analysis). This proposal describes how to fill gaps towards a modern and multidisciplinary ecosystem for dataset+paper publications.",2024-09-01,16,150000
EXPLORE/SUCCESS,Explore,ETH Zürich,NA,André,Kahles,NA,NA,NA,Starting a User Community for Cutting-Edge Sequence Search,SUCCESS,NA,NA,NA,149996
EXPLORE/XCELL,Explore,WSL,Senior Scientist (PhD),Patrick,Fonti,"Dendrosciences, Forest Dynamics",8903,Birmensdorf,Towards an Open and Fair International Tree-Ring database for intra-annual tree-ring data and images (Xcell),Xcell,"Tree-ring research has played a pivotal role in unraveling past environmental conditions, understanding climate variability, and providing valuable insights into ecological changes over time. In the current era of digitalization, driven by technological advancements, the field is undergoing a profound transformation, delivering unprecedented details crucial for enhanced comprehension and exploration across various research domains. However, the absence of a suitable repository and the emerging imbalance between resource-intensive data producers and users pose significant challenges to data-sharing practices. This project aims to address these challenges by showcasing an operational solution, exemplified through intra-annually resolved wood cell anatomical data and images, involving the establishment of a modern, robust, and flexible repository and simultaneous redefinition of incentives for data producers. The Xcell Hub, through the creation of a community-specific, interactive, visualizable, and user-friendly online data repository, aims to foster Open Research Data (ORD) practices. Specifically, the project will develop an ORD-oriented operational web-based prototype designed for handling and hosting intra-annual resolved tree-ring data, focusing initially on Quantitative Wood Anatomy (QWA) data produced with the ROXAS software. The hub will collect, harmonize, centralize, preserve, and archive QWA data, metadata, and images, promoting openness, reproducibility, and collaboration between data producers and users. Features include a user-friendly Shiny web interface linked to a PostgreSQL database, comprehensive documentation, interactive data visualization, and a data policy that encourages sharing while recognizing contributors. This platform addresses current inequalities in data publication and access within the QWA and dendrochronology communities, providing a scalable example of good ORD practices through decentralized interactivity, rewarding mechanisms, transparent data assessment, and enhanced data quality.",2024-09-01,18,150000
