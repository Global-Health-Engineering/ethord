{
  "document_path": "raw/ORD_files/Contribute/Hutter - 6th call/final scientific report/appendix - scientific_accepted_paper_compressed.pdf",
  "status": "success",
  "data": {
    "websites_platforms": {
      "quantity": 1,
      "descriptions": [
        "Open-source hardware and software design for Boxi available online"
      ],
      "urls": [
        "https://github.com/leggedrobotics/grand_tour_box"
      ]
    },
    "repositories_catalogues": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "datasets_databases": {
      "quantity": 9,
      "descriptions": [
        "Mountain Ascend dataset, a paired multi-camera dataset enabling algorithmic development and future studies",
        "GrandTour dataset with high-quality ground truth reference data",
        "Hike: The robot descends and then ascends on loose gravel in a very large environment where optimization degradation [72] might occur. The robot traverses 330 m in 405 s.",
        "Warehouse: This dataset consists of the robot walking within a confined warehouse starting from the outdoor court. The environment features items, shelves, and a roll-up door for feature-based state estimation problems. The robot traverses 202 m in 370 s.",
        "Research Station: Acting as a simple dataset, the robot walks outside a research station featuring industrial metal stairs on an elevated metal grid platform. In this dataset, the robot traverses 210 m in 262 s.",
        "Excavation Site: In this outdoor dataset, the robot walks around an operating excavator. This dataset contains large stones, water pits, small dirt roads, and construction site containers, which bring unique features. The robot traverses 262 m in 200 s.",
        "Terrace: This dataset covers the robot walking from a cog railway station onto a terrace towards a large university building where limited features are available for short-range sensors while features are in abundance for large-scale perception. The robot traverses 200 m in 283 s seconds.",
        "Demolished Building: Walking from the outside into a search and rescue training facility through a demolished building with an open staircase and over multiple floors. The robot traverses 290 m in 368 s.",
        "Mountain Ascent: The robot starts by walking the scaffolding stairs, crossing a train station, and then traversing a narrow, very steep hiking path in sunny conditions, which presents challenges based on exposure. The robot traverses 300 m in 384 s.",
        "Ground truth trajectory generated with Holistic Fusion (HF) for the Excavation Site dataset"
      ],
      "urls": []
    },
    "software_tools": {
      "quantity": 11,
      "descriptions": [
        "Open-source software for Boxi integrating sensor payload and algorithmic performance analysis",
        "OKVIS2: Multi-Camera Visual-Inertial Odometry with Loop Closure",
        "DLIO: Customized LiDAR-inertial geometric-observer based odometry pipeline (Direct LiDAR Inertial Odometry)",
        "TSIF: Kinematic-inertial estimator representing proprioceptive state-estimation methods",
        "Inertial Explorer: Post-processed GNSS-IMU solution as an industrial positioning solution for outdoor datasets",
        "DLIO module for LiDAR-Inertial Odometry, used for state estimation and point cloud registration",
        "Wavemap module for 3D volumetric mapping and representation of the scene",
        "standalone, open-source tool for verifying time synchronization between two IMU time series measurements at arbitrary rates",
        "Custom kernel on Raspberry Pi Compute Module 4 for IIO support and timestamping",
        "Distributed recording system for sensor data recording across Jetson, NUC, and CPT7",
        "Open-source code based on Holistic Fusion (HF) framework for ground truth robot pose estimation",
        "In-house solution for camera driver limitations (debayering, white balancing, color correction)",
        "Time synchronization verification tool that calculates the time offset between data streams of IMU measurements using correlation and gradient-based optimization.",
        "Custom camera calibration workflow and software providing live feedback and distributed computation across target detection nodes, with real-time calibration during data collection, non-linear least squares optimization with Ceres Solver."
      ],
      "urls": [
        "https://github.com/leggedrobotics/grand_tour_box"
      ]
    },
    "models_standards": {
      "quantity": 1,
      "descriptions": [
        "Comprehensive cookbook for mobile sensor suite design, summarizing lessons learned and best practices"
      ],
      "urls": []
    },
    "workshops": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "training_events": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "publications": {
      "quantity": 28,
      "descriptions": [
        "Learning-based localizability estimation for robust lidar localization. In 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 17–24. IEEE, 2022.",
        "Holistic fusion: Task-and setup-agnostic robot localization and state estimation with factor graphs. arXiv preprint arXiv:2504.06479, 2025.",
        "Apriltag: A robust and flexible visual fiducial system. In 2011 IEEE International Conference on Robotics and Automation, pages 3400–3407, 2011. doi: 10.1109/ICRA.2011.5979561.",
        "The newer college dataset: Handheld lidar, inertial and vision with ground truth. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 4353–4360. IEEE, 2020.",
        "Wildcat: Online continuous-time 3d lidar-inertial slam. arXiv preprint arXiv:2205.12595, 2022.",
        "Extending kalibr: Calibrating the extrinsics of multiple imus and of individual axes. In 2016 IEEE International Conference on Robotics and Automation (ICRA), pages 4304–4311, 2016. doi: 10.1109/ICRA.2016.7487628.",
        "Efficient volumetric mapping of multi-scale environments using wavelet-based compression. In Robotics: Science and Systems (RSS), 2023. doi: 10.15607/RSS.2023.XIX.065.",
        "Stereo vision and imu based real-time ego-motion and depth image computation on a handheld device. In 2013 IEEE International Conference on Robotics and Automation, pages 4671–4678. IEEE, 2013.",
        "Core research development kit, 2022.",
        "Parallel pointing systems suitable for robotic total stations: Selection, dimensional synthesis, and accuracy analysis. Machines, 12(1):54, 2024.",
        "Tartandrive 2.0: More modalities and better infrastructure to further self-supervised learning research in off-road driving tasks. arXiv preprint arXiv:2402.01913, 2024.",
        "Rolling shutter camera synchronization with sub-millisecond accuracy. arXiv preprint arXiv:1902.11084, 2019.",
        "Scalability in perception for autonomous driving: Waymo open dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2446–2454, 2020.",
        "The oxford spires dataset: Benchmarking large-scale lidar-visual localisation, reconstruction and radiance field methods. arXiv preprint arXiv:2411.10546, 2024.",
        "Sensor fusion of robotic total station and inertial navigation system for 6dof tracking applications. Applied Geomatics, 16(4):933–949, 2024.",
        "The ROS Multimaster Extension for Simplified Deployment of Multi-Robot Systems, pages 629–650. Springer International Publishing, Cham, 2016. ISBN 978-3-319-26054-9. doi: 10.1007/978-3-319-26054-9_24.",
        "Cerberus: Autonomous legged and aerial robotic exploration in the tunnel and urban circuits of the darpa subterranean challenge. arXiv preprint arXiv:2201.07067, page 3, 2022.",
        "Tartandrive: A large-scale dataset for learning off-road dynamics models. In 2022 International Conference on Robotics and Automation (ICRA), pages 2546–2552. IEEE, 2022.",
        "Conslam: Construction data set for slam. Journal of Computing in Civil Engineering, 37(3):04023009, 2023.",
        "Versavis—an open versatile multi-camera visual-inertial sensor suite. Sensors, 20(5):1439, 2020.",
        "X-icp: Localizability-aware lidar registration for robust localization in extreme environments. IEEE Transactions on Robotics, 2023.",
        "Informed, constrained, aligned: A field analysis on degeneracy-aware point cloud registration in the wild. arXiv preprint arXiv:2408.11809, 2024.",
        "Rts-gt: Robotic total stations ground truthing dataset. In 2024 IEEE International Conference on Robotics and Automation (ICRA), pages 17050–17056. IEEE, 2024.",
        "Understanding and applying precision time protocol. In 2015 Saudi Arabia Smart Grid (SASG), pages 1–7. IEEE, 2015.",
        "Everysync: An open hardware time synchronization sensor suite for common sensors in slam. In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 12587–12593. IEEE, 2024.",
        "Pirvs: An advanced visual-inertial slam system with flexible sensor fusion and hardware co-design. In 2018 IEEE International Conference on Robotics and Automation (ICRA), pages 3826–3832. IEEE, 2018.",
        "Subt-mrs dataset: Pushing slam towards all-weather environments. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22647–22657, 2024."
      ],
      "urls": [
        "https://github.com/sevensense-robotics/core_research_manual",
        "https://www.roboticsproceedings.org/rss19/p065.pdf",
        "https://github.com/ethz-asl/wavemap",
        "https://doi.org/10.1007/978-3-319-26054-9_24"
      ]
    },
    "presentations": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "outreach_activities": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "patents_ip": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "new_collaborations": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "industrial_collaborations": {
      "quantity": 1,
      "descriptions": [
        "Collaboration with Leica Geosystems for co-development of Boxi"
      ],
      "urls": []
    },
    "estimated_users": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "other_outputs": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    }
  },
  "metadata": {
    "schema_name": "ORDReportOutput",
    "extraction_mode": "PREMIUM",
    "attempts": 1
  },
  "extraction_metadata": {
    "field_metadata": {
      "websites_platforms": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
            }
          ],
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 1,
                "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
              }
            ],
            "extraction_confidence": 0.7147713401963876,
            "confidence": 0.7147713401963876
          }
        ],
        "urls": [
          {
            "citation": [
              {
                "page": 1,
                "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          }
        ],
        "reasoning": "VERBATIM EXTRACTION"
      },
      "software_tools": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
            },
            {
              "page": 4,
              "matching_text": "| Algorithm              | Modality           | Description                        |\n| ---------------------- | ------------------ | ---------------------------------- |\n| OKVIS2 \\[41]           | Visual-Inertial    | Multi-Camera VIO with Loop Closure |\n| DLIO \\[14]             | LiDAR-Inertial     | Tightly coupled Filter-based LIO   |\n| TSIF \\[5]              | Kinematic-Inertial | Proprioceptive Filter-based        |\n| Inertial Explorer \\[2] | GNSS-Inertial      | Industrial offline INS             |"
            },
            {
              "page": 6,
              "matching_text": "performance of DLIO module"
            },
            {
              "page": 8,
              "matching_text": "Wavemap [57], which generates a detailed volumetric representation of the scene"
            },
            {
              "page": 13,
              "matching_text": "We have developed a standalone, open-source tool for verifying time synchronization between two IMU time series measurements at arbitrary rates."
            },
            {
              "page": 15,
              "matching_text": "A custom kernel was used on the Raspberry Pi Compute Module 4 to enable IIO support and accurate kernel timestamping."
            },
            {
              "page": 15,
              "matching_text": "implemented a distributed recording system, which stores data on the Jetson, NUC, and CPT7, minimizing network bandwidth and distributing load across machines."
            },
            {
              "page": 22,
              "matching_text": "We build on the publicly available Holistic Fusion (HF) framework [51] and refer to the offline factor-graph optimization output as our ground truth robot pose estimation. Details and code will be made available open-source."
            },
            {
              "page": 23,
              "matching_text": "we developed an in-house solution to address this"
            },
            {
              "page": 25,
              "matching_text": "We developed a time synchronization verification tool that calculates the time offset between data streams of IMU measurements. It first transforms the angular velocity readings of the IMUs"
            }
          ]
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 1,
                "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
              }
            ],
            "extraction_confidence": 0.36679223016198964,
            "confidence": 0.36679223016198964
          },
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "OKVIS2 [41], which is configured to perform loop closures"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9475068354758559,
            "confidence": 0.9475068354758559
          },
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "customized version of the state-of-the-art LiDAR-inertial geometric-observer based odometry pipeline Direct LiDAR Inertial Odometry (DLIO) [14]"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.8601129478305413,
            "confidence": 0.8601129478305413
          },
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "use the kinematic-inertial estimator TSIF [5] to represent the performance of proprioceptive state-estimation methods"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.916834871770487,
            "confidence": 0.916834871770487
          },
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "post-processed GNSS-IMU solution of the Inertial Explorer [2] is provided as an industrial positioning solution for outdoor datasets"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9287756062240794,
            "confidence": 0.9287756062240794
          },
          {
            "citation": [
              {
                "page": 6,
                "matching_text": "performance of DLIO module"
              }
            ]
          },
          {
            "citation": [
              {
                "page": 8,
                "matching_text": "Wavemap [57], which generates a detailed volumetric representation of the scene"
              }
            ]
          },
          {
            "citation": [
              {
                "page": 13,
                "matching_text": "We have developed a standalone, open-source tool for verifying time synchronization between two IMU time series measurements at arbitrary rates."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9950222800729682,
            "confidence": 0.9950222800729682
          },
          {
            "citation": [
              {
                "page": 15,
                "matching_text": "A custom kernel was used on the Raspberry Pi Compute Module 4 to enable IIO support and accurate kernel timestamping."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          {
            "citation": [
              {
                "page": 15,
                "matching_text": "implemented a distributed recording system, which stores data on the Jetson, NUC, and CPT7, minimizing network bandwidth and distributing load across machines."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999999886110207,
            "confidence": 0.9999999886110207
          },
          {
            "citation": [
              {
                "page": 22,
                "matching_text": "We build on the publicly available Holistic Fusion (HF) framework [51] and refer to the offline factor-graph optimization output as our ground truth robot pose estimation. Details and code will be made available open-source."
              }
            ],
            "extraction_confidence": 0.5981398823633974,
            "confidence": 0.5981398823633974
          },
          {
            "citation": [
              {
                "page": 23,
                "matching_text": "we developed an in-house solution to address this"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.7341115153923243,
            "confidence": 0.7341115153923243
          },
          {
            "citation": [
              {
                "page": 25,
                "matching_text": "We developed a time synchronization verification tool that calculates the time offset between data streams of IMU measurements. It first transforms the angular velocity readings of the IMUs"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.7733876352914717,
            "confidence": 0.7733876352914717
          },
          {
            "extraction_confidence": 0.37252619845586976,
            "confidence": 0.37252619845586976
          }
        ],
        "urls": [
          {
            "citation": [
              {
                "page": 1,
                "matching_text": "https://github.com/leggedrobotics/grand_tour_box"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          }
        ],
        "reasoning": "Combined all unique new or enhanced software, hardware, prototypes, and tools reported in the document, removing external software/tools and merging repeated references (e.g., synchronization tools only counted once but included all relevant detailed descriptions). Used verbatim extraction for descriptions, associating confidence scores where present. Included all associated URLs. This yields 11 unique outputs as per evidence across the source pages."
      },
      "models_standards": {
        "quantity": {
          "citation": [
            {
              "page": 2,
              "matching_text": "Compiling a comprehensive cookbook, featuring insights, lessons learned, and best practices"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "Compiling a comprehensive cookbook, featuring insights, lessons learned, and best practices"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.453513912027887,
            "confidence": 0.453513912027887
          }
        ],
        "reasoning": "VERBATIM EXTRACTION"
      },
      "datasets_databases": {
        "quantity": {
          "citation": [
            {
              "page": 6,
              "matching_text": "Mountain Ascend dataset (see Figure 4)...our paired multi-camera dataset enables rigorous future studies"
            },
            {
              "page": 16,
              "matching_text": "collection of the GrandTour dataset with high-quality ground truth reference data"
            },
            {
              "page": 21,
              "matching_text": "*Hike*: The robot descends and then ascends on loose gravel in a very large e..."
            },
            {
              "page": 21,
              "matching_text": "*Warehouse*: This dataset consists of the robot walking within a confined ware..."
            },
            {
              "page": 21,
              "matching_text": "*Research Station*: Acting as a simple dataset, the robot walks outside a rese..."
            },
            {
              "page": 21,
              "matching_text": "*Excavation Site*: In this outdoor dataset, the robot walks around an operati..."
            },
            {
              "page": 21,
              "matching_text": "*Terrace*: This dataset covers the robot walking from a cog railway station o..."
            },
            {
              "page": 21,
              "matching_text": "*Demolished Building*: Walking from the outside into a search and rescue trai..."
            },
            {
              "page": 21,
              "matching_text": "*Mountain Ascent*: The robot starts by walking the scaffolding stairs, crossi..."
            },
            {
              "page": 22,
              "matching_text": "Ground truth trajectory generated with Holistic Fusion (HF) for the Excavation Site dataset"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 0.9955957990075724,
          "confidence": 0.9955957990075724
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 6,
                "matching_text": "our paired multi-camera dataset enables rigorous future studies and algorithmic development"
              }
            ]
          },
          {
            "citation": [
              {
                "page": 16,
                "matching_text": "collection of the GrandTour dataset with high-quality ground truth reference data"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Hike*: The robot descends and then ascends on loose gravel in a very large e..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9870513576473715,
            "confidence": 0.9870513576473715
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Warehouse*: This dataset consists of the robot walking within a confined ware..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9987002390696428,
            "confidence": 0.9987002390696428
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Research Station*: Acting as a simple dataset, the robot walks outside a rese..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.999981146072385,
            "confidence": 0.999981146072385
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Excavation Site*: In this outdoor dataset, the robot walks around an operati..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999706948954277,
            "confidence": 0.9999706948954277
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Terrace*: This dataset covers the robot walking from a cog railway station o..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999968640397714,
            "confidence": 0.9999968640397714
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Demolished Building*: Walking from the outside into a search and rescue trai..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999997666852039,
            "confidence": 0.9999997666852039
          },
          {
            "citation": [
              {
                "page": 21,
                "matching_text": "*Mountain Ascent*: The robot starts by walking the scaffolding stairs, crossi..."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999859032640224,
            "confidence": 0.9999859032640224
          },
          {
            "citation": [
              {
                "page": 22,
                "matching_text": "Ground truth trajectory generated with Holistic Fusion (HF) for the Excavation Site dataset"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9675625885819089,
            "confidence": 0.9675625885819089
          }
        ],
        "reasoning": "Combined explicit new/enhanced dataset references. The 'A. Dataset Descriptions' section lists seven datasets with detailed context. Added Mountain Ascend (which contextually appears distinct) and GrandTour from other sections. The ground truth trajectory for Excavation Site is an enhancement and counted separately from its basic description. No URLs were present in any text."
      },
      "repositories_catalogues": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 22,
              "matching_text": "Details and code will be made available open-source."
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "INSUFFICIENT DATA. All provided JSON objects state there is no explicit mention of new or enhanced repositories or catalogs created by the project. External open-source references are not counted as outputs since they are not attributed as project products. All descriptions and URLs lists are empty, and quantity is zero, per verbatim extraction."
      },
      "workshops": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "INSUFFICIENT DATA"
      },
      "training_events": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "INSUFFICIENT DATA"
      },
      "publications": {
        "quantity": {
          "citation": [
            {
              "page": 20,
              "matching_text": "[77] Shibo Zhao, Yuanjun Gao, Tianhao Wu, Damanpreet Singh, Rushan Jiang, Haoxiang Sun, ..."
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 0.9998474830694232,
          "confidence": 0.9998474830694232
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Learning-based localizability estimation for robust lidar localization. In 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 17–24. IEEE, 2022."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9722701204717752,
            "confidence": 0.9722701204717752
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Holistic fusion: Task-and setup-agnostic robot localization and state estimation with factor graphs. arXiv preprint arXiv:2504.06479, 2025."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999998827741162,
            "confidence": 0.9999998827741162
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Apriltag: A robust and flexible visual fiducial system. In 2011 IEEE International Conference on Robotics and Automation, pages 3400–3407, 2011. doi: 10.1109/ICRA.2011.5979561."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9949888837150823,
            "confidence": 0.9949888837150823
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "The newer college dataset: Handheld lidar, inertial and vision with ground truth. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 4353–4360. IEEE, 2020."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999983666373932,
            "confidence": 0.9999983666373932
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Wildcat: Online continuous-time 3d lidar-inertial slam. arXiv preprint arXiv:2205.12595, 2022."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999978767115971,
            "confidence": 0.9999978767115971
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Extending kalibr: Calibrating the extrinsics of multiple imus and of individual axes. In 2016 IEEE International Conference on Robotics and Automation (ICRA), pages 4304–4311, 2016. doi: 10.1109/ICRA.2016.7487628."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999923342183992,
            "confidence": 0.9999923342183992
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Efficient volumetric mapping of multi-scale environments using wavelet-based compression. In Robotics: Science and Systems (RSS), 2023. doi: 10.15607/RSS.2023.XIX.065."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9731355780119302,
            "confidence": 0.9731355780119302
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Stereo vision and imu based real-time ego-motion and depth image computation on a handheld device. In 2013 IEEE International Conference on Robotics and Automation, pages 4671–4678. IEEE, 2013."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999914065526275,
            "confidence": 0.9999914065526275
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Core research development kit, 2022. URL https://github.com/sevensense-robotics/core_research_manual."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9959803112798334,
            "confidence": 0.9959803112798334
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Parallel pointing systems suitable for robotic total stations: Selection, dimensional synthesis, and accuracy analysis. Machines, 12(1):54, 2024."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999992905823064,
            "confidence": 0.9999992905823064
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Tartandrive 2.0: More modalities and better infrastructure to further self-supervised learning research in off-road driving tasks. arXiv preprint arXiv:2402.01913, 2024."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999992339568681,
            "confidence": 0.9999992339568681
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Rolling shutter camera synchronization with sub-millisecond accuracy. arXiv preprint arXiv:1902.11084, 2019."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999999378452115,
            "confidence": 0.9999999378452115
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Scalability in perception for autonomous driving: Waymo open dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2446–2454, 2020."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999960081753366,
            "confidence": 0.9999960081753366
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "The oxford spires dataset: Benchmarking large-scale lidar-visual localisation, reconstruction and radiance field methods. arXiv preprint arXiv:2411.10546, 2024."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999995973573825,
            "confidence": 0.9999995973573825
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Sensor fusion of robotic total station and inertial navigation system for 6dof tracking applications. Applied Geomatics, 16(4):933–949, 2024."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999977528825864,
            "confidence": 0.9999977528825864
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "The ROS Multimaster Extension for Simplified Deployment of Multi-Robot Systems, pages 629–650. Springer International Publishing, Cham, 2016. ISBN 978-3-319-26054-9. doi: 10.1007/978-3-319-26054-9_24."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.999275680913011,
            "confidence": 0.999275680913011
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Cerberus: Autonomous legged and aerial robotic exploration in the tunnel and urban circuits of the darpa subterranean challenge. arXiv preprint arXiv:2201.07067, page 3, 2022."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999942392093071,
            "confidence": 0.9999942392093071
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Tartandrive: A large-scale dataset for learning off-road dynamics models. In 2022 International Conference on Robotics and Automation (ICRA), pages 2546–2552. IEEE, 2022."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999995123657203,
            "confidence": 0.9999995123657203
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Conslam: Construction data set for slam. Journal of Computing in Civil Engineering, 37(3):04023009, 2023."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999992257128116,
            "confidence": 0.9999992257128116
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "Versavis—an open versatile multi-camera visual-inertial sensor suite. Sensors, 20(5):1439, 2020."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999963638099362,
            "confidence": 0.9999963638099362
          },
          {
            "extraction_confidence": 0.999927302066646,
            "confidence": 0.999927302066646
          },
          {
            "extraction_confidence": 0.9993812339067357,
            "confidence": 0.9993812339067357
          },
          {
            "extraction_confidence": 0.9989727428948751,
            "confidence": 0.9989727428948751
          },
          {
            "extraction_confidence": 0.9999948014061597,
            "confidence": 0.9999948014061597
          },
          {
            "extraction_confidence": 0.9999996000979124,
            "confidence": 0.9999996000979124
          },
          {
            "extraction_confidence": 0.9999987550790047,
            "confidence": 0.9999987550790047
          },
          {
            "extraction_confidence": 0.9999951605593166,
            "confidence": 0.9999951605593166
          }
        ],
        "urls": [
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "URL https://github.com/sevensense-robotics/core_research_manual. Accessed: 19 Oct 2024."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999949519703936,
            "confidence": 0.9999949519703936
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "URL https://www.roboticsproceedings.org/rss19/p065.pdf."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9856064909602332,
            "confidence": 0.9856064909602332
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "[Korbinian Schmid](https://github.com/ethz-asl/wavemap)"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9932719478397692,
            "confidence": 0.9932719478397692
          },
          {
            "citation": [
              {
                "page": 19,
                "matching_text": "URL https://doi.org/10.1007/978-3-319-26054-9_24."
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999265968261903,
            "confidence": 0.9999265968261903
          }
        ],
        "reasoning": "VERBATIM EXTRACTION"
      },
      "presentations": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "INSUFFICIENT DATA. All extracted data indicate zero presentations and lack of any descriptions or URLs. No mention of project-related presentations (conferences, posters, talks, etc.) is present within the provided text."
      },
      "outreach_activities": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "All provided source records report no evidence of outreach, dissemination, communications, or networking activities; each section searched returns 0 as the output value, with verbatim explanations indicating no such events or activities exist in the text. Therefore, the quantity is 0, with no descriptions or URLs present. VERBATIM EXTRACTION."
      },
      "patents_ip": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "All provided extractions (across multiple segments/pages) consistently report no evidence of patents, patent applications, or intellectual property outputs related to the project. Quantity is set to zero, with no descriptions or URLs reported. Reasoning is consistent across all entries, so 1.0 confidence is appropriate."
      },
      "new_collaborations": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "co-developed in collaboration with Leica Geosystems"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION. Each section of the source indicates zero new collaborations (except with industrial partners). No descriptions or URLs are provided that pertain to academic or other non-industrial partnerships."
      },
      "industrial_collaborations": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "co-developed in collaboration with Leica Geosystems"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 1,
                "matching_text": "co-developed in collaboration with Leica Geosystems"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.8787558873651562,
            "confidence": 0.8787558873651562
          }
        ],
        "reasoning": "VERBATIM EXTRACTION"
      },
      "estimated_users": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "INSUFFICIENT DATA"
      },
      "other_outputs": {
        "quantity": {
          "citation": [
            {
              "page": 1,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 6,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 9,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 17,
              "matching_text": "REFERENCES"
            },
            {
              "page": 22,
              "matching_text": "INSUFFICIENT DATA"
            },
            {
              "page": 25,
              "matching_text": "INSUFFICIENT DATA"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      }
    },
    "usage": {
      "num_pages_extracted": 27,
      "num_document_tokens": 39118,
      "num_output_tokens": 34349
    }
  },
  "config": {
    "priority": null,
    "extraction_target": "PER_DOC",
    "extraction_mode": "PREMIUM",
    "parse_model": "gemini-2.5-pro",
    "extract_model": "openai-gpt-4-1",
    "multimodal_fast_mode": false,
    "system_prompt": "\n  EXTRACTION STRATEGY:\n  1. PRIMARY: Look for data in the specified location/table/section\n  2. FALLBACK: If not found, search broader document context for semantically equivalent information\n  3. FLEXIBILITY: Allow for format variations, OCR errors, and synonym usage\n\n  LOCATION FLEXIBILITY:\n  - Handle table format variations (column/row order, spacing, naming)\n  - Consider synonyms and equivalent terms\n  - Account for OCR/parsing errors that may affect document quality\n\n  QUALITY STANDARDS:\n  - Extract actual values found in the document\n  - If uncertain, provide best interpretation with appropriate confidence\n  - Only return null if the information category truly doesn't exist\n  - Convert abbreviated amounts (k=1000) to full numbers where applicable\n  \n\n  REPORT OUTPUT FOCUS:\n  - 15 standard output categories in \"List of Outputs\" table\n  - Each category: quantity number, descriptions list, URLs list\n  - Separate descriptions from URLs even when mixed in same cell\n  - Academic collaborations vs Industrial partnerships (distinct categories)\n  - Preserve all detailed descriptions and web addresses\n  ",
    "use_reasoning": true,
    "cite_sources": true,
    "confidence_scores": true,
    "chunk_mode": "PAGE",
    "high_resolution_mode": true,
    "invalidate_cache": false,
    "num_pages_context": null,
    "page_range": null
  },
  "job_id": "ade7674c-839c-4230-9008-89ffb89184c7",
  "extraction_agent_id": "5e203f76-c00c-4144-b8ea-5a1cb37a2f07",
  "created_at": "2025-11-11T18:23:03.056161+00:00",
  "updated_at": "2025-11-11T18:24:55.576646+00:00"
}