{
  "document_path": "raw/ORD_files/Contribute/Miron - 3rd call/application/PSI_Miron.pdf",
  "status": "success",
  "data": {
    "project_category": "Contribute Projects",
    "main_applicant_institution": "PSI",
    "main_applicant_function": "Dr.",
    "main_applicant_first_name": "George Dan",
    "main_applicant_surname": "Miron",
    "main_applicant_laboratory_name": "Laboratory for Waste Management (LES)",
    "main_applicant_postcode": 5232,
    "main_applicant_city": "Villigen PSI",
    "all_applicants": [
      {
        "eth_domain_institution": "PSI",
        "function_title": "Dr.",
        "first_name": "George-Dan",
        "surname": "Miron",
        "postcode": 5232
      }
    ],
    "project_title": "Traceable thermodynamic datasets for chemical modelling",
    "project_acronym": "THRACE",
    "project_abstract": "At present, thermodynamic datasets do not follow ORD FAIR principles. ThermoHub database provides access to a collection of traceable thermodynamic datasets for various fields of application. These datasets are curated and documented by experts using an open standard JSON format. The aim of the project is to bring ThermoHub to its full potential and demonstrate its ORD capabilities by producing a unified database of several mainstream thermodynamic datasets that are ready to use for chemical modeling. The project also aims to develop and provide a documented semi-automatic workflow for future maintenance and extension with new data. This work can greatly standardize and unify the workflow of chemical thermodynamic modeling, and support iterative improvement of the quality, reliability, and traceability of databases and modeling results. Providing datasets following FAIR principles will be advantageous when used in modeling, as it will remove the burden from modelers of collecting all necessary standard thermodynamic values from vast literature or writing complex scripts for importing these from different formats. ThermoHub can greatly streamline collaboration within Swiss, European, and other international projects by providing traceable thermodynamic data for various modeling applications. It will also be advantageous for the recognized work at PSI/LES (as well as EPMA and ETHZ) on thermodynamic database and modeling code development.",
    "keywords": [
      "thermodynamics",
      "datasets",
      "modelling"
    ],
    "start_date": "1 Sep 2023",
    "project_duration_months": 4,
    "total_budget_requested": 30000.0,
    "work_packages": [
      {
        "wp_identifier": "WP1",
        "wp_title": "Data import and curating in ThermoHub"
      },
      {
        "wp_identifier": "WP2",
        "wp_title": "Extending data schemas, import/export"
      },
      {
        "wp_identifier": "WP3",
        "wp_title": "Workflow development from original data to data in ThermoHub"
      }
    ]
  },
  "metadata": {
    "schema_name": "ORDMetadata",
    "extraction_mode": "PREMIUM",
    "attempts": 1
  },
  "extraction_metadata": {
    "field_metadata": {
      "main_applicant_institution": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 18,
            "matching_text": "supports the application of Dr. George Dan Miron for an ORD Contribute project at Paul Scherrer Institute"
          },
          {
            "page": 21,
            "matching_text": "Paul Scherrer Institut - PSI, CH<br/>Laboratory for Waste Management"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_function": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Table in Applicant Details row: Function (Title) = Dr."
          }
        ],
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_first_name": {
        "reasoning": "There is a slight discrepancy between 'George-Dan' (table, idx 0) and 'George Dan' (text, idx 1 and 2). The form 'George Dan' is consistently used in narrative text and the CV, making it the more authoritative version for the first name. All extractions are verbatim from the document.",
        "citation": [
          {
            "page": 18,
            "matching_text": "application of Dr. George Dan Miron for an ORD Contribute project at Paul Scherrer Institute"
          },
          {
            "page": 21,
            "matching_text": "George Dan Miron"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_surname": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 18,
            "matching_text": "application of Dr. George Dan Miron for an ORD Contribute project at Paul Scherrer Institute"
          },
          {
            "page": 21,
            "matching_text": "George Dan Miron"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_laboratory_name": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Table in Applicant Details row: Laboratory name = Laboratory for Waste Management (LES)"
          }
        ],
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_postcode": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Table in Applicant Details row: Postcode / Zipcode = 5232"
          }
        ],
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "main_applicant_city": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Table in Applicant Details row: City = Villigen PSI"
          }
        ],
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "project_category": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 1,
            "matching_text": "ETH-Domain ORD Program - Measure 1 \"Contribute Projects\""
          },
          {
            "page": 18,
            "matching_text": "ETH Domain ORD Program<br/>Contribute Track"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "project_title": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 2,
            "matching_text": "Project title | Traceable thermodynamic datasets for chemical modelling"
          },
          {
            "page": 18,
            "matching_text": "project entitled “Traceable thermodynamic datasets for chemical modelling”"
          },
          {
            "page": 20,
            "matching_text": "Proposal: “Traceable thermodynamic datasets for chemical modelling”"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 0.9999998447946863,
        "confidence": 0.9999998447946863
      },
      "project_acronym": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 2,
            "matching_text": "Acronym of the project | THRACE"
          },
          {
            "page": 18,
            "matching_text": "acronym “THRACE”, pending ethical clearance of the project."
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "project_abstract": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 2,
            "matching_text": "Abstract | At present, thermodynamic datasets do not follow ORD FAIR principles. ThermoHub database..."
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 0.9999985018158294,
        "confidence": 0.9999985018158294
      },
      "keywords": [
        {
          "reasoning": "VERBATIM EXTRACTION",
          "citation": [
            {
              "page": 2,
              "matching_text": "thermodynamics, datasets, modelling"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        {
          "reasoning": "VERBATIM EXTRACTION",
          "citation": [
            {
              "page": 2,
              "matching_text": "thermodynamics, datasets, modelling"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        {
          "reasoning": "VERBATIM EXTRACTION",
          "citation": [
            {
              "page": 2,
              "matching_text": "thermodynamics, datasets, modelling"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        }
      ],
      "start_date": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Research Proposal table: Proposed Starting Date = 1 Sep 2023"
          }
        ],
        "extraction_confidence": 0.9999999374367368,
        "confidence": 0.9999999374367368
      },
      "project_duration_months": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 0,
            "matching_text": "Research Proposal table: Project duration = 4"
          }
        ],
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "total_budget_requested": {
        "reasoning": "VERBATIM EXTRACTION",
        "citation": [
          {
            "page": 16,
            "matching_text": "Total Costs (A + B)             |                                     |                                                  | 30'000       |"
          }
        ],
        "parsing_confidence": 1.0,
        "extraction_confidence": 1.0,
        "confidence": 1.0
      },
      "all_applicants": [
        {
          "eth_domain_institution": {
            "citation": [
              {
                "page": 0,
                "matching_text": "Applicant Details table provides all required fields for one applicant"
              }
            ],
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "function_title": {
            "citation": [
              {
                "page": 0,
                "matching_text": "Applicant Details table provides all required fields for one applicant"
              }
            ],
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "first_name": {
            "citation": [
              {
                "page": 0,
                "matching_text": "Applicant Details table provides all required fields for one applicant"
              }
            ],
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "surname": {
            "citation": [
              {
                "page": 0,
                "matching_text": "Applicant Details table provides all required fields for one applicant"
              }
            ],
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "postcode": {
            "citation": [
              {
                "page": 0,
                "matching_text": "Applicant Details table provides all required fields for one applicant"
              }
            ],
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "reasoning": "VERBATIM EXTRACTION"
        }
      ],
      "work_packages": [
        {
          "wp_identifier": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP1 | Data import and curating in ThermoHub"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "wp_title": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP1 | Data import and curating in ThermoHub"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "reasoning": "VERBATIM EXTRACTION"
        },
        {
          "wp_identifier": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP2 | Extending data schemas, import/export"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "wp_title": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP2 | Extending data schemas, import/export"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "reasoning": "VERBATIM EXTRACTION"
        },
        {
          "wp_identifier": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP3 | Workflow development from original data to data in ThermoHub"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "wp_title": {
            "citation": [
              {
                "page": 13,
                "matching_text": "WP3 | Workflow development from original data to data in ThermoHub"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 1.0,
            "confidence": 1.0
          },
          "reasoning": "VERBATIM EXTRACTION"
        }
      ]
    },
    "usage": {
      "num_pages_extracted": 23,
      "num_document_tokens": 12337,
      "num_output_tokens": 8092
    }
  },
  "config": {
    "priority": null,
    "extraction_target": "PER_DOC",
    "extraction_mode": "PREMIUM",
    "parse_model": "gemini-2.5-pro",
    "extract_model": "openai-gpt-4-1",
    "multimodal_fast_mode": false,
    "system_prompt": "\n  EXTRACTION STRATEGY:\n  1. PRIMARY: Look for data in the specified location/table/section\n  2. FALLBACK: If not found, search broader document context for semantically equivalent information\n  3. FLEXIBILITY: Allow for format variations, OCR errors, and synonym usage\n\n  LOCATION FLEXIBILITY:\n  - Handle table format variations (column/row order, spacing, naming)\n  - Consider synonyms and equivalent terms\n  - Account for OCR/parsing errors that may affect document quality\n\n  QUALITY STANDARDS:\n  - Extract actual values found in the document\n  - If uncertain, provide best interpretation with appropriate confidence\n  - Only return null if the information category truly doesn't exist\n  - Convert abbreviated amounts (k=1000) to full numbers where applicable\n  \n\n  METADATA EXTRACTION FOCUS:\n  - Project identification: title, acronym, duration, start date\n  - Applicant details: names, institutions, functions, addresses\n  - Project categorization: Explore/Establish/Contribute classification\n  - Keywords and abstract information from research proposal sections\n  ",
    "use_reasoning": true,
    "cite_sources": true,
    "confidence_scores": true,
    "chunk_mode": "PAGE",
    "high_resolution_mode": true,
    "invalidate_cache": false,
    "num_pages_context": null,
    "page_range": null
  },
  "job_id": "13130a61-3b55-4270-8ff2-e2a2886e7a0a",
  "extraction_agent_id": "2789051a-9806-42f4-b986-57da3d904671",
  "created_at": "2025-11-11T10:36:50.655821+00:00",
  "updated_at": "2025-11-11T10:39:15.701952+00:00"
}