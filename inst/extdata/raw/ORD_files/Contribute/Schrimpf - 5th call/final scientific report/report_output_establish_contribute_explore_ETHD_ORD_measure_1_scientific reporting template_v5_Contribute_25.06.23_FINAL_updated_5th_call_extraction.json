{
  "document_path": "raw/ORD_files/Contribute/Schrimpf - 5th call/final scientific report/ETHD_ORD_measure_1_scientific reporting template_v5_Contribute_25.06.23_FINAL_updated_5th_call.pdf",
  "status": "success",
  "data": {
    "websites_platforms": {
      "quantity": 1,
      "descriptions": [
        "Enhancements to the Brain-Score platform to support human data and new evaluation functionalities."
      ],
      "urls": [
        "https://www.brain-score.org/"
      ]
    },
    "repositories_catalogues": {
      "quantity": 1,
      "descriptions": [
        "GitHub repository for brain-score/vision—central repository for the project’s code, models, and benchmarks."
      ],
      "urls": [
        "https://www.github.com/brain-score/vision"
      ]
    },
    "datasets_databases": {
      "quantity": 2,
      "descriptions": [
        "Natural Scenes Dataset (NSD) packaged in Brain-Score format for model testing.",
        "THINGS-similarity dataset behavioral data packaged, benchmark available via Brain-Score platform."
      ],
      "urls": [
        "https://www.brain-score.org/benchmark/vision/169",
        "https://github.com/brain-score/vision/pull/1221"
      ]
    },
    "software_tools": {
      "quantity": 1,
      "descriptions": [
        "Enhanced Brain-Score Python model interface for human as well as non-human data."
      ],
      "urls": [
        "https://github.com/brain-score/vision/blob/master/brainscore_vision/model_interface.py"
      ]
    },
    "models_standards": {
      "quantity": 4,
      "descriptions": [
        "Proposed and revised Brain-Score model API for human data.",
        "New models submitted and integrated for human visual data evaluation in Brain-Score.",
        "New benchmarks for NSD and THINGS-similarity data available on Brain-Score.",
        "Best practice workflows for aligning computational models with human fMRI and behavioral data."
      ],
      "urls": [
        "https://github.com/brain-score/vision/blob/master/brainscore_vision/model_interface.py",
        "https://www.brain-score.org/benchmark/vision/169",
        "https://github.com/brain-score/vision/pull/1221",
        "https://www.brain-score.org/model/vision/2147"
      ]
    },
    "workshops": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "training_events": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "publications": {
      "quantity": 8,
      "descriptions": [
        "3 publications directly from the applicant’s group, at least 5 others in the wider community using project resources"
      ],
      "urls": []
    },
    "presentations": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "outreach_activities": {
      "quantity": 1,
      "descriptions": [
        "Brain-Score benchmarking competition for the community."
      ],
      "urls": [
        "https://www.brain-score.org/competition/"
      ]
    },
    "patents_ip": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "new_collaborations": {
      "quantity": 2,
      "descriptions": [
        "Collaboration with the Hebart lab at Max Planck Institute.",
        "Collaboration with the Yamins lab at Stanford."
      ],
      "urls": []
    },
    "industrial_collaborations": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    },
    "estimated_users": {
      "quantity": 400,
      "descriptions": [
        "Over 400 registered Brain-Score users; 100,000+ annual visits to the website."
      ],
      "urls": []
    },
    "other_outputs": {
      "quantity": 0,
      "descriptions": [],
      "urls": []
    }
  },
  "metadata": {
    "schema_name": "ORDReportOutput",
    "extraction_mode": "PREMIUM",
    "attempts": 1
  },
  "extraction_metadata": {
    "field_metadata": {
      "websites_platforms": {
        "quantity": {
          "citation": [
            {
              "page": 3,
              "matching_text": "New or enhanced website(s), web interface, platform(s) and/ or infrastructure:"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 0.6224593113235651,
          "confidence": 0.6224593113235651
        },
        "descriptions": [
          {
            "extraction_confidence": 0.5372556862030137,
            "confidence": 0.5372556862030137
          }
        ],
        "urls": [
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "https://www.brain-score.org/competition/"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.8690195259263641,
            "confidence": 0.8690195259263641
          }
        ],
        "reasoning": "No explicit new website created, but substantial new platform functionality—a core deliverable—so 'enhanced platform' is valid. URL inferred from multiple references; description synthesized from progress text."
      },
      "repositories_catalogues": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "extraction_confidence": 0.43021527831349915,
            "confidence": 0.43021527831349915
          }
        ],
        "urls": [
          {
            "extraction_confidence": 0.9440245526885428,
            "confidence": 0.9440245526885428
          }
        ],
        "reasoning": "VERBATIM EXTRACTION"
      },
      "datasets_databases": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "Natural Scenes Dataset (NSD) to incorporate their data into Brain-Score"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.7259388533256361,
            "confidence": 0.7259388533256361
          },
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "THINGS-similarity dataset to incorporate their data into Brain-Score"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.45968722226969216,
            "confidence": 0.45968722226969216
          }
        ],
        "urls": [
          {
            "extraction_confidence": 0.9999999851067194,
            "confidence": 0.9999999851067194
          },
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "https://github.com/brain-score/vision/pull/1221"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999997935355732,
            "confidence": 0.9999997935355732
          }
        ],
        "reasoning": "Quantity is explicit (2). Dataset details from Achievements text and table. URLs extracted and cleaned."
      },
      "software_tools": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "extraction_confidence": 0.5628168194866869,
            "confidence": 0.5628168194866869
          }
        ],
        "urls": [
          {
            "extraction_confidence": 0.9999999898098606,
            "confidence": 0.9999999898098606
          }
        ],
        "reasoning": "Verbatim from table, description clarified from report narrative."
      },
      "models_standards": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "proposal to adapt the Brain-Score model API for human data"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.6117577216696447,
            "confidence": 0.6117577216696447
          },
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "+ many new models submitted"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.14816469068208737,
            "confidence": 0.14816469068208737
          },
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "benchmark available via the Brain-Score platform"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.5994013329418665,
            "confidence": 0.5994013329418665
          },
          {
            "citation": [
              {
                "page": 2,
                "matching_text": "implemented a way to simulate the more noisy and less direct fMRI measure"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.457349831503639,
            "confidence": 0.457349831503639
          }
        ],
        "urls": [
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "https://github.com/brain-score/vision/blob/master/brainscore_vision/model_interface.py"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.999998689559535,
            "confidence": 0.999998689559535
          },
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "https://www.brain-score.org/benchmark/vision/169"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9999453732575591,
            "confidence": 0.9999453732575591
          },
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "https://github.com/brain-score/vision/pull/1221"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.999999952112336,
            "confidence": 0.999999952112336
          },
          {
            "extraction_confidence": 1.0,
            "confidence": 1.0
          }
        ],
        "reasoning": "Quantity and URL count explicit. Descriptions inferred from report body as well as output table."
      },
      "workshops": {
        "quantity": {
          "citation": [
            {
              "page": 3,
              "matching_text": "Scientific workshops organized as part of the project: | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      },
      "training_events": {
        "quantity": {
          "citation": [
            {
              "page": 3,
              "matching_text": "Training and educational events and/or resources directly related to the project: | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      },
      "publications": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "3 in my group, at least 5 others that I am aware of"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.45616271592992536,
            "confidence": 0.45616271592992536
          }
        ],
        "reasoning": "Quantity 8 is lowest plausible (8+). Descriptions verbatim, URLs not given."
      },
      "presentations": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "Presentations (e.g. conferences, poster, etc.) directly related to the project: | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      },
      "outreach_activities": {
        "quantity": {
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 3,
                "matching_text": "benchmarking competition last year (https://www.brain-score.org/competition/)"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.6657709872815275,
            "confidence": 0.6657709872815275
          }
        ],
        "urls": [
          {
            "extraction_confidence": 0.9999994919038199,
            "confidence": 0.9999994919038199
          }
        ],
        "reasoning": "Table entry with clear URL and description in narrative."
      },
      "patents_ip": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "Patents, patents applications or other intellectual property directly related to the project: | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      },
      "new_collaborations": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "New collaborations (except with industrial partners – see below): | 2 | My group now more closely works with the Hebart lab at MPI, and the Yamins lab at Stanford"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "My group now more closely works with the Hebart lab at MPI"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.8115601342679274,
            "confidence": 0.8115601342679274
          },
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "and the Yamins lab at Stanford"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.9897576273557104,
            "confidence": 0.9897576273557104
          }
        ],
        "reasoning": "Direct table entry; details also explicit."
      },
      "industrial_collaborations": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "New collaborations and/or contracts with industrial partners: | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      },
      "estimated_users": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "Estimated number of users within the community benefiting from enhanced ORD practices: | 400+ | Over 400 registered Brain-Score users; 100'000+ visits to the website per year"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "descriptions": [
          {
            "citation": [
              {
                "page": 4,
                "matching_text": "Over 400 registered Brain-Score users; 100'000+ visits to the website per year"
              }
            ],
            "parsing_confidence": 1.0,
            "extraction_confidence": 0.6751745013219733,
            "confidence": 0.6751745013219733
          }
        ],
        "reasoning": "400 taken as minimum, consistent with '400+'."
      },
      "other_outputs": {
        "quantity": {
          "citation": [
            {
              "page": 4,
              "matching_text": "Other (please specify): | |"
            }
          ],
          "parsing_confidence": 1.0,
          "extraction_confidence": 1.0,
          "confidence": 1.0
        },
        "reasoning": "VERBATIM EXTRACTION"
      }
    },
    "usage": {
      "num_pages_extracted": 5,
      "num_document_tokens": 3172,
      "num_output_tokens": 3792
    }
  },
  "config": {
    "priority": null,
    "extraction_target": "PER_DOC",
    "extraction_mode": "PREMIUM",
    "parse_model": "gemini-2.5-pro",
    "extract_model": "openai-gpt-4-1",
    "multimodal_fast_mode": false,
    "system_prompt": "\n  EXTRACTION STRATEGY:\n  1. PRIMARY: Look for data in the specified location/table/section\n  2. FALLBACK: If not found, search broader document context for semantically equivalent information\n  3. FLEXIBILITY: Allow for format variations, OCR errors, and synonym usage\n\n  LOCATION FLEXIBILITY:\n  - Handle table format variations (column/row order, spacing, naming)\n  - Consider synonyms and equivalent terms\n  - Account for OCR/parsing errors that may affect document quality\n\n  QUALITY STANDARDS:\n  - Extract actual values found in the document\n  - If uncertain, provide best interpretation with appropriate confidence\n  - Only return null if the information category truly doesn't exist\n  - Convert abbreviated amounts (k=1000) to full numbers where applicable\n  \n\n  REPORT OUTPUT FOCUS:\n  - 15 standard output categories in \"List of Outputs\" table\n  - Each category: quantity number, descriptions list, URLs list\n  - Separate descriptions from URLs even when mixed in same cell\n  - Academic collaborations vs Industrial partnerships (distinct categories)\n  - Preserve all detailed descriptions and web addresses\n  ",
    "use_reasoning": true,
    "cite_sources": true,
    "confidence_scores": true,
    "chunk_mode": "PAGE",
    "high_resolution_mode": true,
    "invalidate_cache": false,
    "num_pages_context": null,
    "page_range": null
  },
  "job_id": "75b888cc-77c2-46e3-985c-c57c86d0b579",
  "extraction_agent_id": "5e203f76-c00c-4144-b8ea-5a1cb37a2f07",
  "created_at": "2025-11-11T18:33:21.240253+00:00",
  "updated_at": "2025-11-11T18:34:19.101840+00:00"
}